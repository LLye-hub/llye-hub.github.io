<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LLye</title>
  
  
  <link href="https://llye-hub.github.io/atom.xml" rel="self"/>
  
  <link href="https://llye-hub.github.io/"/>
  <updated>2023-11-08T04:04:31.255Z</updated>
  <id>https://llye-hub.github.io/</id>
  
  <author>
    <name>LLye</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>java刷题常用code整理</title>
    <link href="https://llye-hub.github.io/posts/2a5db4cb.html"/>
    <id>https://llye-hub.github.io/posts/2a5db4cb.html</id>
    <published>2023-10-10T10:31:02.000Z</published>
    <updated>2023-11-08T04:04:31.255Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="780c9754f7b0d4dc15faf73e62d526c0a60c1f19ef439ce42f69f886ac30f4b8">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">这是一篇加密文章，需要密码才能继续阅读。</summary>
    
    
    
    <category term="对照文件存放的目录名称" scheme="https://llye-hub.github.io/categories/%E5%AF%B9%E7%85%A7%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E7%9A%84%E7%9B%AE%E5%BD%95%E5%90%8D%E7%A7%B0/"/>
    
    
    <category term="文章内容的关键词" scheme="https://llye-hub.github.io/tags/%E6%96%87%E7%AB%A0%E5%86%85%E5%AE%B9%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D/"/>
    
    <category term="private" scheme="https://llye-hub.github.io/tags/private/"/>
    
  </entry>
  
  <entry>
    <title>SparkSQL优化之数据倾斜</title>
    <link href="https://llye-hub.github.io/posts/faab1ad7.html"/>
    <id>https://llye-hub.github.io/posts/faab1ad7.html</id>
    <published>2023-07-09T02:19:52.000Z</published>
    <updated>2023-11-08T03:56:31.674Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在Spark作业优化场景中，最常见且比较棘手的就是数据倾斜问题。个人认为，具备数据倾斜调优能力对从事数仓开发人员是必备的基本要求。当然，数据倾斜的场景是比较复杂的，针对不同的数据倾斜有不同的处理方案。</p><h1 id="如何辨别和定位数据倾斜"><a href="#如何辨别和定位数据倾斜" class="headerlink" title="如何辨别和定位数据倾斜"></a>如何辨别和定位数据倾斜</h1><p>从Spark作业的执行计划看，若出现某个task任务比其他task任务执行耗时极其久，比如：某个stage有100个task，其中99个task在1min左右就执行成功，但是有1个task却执行了1个小时甚至更久，这种情况显然是出现了数据倾斜。</p><p>数据倾斜问题仅出现在shuffle过程，一些会触发shuffle的算子：distinct、groupByKey、reduceByKey、aggregateByKey、countByKey、join、cogroup、repartition等。<br>对应提交的SparkSQL中可能有distinct、count(distinct)、group by、partition by、join等关键词。</p><h1 id="常见的数据倾斜场景及解决方案"><a href="#常见的数据倾斜场景及解决方案" class="headerlink" title="常见的数据倾斜场景及解决方案"></a>常见的数据倾斜场景及解决方案</h1><h1 id="碰到的数据倾斜案例"><a href="#碰到的数据倾斜案例" class="headerlink" title="碰到的数据倾斜案例"></a>碰到的数据倾斜案例</h1><h2 id="窗口分组数据倾斜"><a href="#窗口分组数据倾斜" class="headerlink" title="窗口分组数据倾斜"></a>窗口分组数据倾斜</h2><p><strong>倾斜场景</strong><br>业务上有一张消息记录表msg_records，sql要求是取下一次回复消息</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> msg_tmp <span class="keyword">as</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span>  id                  <span class="comment">-- 唯一键，消息id</span></span><br><span class="line">           ,from_chat_id        <span class="comment">-- 消息发送者id</span></span><br><span class="line">           ,to_chat_id          <span class="comment">-- 消息接受者id</span></span><br><span class="line">           ,msg_time            <span class="comment">-- 消息时间</span></span><br><span class="line">    <span class="keyword">from</span> msg_records</span><br><span class="line">)</span><br><span class="line"><span class="keyword">select</span>  id</span><br><span class="line">       ,msg_time</span><br><span class="line">       ,<span class="built_in">first_value</span>(if(type <span class="operator">=</span> <span class="string">&#x27;reply&#x27;</span>,id,<span class="keyword">null</span>),<span class="literal">true</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> from_chat_id,to_chat_id <span class="keyword">order</span> <span class="keyword">by</span> msg_time,id <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> following <span class="keyword">and</span> unbounded following) <span class="keyword">as</span> reply_msg_id_n1t <span class="comment">-- 取下一次回复消息</span></span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span>  id</span><br><span class="line">           ,from_chat_id</span><br><span class="line">           ,to_chat_id</span><br><span class="line">           ,msg_time</span><br><span class="line">           ,<span class="string">&#x27;send&#x27;</span> <span class="keyword">as</span> type</span><br><span class="line">    <span class="keyword">from</span> msg_tmp</span><br><span class="line">    <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">    <span class="comment">-- 调转，取返回消息</span></span><br><span class="line">    <span class="keyword">select</span>  id</span><br><span class="line">           ,to_chat_id   <span class="keyword">as</span> from_chat_id</span><br><span class="line">           ,from_chat_id <span class="keyword">as</span> to_chat_id</span><br><span class="line">           ,msg_time</span><br><span class="line">           ,<span class="string">&#x27;reply&#x27;</span>      <span class="keyword">as</span> type</span><br><span class="line">    <span class="keyword">from</span> msg_tmp</span><br><span class="line">) t1</span><br></pre></td></tr></table></figure><p><strong>sql执行分析</strong><br>有一个task执行耗时1h<br><img src="https://i.328888.xyz/2023/02/10/R2j3w.png" alt="R2j3w.png"></p><p><strong>数据倾斜分析</strong><br>根据窗口函数的分组<code>from_chat_id + to_chat_id</code>分析，数据量出现严重倾斜，表总数据量1亿多，其中，分组<code>from_chat_id=12 and to_chat_id=81867</code>的数据量有30w，其他分组数据量至多3w。</p><p>另外，分组<code>from_chat_id=12 and to_chat_id=81867</code>的数据在业务上可定义为脏数据，且first_value()函数计算出的值全为null。</p><p>经过测试验证发现，没有 <strong>rows between语句</strong> 或是 <strong>过滤倾斜数据</strong> 时，SQL执行很快</p><p>综上分析，再对照spark执行计划基本可以定位倾斜原因为<strong>窗口数据倾斜和rows between计算耗时</strong></p><p><strong>解决方案</strong><br>结合业务知识，在sql逻辑中过滤<code>from_chat_id=12 and to_chat_id=81867</code>的数据</p><p>最终，任务执行耗时从<code>1h</code>优化至<code>10min</code></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html">美团技术团队：Spark性能优化指南——高级篇</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;在Spark作业优化场景中，最常见且比较棘手的就是数据倾斜问题。个人认为，具备数据倾斜调优能力对从事数仓开发人员是必备的基本要求。当然，数据</summary>
      
    
    
    
    <category term="SQL" scheme="https://llye-hub.github.io/categories/SQL/"/>
    
    
    <category term="数据倾斜" scheme="https://llye-hub.github.io/tags/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"/>
    
  </entry>
  
  <entry>
    <title>算法思路总结</title>
    <link href="https://llye-hub.github.io/posts/5f4823a0.html"/>
    <id>https://llye-hub.github.io/posts/5f4823a0.html</id>
    <published>2023-06-15T06:16:02.000Z</published>
    <updated>2023-06-28T03:05:20.441Z</updated>
    
    <content type="html"><![CDATA[<h1 id="st表"><a href="#ST表" class="headerlink" title="ST表"></a>ST表</h1><p>ST表（Sparse Table，稀疏表）是一种数据结构，采用了倍增的思想，在<code>O(nlogn)</code>时间构造一个二维表，可以在<code>O(1)</code>时间查询<code>[l,r]</code>区间的最值。主要用于解决RMQ（Range Minimum&#x2F;Maximum Query，区间最值查询）问题。</p><p>实现思路：</p><ul><li>设<code>F[i,j]</code>表示<code>[i,i+2^j-1]</code>区间的最值，区间长度为<code>2^j</code></li><li>根据倍增思想，长度为<code>2^j</code>的区间能分成两个长度为<code>2^(j-1)</code>的区间，然后分别求两个区间的最值。递推公式：<code>F[i,j]=max(F[i,j-1],F[i+2^(j-1),j-1])</code></li></ul><p>java代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 构建ST表</span></span><br><span class="line"><span class="type">int</span>[] lg = <span class="keyword">new</span> <span class="title class_">int</span>[n + <span class="number">1</span>];<span class="comment">// 预处理：以2为底的对数，向下取整</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">2</span>; i &lt;= n; ++i) &#123;</span><br><span class="line">    lg[i] = lg[i &gt;&gt; <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(Arrays.toString(lg));</span><br><span class="line"></span><br><span class="line"><span class="comment">// f[i][j] 表示 [i - 2^j + 1, i] 区间的最大值</span></span><br><span class="line"><span class="type">int</span>[][] f = <span class="keyword">new</span> <span class="title class_">int</span>[n][lg[n] + <span class="number">1</span>];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    f[i][<span class="number">0</span>] = chargeTimes[i];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">1</span>; j &lt;= lg[i + <span class="number">1</span>]; ++j) &#123;</span><br><span class="line">        f[i][j] = Math.max(f[i][j - <span class="number">1</span>], f[i - (<span class="number">1</span> &lt;&lt; j - <span class="number">1</span>)][j - <span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span>[] tmp : f) &#123;</span><br><span class="line">    System.out.printf(Arrays.toString(tmp));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;st表&quot;&gt;&lt;a href=&quot;#ST表&quot; class=&quot;headerlink&quot; title=&quot;ST表&quot;&gt;&lt;/a&gt;ST表&lt;/h1&gt;&lt;p&gt;ST表（Sparse Table，稀疏表）是一种数据结构，采用了倍增的思想，在&lt;code&gt;O(nlogn)&lt;/code&gt;时间构造一个</summary>
      
    
    
    
    <category term="练习笔记" scheme="https://llye-hub.github.io/categories/%E7%BB%83%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>解题思路之贪心算法</title>
    <link href="https://llye-hub.github.io/posts/da0ecc89.html"/>
    <id>https://llye-hub.github.io/posts/da0ecc89.html</id>
    <published>2023-05-31T07:37:07.000Z</published>
    <updated>2023-06-06T07:05:16.181Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="f1f3933a38de26f1241c74b22bf82c037a1f539cf1cf481ff0f3312a41d44f38">0ae7e196f2221a75e5346dcbb7e124f36deed831076312fa04e0c81d58c043c148e8c22ba19b06abf116e63b513fbe0b5b1ddbf3866dc6a4e231d41e8109c481fc84aff1e6d1f764e5387bbc2a63efcd269076b6d26b9e37133e8c3c6e87e9c29bb7891588fe68135e64e07a5ee665260c228e10e9e2b55e786e2e883ea80bceea0893b36e9e1e963aad143ef29fb21981efea5dca5fe6cbb33adb683110ddbb7085b2538798a7949198817313548b38852832d8eddec8d696ad233fc849508b1de1d97c47860c66db564e474b3cdd7dc05b249a441e1f42d0fe89b797e9a6f338fd5759017bc374582df0e6d42f28361eb0d77c753ec011e1c74dff9ebd735b03ceeea2bf90dbe2c14c2a3da8ce0fa476df707c7a8e1749a23b680aa9b612153300f46bb11388f8217130f8ee7b541cf4431a021a430a3e721ede6cc6a94facb92a5ca4b781e9be77c179c399d4d821</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">这是一篇加密文章，需要密码才能继续阅读。</summary>
    
    
    
    <category term="对照文件存放的目录名称" scheme="https://llye-hub.github.io/categories/%E5%AF%B9%E7%85%A7%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E7%9A%84%E7%9B%AE%E5%BD%95%E5%90%8D%E7%A7%B0/"/>
    
    
    <category term="文章内容的关键词" scheme="https://llye-hub.github.io/tags/%E6%96%87%E7%AB%A0%E5%86%85%E5%AE%B9%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D/"/>
    
    <category term="private" scheme="https://llye-hub.github.io/tags/private/"/>
    
  </entry>
  
  <entry>
    <title>SQL之distirbute by rand有坑</title>
    <link href="https://llye-hub.github.io/posts/68201c19.html"/>
    <id>https://llye-hub.github.io/posts/68201c19.html</id>
    <published>2023-05-23T09:29:09.000Z</published>
    <updated>2023-06-06T07:05:16.175Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="27e524583d1fcf2f1c13d3f5a7034a7f698ec863b32338e48443bc6eccafe994">0ae7e196f2221a75e5346dcbb7e124f39514e07fde056a265182dbd07146d257904f8da20d3ff0c1b0ef8ab8f0988a5faa61ca39c50eca0bc647f1183468803fdb7eb5d5a7593fd27e5d0d4c591b1b3b437b54ddd77005bf7470681fc084f79e4692262a7f466691839a576636f25cc888052dd1155a41106eb8db3b08946eb959cf163478c34033fb6ecaec8e26b694d3d6c8f1267c9f15b06256e1ca5699e5cac5130527fb77e1f5d169cd7b276a6fb1d18b77ca651179a48e0c7aa93ed2e7b1bf0984864b9f7a1e23e5aff938ca81b5be8200b7bf93fe40d35a21c6bcb5c6c181d8277085c1c77c914826650e9850</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">这是一篇加密文章，需要密码才能继续阅读。</summary>
    
    
    
    <category term="对照文件存放的目录名称" scheme="https://llye-hub.github.io/categories/%E5%AF%B9%E7%85%A7%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E7%9A%84%E7%9B%AE%E5%BD%95%E5%90%8D%E7%A7%B0/"/>
    
    
    <category term="文章内容的关键词" scheme="https://llye-hub.github.io/tags/%E6%96%87%E7%AB%A0%E5%86%85%E5%AE%B9%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D/"/>
    
    <category term="private" scheme="https://llye-hub.github.io/tags/private/"/>
    
  </entry>
  
  <entry>
    <title>解题思路之回溯算法</title>
    <link href="https://llye-hub.github.io/posts/49adf57d.html"/>
    <id>https://llye-hub.github.io/posts/49adf57d.html</id>
    <published>2023-05-19T06:34:49.000Z</published>
    <updated>2023-06-28T02:03:26.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是回溯算法"><a href="#什么是回溯算法" class="headerlink" title="什么是回溯算法"></a>什么是回溯算法</h1><p>回溯法也可以叫做回溯搜索法，它是一种搜索的方式。回溯是递归的副产品，回溯函数也就是递归函数。  </p><p>回溯的本质是穷举，穷举所有可能，然后选出我们想要的答案，如果想让回溯法高效一些，可以加一些剪枝的操作，但也改不了回溯法就是穷举的本质。</p><p>回溯法，一般可以解决如下几种问题：</p><ul><li>组合问题：N个数里面按一定规则找出k个数的集合</li><li>切割问题：一个字符串按一定规则有几种切割方式</li><li>子集问题：一个N个数的集合里有多少符合条件的子集</li><li>排列问题：N个数按一定规则全排列，有几种排列方式</li><li>棋盘问题：N皇后，解数独等等</li></ul><h1 id="解题步骤"><a href="#解题步骤" class="headerlink" title="解题步骤"></a>解题步骤</h1><p>1、回溯函数模板返回值以及参数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; result;</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; path;</span><br><span class="line"><span class="keyword">void</span> <span class="title function_">backtracking</span><span class="params">(参数)</span></span><br></pre></td></tr></table></figure><p>2、终止条件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (终止条件) &#123;</span><br><span class="line">    存放结果;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、回溯搜索的遍历过程</p><p><img src="https://i.328888.xyz/2023/05/19/VfjGSo.png" alt="VfjGSo.png"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) &#123;</span><br><span class="line">    处理节点;</span><br><span class="line">    backtracking(路径，选择列表); <span class="comment">// 递归</span></span><br><span class="line">    回溯，撤销处理结果;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>for循环就是遍历集合区间，可以理解一个节点有多少个孩子，这个for循环就执行多少次。<br>backtracking是自己调用自己，实现递归。</p><p>综上，回溯算法的模板框架如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; result;</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; path;</span><br><span class="line"><span class="keyword">void</span> <span class="title function_">backtracking</span><span class="params">(参数)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (终止条件) &#123;</span><br><span class="line">        存放结果;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) &#123;</span><br><span class="line">        处理节点;</span><br><span class="line">        backtracking(路径，选择列表); <span class="comment">// 递归</span></span><br><span class="line">        回溯，撤销处理结果;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="例子全排列"><a href="#例子：全排列" class="headerlink" title="例子：全排列"></a>例子：全排列</h2><p>题目：给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。<br>输入：nums &#x3D; [1,2,3]<br>输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]</p><p>抽象成树形结构如下：<br><img src="https://i.328888.xyz/2023/05/19/Vf87Gp.png" alt="Vf87Gp.png"></p><p>代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();<span class="comment">// 存放符合条件结果的集合</span></span><br><span class="line">LinkedList&lt;Integer&gt; path = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();<span class="comment">// 用来存放符合条件结果</span></span><br><span class="line">    <span class="type">boolean</span>[] isVisited;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; <span class="title function_">permute</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">        isVisited = <span class="keyword">new</span> <span class="title class_">boolean</span>[nums.length];</span><br><span class="line">        backTracking(nums);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">backTracking</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">        <span class="comment">// 终止条件</span></span><br><span class="line">        <span class="keyword">if</span> (path.size() == nums.length) &#123;</span><br><span class="line">            res.add(<span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(path));</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遍历当前数组</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            <span class="comment">// 处理节点</span></span><br><span class="line">            <span class="keyword">if</span> (isVisited[i]) &#123;  <span class="keyword">continue</span>;&#125;  <span class="comment">// 跳过已排列的元素</span></span><br><span class="line">            isVisited[i] = <span class="literal">true</span>; <span class="comment">// 标记当前位置元素是否已排列</span></span><br><span class="line">            path.add(nums[i]);</span><br><span class="line">            <span class="comment">// 递归</span></span><br><span class="line">            backTracking(nums);</span><br><span class="line">            <span class="comment">// 回溯</span></span><br><span class="line">            path.removeLast();</span><br><span class="line">            isVisited[i] = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>扩展</strong>：给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。</p><p>代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;List&lt;Integer&gt;&gt;();  <span class="comment">// 存放符合条件结果的集合</span></span><br><span class="line">    LinkedList&lt;Integer&gt; path = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();  <span class="comment">// 存放符合条件结果</span></span><br><span class="line">    Set&lt;Integer&gt; distNums;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; <span class="title function_">permuteUnique</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">        <span class="comment">// 计数</span></span><br><span class="line">        Map&lt;Integer, Integer&gt; dict = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> num : nums) &#123;dict.put(num, dict.getOrDefault(num, <span class="number">0</span>)+<span class="number">1</span>);&#125;</span><br><span class="line">        <span class="comment">// 唯一出现的数字</span></span><br><span class="line">        distNums = dict.keySet();</span><br><span class="line">        backTracking(nums,dict);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">backTracking</span><span class="params">(<span class="type">int</span>[] nums,Map&lt;Integer, Integer&gt; dict)</span> &#123;</span><br><span class="line">        <span class="comment">// 终止条件</span></span><br><span class="line">        <span class="keyword">if</span> (path.size() == nums.length) &#123;</span><br><span class="line">            res.add(<span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(path));</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遍历所有数字（去重后的）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> num : distNums) &#123;</span><br><span class="line">            <span class="comment">// 处理节点</span></span><br><span class="line">            <span class="keyword">if</span> (dict.get(num) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                path.add(num);</span><br><span class="line">                dict.put(num, dict.get(num) - <span class="number">1</span>);</span><br><span class="line">                <span class="comment">// 递归</span></span><br><span class="line">                backTracking(nums, dict);</span><br><span class="line">                <span class="comment">// 回溯</span></span><br><span class="line">                dict.put(num, dict.get(num) + <span class="number">1</span>);</span><br><span class="line">                path.removeLast();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 时间复杂度O(n^2)，空间复杂度O(n)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="例子活字印刷"><a href="#例子：活字印刷" class="headerlink" title="例子：活字印刷"></a>例子：活字印刷</h1><p>题目：你有一套活字字模 tiles，其中每个字模上都刻有一个字母 tiles[i]。返回你可以印出的非空字母序列的数目。<br>输入：”AAB”<br>输出：8  </p><p>代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">numTilePossibilities</span><span class="params">(String tiles)</span> &#123;</span><br><span class="line">        <span class="comment">// 统计字符个数</span></span><br><span class="line">        Map&lt;Character, Integer&gt; dict = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">char</span> c : tiles.toCharArray()) &#123;</span><br><span class="line">            dict.put(c, dict.getOrDefault(c, <span class="number">0</span>) + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Set&lt;Character&gt; tile=<span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(dict.keySet());</span><br><span class="line">        <span class="keyword">return</span> dfs(tiles.length(),dict,tile)-<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span> i, Map&lt;Character, Integer&gt; dict, Set&lt;Character&gt; tile)</span> &#123;</span><br><span class="line">        <span class="comment">// 递归终止条件，字符用完了</span></span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遍历当前dict中value大于0的字符（去重后的）</span></span><br><span class="line">        <span class="type">int</span> res=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">char</span> c : tile) &#123;</span><br><span class="line">            <span class="keyword">if</span> (dict.get(c) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                dict.put(c, dict.get(c) - <span class="number">1</span>);</span><br><span class="line">                res += dfs(i - <span class="number">1</span>, dict, tile);</span><br><span class="line">                dict.put(c, dict.get(c) + <span class="number">1</span>); <span class="comment">// 回溯</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 时间复杂度O(n * n!)，空间复杂度O(∑)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://programmercarl.com/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html#%E9%A2%98%E7%9B%AE%E5%88%86%E7%B1%BB%E5%A4%A7%E7%BA%B2%E5%A6%82%E4%B8%8B">代码随想录之回溯算法</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;什么是回溯算法&quot;&gt;&lt;a href=&quot;#什么是回溯算法&quot; class=&quot;headerlink&quot; title=&quot;什么是回溯算法&quot;&gt;&lt;/a&gt;什么是回溯算法&lt;/h1&gt;&lt;p&gt;回溯法也可以叫做回溯搜索法，它是一种搜索的方式。回溯是递归的副产品，回溯函数也就是递归函数。  &lt;/</summary>
      
    
    
    
    <category term="练习笔记" scheme="https://llye-hub.github.io/categories/%E7%BB%83%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="LeetCode" scheme="https://llye-hub.github.io/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>hiveSQL之深入理解视图</title>
    <link href="https://llye-hub.github.io/posts/2dfa544e.html"/>
    <id>https://llye-hub.github.io/posts/2dfa544e.html</id>
    <published>2023-05-17T01:58:48.000Z</published>
    <updated>2023-05-23T01:49:28.599Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="4f2fa0670b869d791d182abfc78a3015284ac2f7c4e7e7841f52957474817890">0ae7e196f2221a75e5346dcbb7e124f3a273828722568f616125477033531497</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">这是一篇加密文章，需要密码才能继续阅读。</summary>
    
    
    
    <category term="对照文件存放的目录名称" scheme="https://llye-hub.github.io/categories/%E5%AF%B9%E7%85%A7%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E7%9A%84%E7%9B%AE%E5%BD%95%E5%90%8D%E7%A7%B0/"/>
    
    
    <category term="文章内容的关键词" scheme="https://llye-hub.github.io/tags/%E6%96%87%E7%AB%A0%E5%86%85%E5%AE%B9%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D/"/>
    
    <category term="private" scheme="https://llye-hub.github.io/tags/private/"/>
    
  </entry>
  
  <entry>
    <title>hive之常用元数据表</title>
    <link href="https://llye-hub.github.io/posts/b06ccdfe.html"/>
    <id>https://llye-hub.github.io/posts/b06ccdfe.html</id>
    <published>2023-05-16T03:30:36.000Z</published>
    <updated>2023-11-08T04:05:15.051Z</updated>
    
    <content type="html"><![CDATA[<p>hive元数据信息通常存储在关系型数据库，常见的是MySQL数据库。hive元数据信息存储在MySQL库的57张表中。<br><img src="https://i.328888.xyz/2023/05/16/Vi0EjJ.png" alt="Vi0EjJ.png"></p><h1 id="存储hive版本的元数据表version"><a href="#存储Hive版本的元数据表（VERSION）" class="headerlink" title="存储Hive版本的元数据表（VERSION）"></a>存储Hive版本的元数据表（VERSION）</h1><table><thead><tr><th>VER_ID</th><th>SCHEMA_VERSION</th><th>VERSION_COMMENT</th></tr></thead><tbody><tr><td>1</td><td>2.3.0</td><td>Hive release version 2.3.0</td></tr></tbody></table><p>该表比较重要，如果出现问题，根本进入不了Hive-Cli。比如该表不存在，当启动Hive-Cli时候，就会报错”Table ‘hive.version’ doesn’t exist”。</p><h1 id="hive数据库相关的元数据表dbs-database_params"><a href="#Hive数据库相关的元数据表（DBS、DATABASE-PARAMS）" class="headerlink" title="Hive数据库相关的元数据表（DBS、DATABASE_PARAMS）"></a>Hive数据库相关的元数据表（DBS、DATABASE_PARAMS）</h1><h2 id="dbs"><a href="#DBS" class="headerlink" title="DBS"></a>DBS</h2><p>DBS表存储的是hive中所有库的基本信息</p><table><thead><tr><th>DB_ID</th><th>DESC</th><th>DB_LOCATION_URI</th><th>NAME</th><th>OWNER_NAME</th><th>OWNER_TYPE</th></tr></thead><tbody><tr><td>1</td><td>Default Hive database</td><td>hdfs:&#x2F;&#x2F;localhost:8020&#x2F;user&#x2F;hive&#x2F;warehouse</td><td>default</td><td>public</td><td>ROLE</td></tr><tr><td>6</td><td></td><td>hdfs:&#x2F;&#x2F;localhost:8020&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;test.db</td><td>test</td><td>llye</td><td>USER</td></tr></tbody></table><h2 id="database_params"><a href="#DATABASE-PARAMS" class="headerlink" title="DATABASE_PARAMS"></a>DATABASE_PARAMS</h2><p>DATABASE_PARAMS表存储数据库的相关参数，在CREATE DATABASE时候用<code>WITH DBPROPERTIES(property_name=property_value, …)</code>指定的参数。</p><p>表字段有：<code>DB_ID</code>、<code>PARAM_KEY</code>、<code>PARAM_VALUE</code></p><h1 id="hive表和视图相关的元数据表tbls-table_params-tbl_privs"><a href="#Hive表和视图相关的元数据表（TBLS、TABLE-PARAMS、TBL-PRIVS）" class="headerlink" title="Hive表和视图相关的元数据表（TBLS、TABLE_PARAMS、TBL_PRIVS）"></a>Hive表和视图相关的元数据表（TBLS、TABLE_PARAMS、TBL_PRIVS）</h1><h2 id="tbls"><a href="#TBLS" class="headerlink" title="TBLS"></a>TBLS</h2><p>TBLS表存储了表&#x2F;视图的基本信息，表字段有：<code>TBL_ID </code>、<code>CREATE_TIME </code>、<code>DB_ID</code>、<code>LAST_ACCESS_TIME</code>(上次访问时间)、<code>OWNER</code>、<code>RETENTION</code>(保留字段)、<code>SD_ID</code>(序列化配置信息)、<code>TBL_NAME</code>、<code>TBL_TYPE</code>、<code>VIEW_EXPANDED_TEXT</code>(视图的详细HQL语句)、<code>VIEW_ORIGINAL_TEXT</code>(视图的原始HQL语句)。</p><table><thead><tr><th>TBL_ID</th><th>CREATE_TIME</th><th>DB_ID</th><th>LAST_ACCESS_TIME</th><th>OWNER</th><th>RETENTION</th><th>SD_ID</th><th>TBL_NAME</th><th>TBL_TYPE</th><th>VIEW_EXPANDED_TEXT</th><th>VIEW_ORIGINAL_TEXT</th><th>IS_REWRITE_ENABLED</th></tr></thead><tbody><tr><td>2</td><td>1678874852</td><td>1</td><td>0</td><td>llye</td><td>0</td><td>2</td><td>student</td><td>MANAGED_TABLE</td><td></td><td></td><td>0</td></tr><tr><td>13</td><td>1683273717</td><td>6</td><td>0</td><td>llye</td><td>0</td><td>13</td><td>travel_data</td><td>MANAGED_TABLE</td><td></td><td></td><td>0</td></tr><tr><td>16</td><td>1684216889</td><td>1</td><td>0</td><td>llye</td><td>0</td><td>16</td><td>test_query</td><td>VIRTUAL_VIEW</td><td>(¶select¶`travel_data`.`province`, `travel_data`.`city`, `travel_data`.`attraction`, `travel_data`.`star_level`, `travel_data`.`price`, `travel_data`.`sales`, `travel_data`.`sale_date`¶from¶ `test`.`travel_data`)</td><td>(¶select¶ *¶from¶ test.travel_data)</td><td>0</td></tr></tbody></table><h2 id="table_params"><a href="#TABLE-PARAMS" class="headerlink" title="TABLE_PARAMS"></a>TABLE_PARAMS</h2><p>TABLE_PARAMS表存储了表&#x2F;视图的属性信息，表字段有：<code>TBL_ID</code>、<code>PARAM_KEY</code>(totalSize,numRows,EXTERNAL)、<code>PARAM_VALUE</code></p><table><thead><tr><th>TBL_ID</th><th>PARAM_KEY</th><th>PARAM_VALUE</th></tr></thead><tbody><tr><td>2</td><td>COLUMN_STATS_ACCURATE</td><td>{“BASIC_STATS”:”true”}</td></tr><tr><td>2</td><td>numFiles</td><td>1</td></tr><tr><td>2</td><td>numRows</td><td>1</td></tr><tr><td>2</td><td>rawDataSize</td><td>5</td></tr><tr><td>2</td><td>totalSize</td><td>6</td></tr><tr><td>2</td><td>transient_lastDdlTime</td><td>1678874879</td></tr><tr><td>13</td><td>COLUMN_STATS_ACCURATE</td><td>{“BASIC_STATS”:”true”}</td></tr><tr><td>13</td><td>numFiles</td><td>1</td></tr><tr><td>13</td><td>numRows</td><td>11</td></tr><tr><td>13</td><td>rawDataSize</td><td>597</td></tr><tr><td>13</td><td>totalSize</td><td>608</td></tr><tr><td>13</td><td>transient_lastDdlTime</td><td>1683273753</td></tr><tr><td>16</td><td>transient_lastDdlTime</td><td>1684216889</td></tr></tbody></table><h2 id="tbl_privs"><a href="#TBL-PRIVS" class="headerlink" title="TBL_PRIVS"></a>TBL_PRIVS</h2><p>TBL_PRIVS表存储了表&#x2F;视图的授权信息，表字段有：<code>TBL_GRANT_ID</code>、<code>CREATE_TIME</code>、<code>GRANT_OPTION</code>、<code>GRANTOR</code>(授权执行用户)、<code>GRANTOR_TYPE</code>、<code>PRINCIPAL_NAME</code>(被授权用户)、<code>PRINCIPAL_TYPE</code>、<code>TBL_PRIV</code>、<code>TBL_ID</code></p><table><thead><tr><th>TBL_GRANT_ID</th><th>CREATE_TIME</th><th>GRANT_OPTION</th><th>GRANTOR</th><th>GRANTOR_TYPE</th><th>PRINCIPAL_NAME</th><th>PRINCIPAL_TYPE</th><th>TBL_PRIV</th><th>TBL_ID</th></tr></thead><tbody><tr><td>5</td><td>1678874852</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>INSERT</td><td>2</td></tr><tr><td>6</td><td>1678874852</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>SELECT</td><td>2</td></tr><tr><td>7</td><td>1678874852</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>UPDATE</td><td>2</td></tr><tr><td>8</td><td>1678874852</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>DELETE</td><td>2</td></tr><tr><td>39</td><td>1683273717</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>INSERT</td><td>13</td></tr><tr><td>40</td><td>1683273717</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>SELECT</td><td>13</td></tr><tr><td>41</td><td>1683273717</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>UPDATE</td><td>13</td></tr><tr><td>42</td><td>1683273717</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>DELETE</td><td>13</td></tr><tr><td>46</td><td>1684216889</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>INSERT</td><td>16</td></tr><tr><td>47</td><td>1684216889</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>SELECT</td><td>16</td></tr><tr><td>48</td><td>1684216889</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>UPDATE</td><td>16</td></tr><tr><td>49</td><td>1684216889</td><td>1</td><td>llye</td><td>USER</td><td>llye</td><td>USER</td><td>DELETE</td><td>16</td></tr></tbody></table><h1 id="hive文件存储信息相关的元数据表sds-sd_params-serdes-serde_params"><a href="#Hive文件存储信息相关的元数据表（SDS、SD-PARAMS、SERDES、SERDE-PARAMS）" class="headerlink" title="Hive文件存储信息相关的元数据表（SDS、SD_PARAMS、SERDES、SERDE_PARAMS）"></a>Hive文件存储信息相关的元数据表（SDS、SD_PARAMS、SERDES、SERDE_PARAMS）</h1><p>由于HDFS支持的文件格式很多，而建Hive表时候也可以指定各种文件格式，Hive在将HQL解析成MapReduce时候，需要知道去哪里，使用哪种格式去读写HDFS文件，而这些信息就保存在这几张表中。</p><h2 id="sds"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h2><p>SDS表保存文件存储的基本信息，如INPUT_FORMAT、OUTPUT_FORMAT、是否压缩等。TBLS表中的SD_ID与该表关联，可以获取Hive表的存储信息。</p><p>表字段有：<code>SD_ID</code>、<code>CD_ID</code>(字段信息id)、<code>INPUT_FORMAT</code>(文件输入格式)、<code>IS_COMPRESSED</code>(是否压缩)、<code>IS_STOREDASSUBDIRECTORIES</code>(是否以子目录存储)、<code>LOCATION</code>(HDFS路径)、<code>NUM_BUCKETS</code>(分桶数量)、<code>OUTPUT_FORMAT</code>(文件输出格式)、<code>SERDE_ID</code>(序列化类id)。</p><table><thead><tr><th>SD_ID</th><th>CD_ID</th><th>INPUT_FORMAT</th><th>IS_COMPRESSED</th><th>IS_STOREDASSUBDIRECTORIES</th><th>LOCATION</th><th>NUM_BUCKETS</th><th>OUTPUT_FORMAT</th><th>SERDE_ID</th></tr></thead><tbody><tr><td>2</td><td>2</td><td>org.apache.hadoop.mapred.TextInputFormat</td><td>0</td><td>0</td><td>hdfs:&#x2F;&#x2F;localhost:8020&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;student</td><td>-1</td><td>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</td><td>2</td></tr><tr><td>13</td><td>13</td><td>org.apache.hadoop.mapred.TextInputFormat</td><td>0</td><td>0</td><td>hdfs:&#x2F;&#x2F;localhost:8020&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;test.db&#x2F;travel_data</td><td>-1</td><td>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</td><td>13</td></tr><tr><td>16</td><td>16</td><td>org.apache.hadoop.mapred.TextInputFormat</td><td>0</td><td>0</td><td>NULL</td><td>-1</td><td>org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</td><td>16</td></tr></tbody></table><h2 id="sd_params"><a href="#SD-PARAMS" class="headerlink" title="SD_PARAMS"></a>SD_PARAMS</h2><p>SD_PARAMS表保存Hive存储的属性信息，在创建表时候使用<code>STORED BY ‘storage.handler.class.name’ [WITH SERDEPROPERTIES (…)</code>指定。</p><p>表字段有：<code>SD_ID</code>、<code>PARAM_KEY</code>、<code>PARAM_VALUE</code></p><h2 id="serdes"><a href="#SERDES" class="headerlink" title="SERDES"></a>SERDES</h2><p>SERDES表存储序列化使用的类信息</p><p>表字段有：<code>SERDE_ID</code>、<code>NAME</code>(序列化类别名)、<code>SLIB</code>(序列化类)。</p><table><thead><tr><th>SERDE_ID</th><th>NAME</th><th>SLIB</th></tr></thead><tbody><tr><td>2</td><td>NULL</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td></tr><tr><td>13</td><td>NULL</td><td>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td></tr><tr><td>16</td><td>NULL</td><td>NULL</td></tr></tbody></table><h2 id="serde_params"><a href="#SERDE-PARAMS" class="headerlink" title="SERDE_PARAMS"></a>SERDE_PARAMS</h2><p>SERDE_PARAMS表存储了hive表序列化的一些属性信息，比如:行、列分隔符</p><p>表字段有：<code>SERDE_ID</code>、<code>PARAM_KEY</code>、<code>PARAM_VALUE</code></p><table><thead><tr><th>SERDE_ID</th><th>PARAM_KEY</th><th>PARAM_VALUE</th></tr></thead><tbody><tr><td>2</td><td>serialization.format</td><td>1</td></tr><tr><td>13</td><td>serialization.format</td><td>1</td></tr></tbody></table><h1 id="hive表字段相关的元数据表columns_v2"><a href="#Hive表字段相关的元数据表（COLUMNS-V2）" class="headerlink" title="Hive表字段相关的元数据表（COLUMNS_V2）"></a>Hive表字段相关的元数据表（COLUMNS_V2）</h1><p>COLUMNS_V2表存储了hive表各字段的基本信息。</p><p>表字段有：<code>CD_ID</code>、<code>COMMENT</code>、<code>COLUMN_NAME</code>、<code>TYPE_NAME</code>(字段类型)、<code>INTEGER_IDX</code>(字段顺序)。</p><table><thead><tr><th>CD_ID</th><th>COMMENT</th><th>COLUMN_NAME</th><th>TYPE_NAME</th><th>INTEGER_IDX</th></tr></thead><tbody><tr><td>2</td><td>NULL</td><td>id</td><td>int</td><td>0</td></tr><tr><td>2</td><td>NULL</td><td>name</td><td>string</td><td>1</td></tr><tr><td>13</td><td>NULL</td><td>attraction</td><td>string</td><td>2</td></tr><tr><td>13</td><td>NULL</td><td>city</td><td>string</td><td>1</td></tr><tr><td>13</td><td>NULL</td><td>price</td><td>double</td><td>4</td></tr><tr><td>13</td><td>NULL</td><td>province</td><td>string</td><td>0</td></tr><tr><td>13</td><td>NULL</td><td>sale_date</td><td>string</td><td>6</td></tr><tr><td>13</td><td>NULL</td><td>sales</td><td>int</td><td>5</td></tr><tr><td>13</td><td>NULL</td><td>star_level</td><td>int</td><td>3</td></tr><tr><td>16</td><td>NULL</td><td>attraction</td><td>string</td><td>2</td></tr><tr><td>16</td><td>NULL</td><td>city</td><td>string</td><td>1</td></tr><tr><td>16</td><td>NULL</td><td>price</td><td>double</td><td>4</td></tr><tr><td>16</td><td>NULL</td><td>province</td><td>string</td><td>0</td></tr><tr><td>16</td><td>NULL</td><td>sale_date</td><td>string</td><td>6</td></tr><tr><td>16</td><td>NULL</td><td>sales</td><td>int</td><td>5</td></tr><tr><td>16</td><td>NULL</td><td>star_level</td><td>int</td><td>3</td></tr></tbody></table><h1 id="hive表分区相关的元数据表partitions-partition_keys-partition_key_vals-partition_params"><a href="#Hive表分区相关的元数据表（PARTITIONS、PARTITION-KEYS、PARTITION-KEY-VALS、PARTITION-PARAMS）" class="headerlink" title="Hive表分区相关的元数据表（PARTITIONS、PARTITION_KEYS、PARTITION_KEY_VALS、PARTITION_PARAMS）"></a>Hive表分区相关的元数据表（PARTITIONS、PARTITION_KEYS、PARTITION_KEY_VALS、PARTITION_PARAMS）</h1><h2 id="partitions"><a href="#PARTITIONS" class="headerlink" title="PARTITIONS"></a>PARTITIONS</h2><p>PARTITIONS表存储hive表分区的基本信息。</p><p>表字段有：<code>PART_ID</code>、<code>CREATE_TIME</code>、<code>LAST_ACCESS_TIME</code>、<code>PART_NAME</code>、<code>SD_ID</code>(分区存储ID)、<code>TBL_ID</code>、<code>LINK_TARGET_ID</code>。</p><table><thead><tr><th>PART_ID</th><th>CREATE_TIME</th><th>LAST_ACCESS_TIME</th><th>PART_NAME</th><th>SD_ID</th><th>TBL_ID</th></tr></thead><tbody><tr><td>1</td><td>1684221232</td><td>0</td><td>dt&#x3D;1</td><td>18</td><td>17</td></tr><tr><td>2</td><td>1684221294</td><td>0</td><td>dt&#x3D;2</td><td>19</td><td>17</td></tr></tbody></table><h2 id="partition_keys"><a href="#PARTITION-KEYS" class="headerlink" title="PARTITION_KEYS"></a>PARTITION_KEYS</h2><p>PARTITION_KEYS表存储hive表分区的字段信息。</p><p>表字段有：<code>TBL_ID</code>、<code>PKEY_COMMENT</code>、<code>PKEY_NAME</code>、<code>PKEY_TYPE</code>、<code>INTEGER_IDX</code>(分区字段顺序)。</p><table><thead><tr><th>TBL_ID</th><th>PKEY_COMMENT</th><th>PKEY_NAME</th><th>PKEY_TYPE</th><th>INTEGER_IDX</th></tr></thead><tbody><tr><td>17</td><td>NULL</td><td>dt</td><td>string</td><td>0</td></tr></tbody></table><h2 id="partition_key_vals"><a href="#PARTITION-KEY-VALS" class="headerlink" title="PARTITION_KEY_VALS"></a>PARTITION_KEY_VALS</h2><p>PARTITION_KEY_VALS表存储hive表分区字段值。</p><p>表字段有：<code>PART_ID</code>、<code>PART_KEY_VAL</code>(分区字段值)、<code>INTEGER_IDX</code>(分区字段值顺序)。</p><table><thead><tr><th>PART_ID</th><th>PART_KEY_VAL</th><th>INTEGER_IDX</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>0</td></tr><tr><td>2</td><td>2</td><td>0</td></tr></tbody></table><h2 id="partition_params"><a href="#PARTITION-PARAMS" class="headerlink" title="PARTITION_PARAMS"></a>PARTITION_PARAMS</h2><p>PARTITIONS表存储hive表分区的属性信息。</p><p>表字段有：<code>PART_ID</code>、<code>PARAM_KEY</code>(numFiles，numRows)、<code>PARAM_VALUE</code>。</p><table><thead><tr><th>PART_ID</th><th>PARAM_KEY</th><th>PARAM_VALUE</th></tr></thead><tbody><tr><td>1</td><td>COLUMN_STATS_ACCURATE</td><td>{“BASIC_STATS”:”true”}</td></tr><tr><td>1</td><td>numFiles</td><td>1</td></tr><tr><td>1</td><td>numRows</td><td>11</td></tr><tr><td>1</td><td>rawDataSize</td><td>4290</td></tr><tr><td>1</td><td>totalSize</td><td>1221</td></tr><tr><td>1</td><td>transient_lastDdlTime</td><td>1684221233</td></tr><tr><td>2</td><td>COLUMN_STATS_ACCURATE</td><td>{“BASIC_STATS”:”true”}</td></tr><tr><td>2</td><td>numFiles</td><td>1</td></tr><tr><td>2</td><td>numRows</td><td>4</td></tr><tr><td>2</td><td>rawDataSize</td><td>1564</td></tr><tr><td>2</td><td>totalSize</td><td>1040</td></tr><tr><td>2</td><td>transient_lastDdlTime</td><td>1684221294</td></tr></tbody></table><h1 id="其他不常用的元数据表"><a href="#其他不常用的元数据表" class="headerlink" title="其他不常用的元数据表"></a>其他不常用的元数据表</h1><p>DB_PRIVS：数据库权限信息表。通过GRANT语句对数据库授权后，将会在这里存储。<br>IDXS：索引表，存储Hive索引相关的元数据。<br>INDEX_PARAMS：索引相关的属性信息。<br>TBL_COL_STATS：表字段的统计信息。使用ANALYZE语句对表字段分析后记录在这里。<br>TBL_COL_PRIVS：表字段的授权信息。<br>PART_PRIVS：分区的授权信息。<br>PART_COL_PRIVS：分区字段的权限信息。<br>PART_COL_STATS：分区字段的统计信息。<br>FUNCS：用户注册的函数信息。<br>FUNC_RU：用户注册函数的资源信息。<br>……  </p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzA3ODUxMzQxMA==&mid=2663993556&idx=1&sn=0e5291bd63426d747f32a7fd05128caa&scene=21#wechat_redirect">Hive 元数据表结构详解</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;hive元数据信息通常存储在关系型数据库，常见的是MySQL数据库。hive元数据信息存储在MySQL库的57张表中。&lt;br&gt;&lt;img src=&quot;https://i.328888.xyz/2023/05/16/Vi0EjJ.png&quot; alt=&quot;Vi0EjJ.png&quot;&gt;&lt;/p</summary>
      
    
    
    
    <category term="hive" scheme="https://llye-hub.github.io/categories/hive/"/>
    
    
    <category term="hive元数据" scheme="https://llye-hub.github.io/tags/hive%E5%85%83%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>算法性能分析之时间和空间复杂度</title>
    <link href="https://llye-hub.github.io/posts/d1fda56a.html"/>
    <id>https://llye-hub.github.io/posts/d1fda56a.html</id>
    <published>2023-05-12T07:42:59.000Z</published>
    <updated>2023-06-28T02:03:26.123Z</updated>
    
    <content type="html"><![CDATA[<p>关于时间复杂度和空间复杂度，刷过一些算法题后多少知道一点，比如单层for循环的时间复杂度为O(n)、数组变量的空间复杂度为O(n)，但是提到大O是什么就说不清了，而且涉及到一些复杂代码时，也说不清时间和空间复杂度。</p><p>首先解释下，这里<strong>大O用来表示算法的一般执行性能</strong>，大多情况下，它是算法的最坏情况下的执行性能，比如：插入排序的时间复杂度都说是O(n^2)。</p><h1 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h1><p>时间复杂度是一个函数，它定性描述该算法的运行时间。更详细的解释可以参见<a href="https://programmercarl.com/%E5%89%8D%E5%BA%8F/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%8C%E4%BD%A0%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E9%83%BD%E5%9C%A8%E8%BF%99%E9%87%8C%EF%BC%81.html#%E7%A9%B6%E7%AB%9F%E4%BB%80%E4%B9%88%E6%98%AF%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6">这篇文章</a>  </p><p>大数据规模的情况下，算法时间复杂度的排行如下：  </p><blockquote><p>O(1)常数阶 &lt; O(logn)对数阶 &lt; O(n)线性阶 &lt; O(nlogn)线性对数阶 &lt; O(n^2)平方阶 &lt; O(n^3)立方阶 &lt; O(2^n)指数阶</p></blockquote><p><strong>举一个例子：</strong> 找出n个字符串中相同的两个字符串（假设这里只有两个相同的字符串）</p><p><strong>解法一：暴力枚举</strong><br>双层遍历所有字符串比较，一般可能认为时间复杂度为O(n^2)。但其实这里忽略了字符串比较的时间消耗，因为字符串比较是按字典序逐位比较，长度为m的字符串比较的时间复杂度为O(m)，所以暴力枚举的时间复杂度应该是O(m×n×n)。</p><p><strong>解法二：所有字符串排序后遍历</strong><br>先对n个字符串按字典序进行排序，排序后相同的两个字符串一定是挨着的，只要再遍历一遍n个字符串就能找到。</p><p>如果用快速排序算法，再加上长度为m的字符串比较，排序步骤的时间复杂度为O(m×nlogn)，遍历步骤的时间复杂度为O(m×n)，所以总的时间复杂度为O(m×nlogn + m×n)，简化后的时间复杂度为O(m×nlogn)。</p><p>很明显O(m×nlogn)是要优于O(m×n×n)的。</p><p><strong>强调下上面两种解法仅做时间复杂度说明，非题目最佳解。</strong></p><p><strong>递归算法的时间复杂度：</strong> 本质上是 <strong>递归的次数 * 每次递归中的操作次数</strong> 。</p><p>比如题目：求x的n次方，用for循环的解法时间复杂度是O(n)，那么如果用递归写法呢？一定是O(logn)吗？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function2</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>; <span class="comment">// return 1 同样是因为0次方是等于1的</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> function2(x, n - <span class="number">1</span>) * x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码层面看，递归了n次，每次进行乘法操作，所以上面代码的时间复杂度为O(n*1)&#x3D;O(n)，和for循环写法没有差别。那么O(logn)的实现应该是怎样的？</p><p>先看下面这段代码，</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function3</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span>) <span class="keyword">return</span> x;</span><br><span class="line">    <span class="keyword">if</span> (n % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> function3(x, n / <span class="number">2</span>) * function3(x, n / <span class="number">2</span>)*x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> function3(x, n / <span class="number">2</span>) * function3(x, n / <span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码中有两处递归调用。假设n&#x3D;16，将上面代码的计算过程抽象为二叉树效果如下：</p><p><img src="https://i.328888.xyz/2023/05/15/VZGP4V.png" alt="VZGP4V.png"></p><p>从图中可以看到，共有n-1个节点，也就是说做了n-1次乘法操作，所以时间复杂度还是O(n-1)&#x3D;O(n)。其实，只要再做个小改动就能实现时间复杂度O(logn)的效果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function4</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span> (n == <span class="number">1</span>) <span class="keyword">return</span> x;</span><br><span class="line"><span class="type">int</span> <span class="variable">t</span> <span class="operator">=</span> function4(x, n / <span class="number">2</span>);<span class="comment">// 这里相对于function3，是把这个递归操作抽取出来，减少了重复计算</span></span><br><span class="line"><span class="keyword">if</span> (n % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> t * t * x;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> t * t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码中，仅有一个调用，且每次都是 n&#x2F;2，所以一共调用了 log以2为底n的对数次，再着每次递归做了一次乘法操作，所以时间复杂度为O(logn*1)&#x3D;O(logn)。</p><h1 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h1><p>空间复杂度是一个算法在运行过程中占用内存空间大小的量度，利用程序的空间复杂度，可以对程序运行中需要多少内存有个预先估计。空间复杂度(Space Complexity)记作 S(n) 依然使用大O来表示。递归算法的空间复杂度 &#x3D; 每次递归的空间复杂度 * 递归深度</p><p>常量的空间复杂度为O(1)，一维数组的空间复杂度为O(n)，二维数组的空间复杂度为O(n^2)……</p><p>那么，什么情况下，空间复杂度会是O(logn)呢？情况特殊些，一般出现在递归算法中。</p><p><strong>举例分析：斐波那契数列</strong></p><p>常规写法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">fibonacci</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">       <span class="keyword">if</span>(i &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">if</span>(i == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">       <span class="keyword">return</span> fibonacci(i-<span class="number">1</span>) + fibonacci(i-<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设i&#x3D;5，计算过程抽象为二叉树效果如下：</p><p><img src="https://i.328888.xyz/2023/05/15/VZhUDo.png" alt="VZhUDo.png"></p><p>每次递归中需要的空间是一个常量，并不会随着n的变化而变化，每次递归的空间复杂度就是O(1)。递归第n个斐波那契数的话，递归调用栈的深度是n。所以，上面代码的空间复杂度为O(1*n)&#x3D;O(n)。</p><p>根据树的结点来看，时间复杂度为O(2^n)，随着n的增大，计算时间消耗呈指数上升，这样的性能是最差的。究其原因，代码中调用了2次递归，导致复杂度非常大，从这个角度，可以做如下优化：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">fibonacci</span><span class="params">(<span class="type">int</span> first, <span class="type">int</span> second, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (n == <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> first + second;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fibonacci(second, first + second, n - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码中用两个常量来记录当前相加的两个数值，仅有一次递归调用，时间复杂度为O(n)。  </p><p>因为递归的深度依然是n，每次递归所需的空间也是常数，所以空间复杂度依然是O(n)。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://programmercarl.com/">算法性能分析</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;关于时间复杂度和空间复杂度，刷过一些算法题后多少知道一点，比如单层for循环的时间复杂度为O(n)、数组变量的空间复杂度为O(n)，但是提到大O是什么就说不清了，而且涉及到一些复杂代码时，也说不清时间和空间复杂度。&lt;/p&gt;
&lt;p&gt;首先解释下，这里&lt;strong&gt;大O用来表示</summary>
      
    
    
    
    <category term="练习笔记" scheme="https://llye-hub.github.io/categories/%E7%BB%83%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>hexo+GitHub自建博客遇到的问题</title>
    <link href="https://llye-hub.github.io/posts/69a95f3b.html"/>
    <id>https://llye-hub.github.io/posts/69a95f3b.html</id>
    <published>2023-05-08T06:48:01.000Z</published>
    <updated>2023-05-08T06:49:22.520Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_45149481/article/details/116794535">hexo文章目录点击不跳转，html没有生成href</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_45149481/article/details/116794535&quot;&gt;hexo文章目录点击不跳转，html没有生成href&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    
    <category term="hexo" scheme="https://llye-hub.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>hiveSQL之理解explain参数</title>
    <link href="https://llye-hub.github.io/posts/2369b6cf.html"/>
    <id>https://llye-hub.github.io/posts/2369b6cf.html</id>
    <published>2023-05-08T03:16:49.000Z</published>
    <updated>2023-05-08T08:27:00.383Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain">hive官方文档说明</a></p><p><strong>关键字</strong> <code>EXPLAIN</code></p><p><strong>语法：</strong> <code>EXPLAIN [EXTENDED|DEPENDENCY|AUTHORIZATION|VECTORIZATION|ANALYZE] query</code>（<code>hive2.3.9</code>版本支持）  </p><ul><li>EXPLAIN EXTENDED是EXPLAIN的扩展，能展示更加详细的信息。除了EXPLAIN打印出的内容，还包括每个标的HDFS读取路径，每个HIVE表的配置信息等，可以查看出表是否被全表扫描。</li><li>EXPLAIN DEPENDENCY用于描述一段sql需要的数据来源，输出的是一个json格式的数据，里面包含一下两个部分的内容，<br>input_partitions：描述一段sql依赖的数据来源表分区，里面存储的分区名的列表，格式如下：<br>{“partitionname”:“库名@表名 @分区列&#x3D;分区列的值”} ，如果整段sql包含的所有表都是是非分区表，则显示为空。<br>input_table：描述一段sql依赖的数据来源表，里面存储的是HIVE表名的列表格式如下：<br>{“tablename”:“库名@表名 ”，“tabletype”：表的类型（外部表&#x2F;内部表）}</li><li>EXPLAIN ANALYZE是EXPLAIN的扩展。EXPLAIN的信息中标示的是预估扫描行数，EXPLAIN ANALYZE但展示信息中也标示了实际扫描行数，格式为：<code>Num rows: (estimated row count)/(actual row count)</code></li></ul><p>**执行计划包含三部分内容: **</p><ul><li>查询sql的抽象语法树</li><li>所有stage之间的依赖关系</li><li>每个stage的具体描述</li></ul><p><strong>参数解释</strong></p><ul><li><p>MapReduce: 表示当前任务执行所用的计算机引擎是MapReduce  </p></li><li><p>Map Operator Tree: 表示当前描述的Map阶段执行的操作信息。</p><ul><li>TableScan: 表示对关键字alias声明的结果集。这里代指表明。</li><li>Statistics: 表示对当前阶段的统计信息。例如数据行数和数据量，这两个都是预估值。</li><li>Filter Operator: 表示在之前操作（TableScan）的结果集上进行数据的过滤。</li><li>Predicate: 表示Filter Operator进行过滤时候使用的谓词，例如 pt_dt &#x3D; 2020-11-11</li><li>Select Operator: 表示在之前的结果集上对列进行投影，即列筛选。<ul><li>Expressions: 表示需要投影的列，即筛选的列。</li><li>OutputColNames: 表示输出的列名。</li><li>Group By Operator: 表示在之前的结果集上分组聚合。<ul><li>keys: 表示分组的列。</li><li>mode[aggregations]: 表示分组聚合使用的算法.例如 count（）。</li><li>Reduce Output Operator: 表示当前描述的是对之前的结果聚合后的输出信息，这里表示Map端聚合后的信息。<ul><li>key expressions&#x2F;value expressions: MapReduce计算引擎，在Map阶段和Reduce阶段输出的都是键-值对的形式，这里key expression和 key expression 和 value expression 分别描述的就是Map阶段输出的键（key） 和值（value）所用的数据列。key expression指代的就是聚合列。 value expression 指代的就是 聚合的函数。</li><li>sort order：表示输出是否进行排序，每个<code>+</code>表示正序排序的一列，每个<code>-</code>表示倒序排序的一列。</li><li>Map-Reduce partition columns: 表示Map阶段输出到Reduce阶段的分区列。在HIVE-SQL中可以用distribute by 指代分区的列。</li></ul></li></ul></li></ul></li></ul></li><li><p>Reduce Operator Tree: 表示当前描述的Reduce阶段执行的操作信息。<br>  Reduce 阶段关键字和Map阶段的含义一样，不同的如下：</p></li><li><p>compressed: 在 File output operator中这个关键词表示文件输出的结果是否进行压缩，FALSE表示不进行输出压缩。</p></li><li><p>table: 表示正在操作的表。</p></li><li><p>input format&#x2F;out putformat: 分别表示文件输入和输出的文件类型。</p></li><li><p>serde:表示读取表数据的序列化和反序列化的方式。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain&quot;&gt;hive官方文档说明&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键字&lt;/strong&gt; &lt;code&gt;EXPLAI</summary>
      
    
    
    
    <category term="hive" scheme="https://llye-hub.github.io/categories/hive/"/>
    
    
    <category term="hiveSQL" scheme="https://llye-hub.github.io/tags/hiveSQL/"/>
    
  </entry>
  
  <entry>
    <title>hiveSQL之groupBy语句增强语法grouping sets/CUBE/rollup</title>
    <link href="https://llye-hub.github.io/posts/67bc5d15.html"/>
    <id>https://llye-hub.github.io/posts/67bc5d15.html</id>
    <published>2023-05-05T06:01:45.000Z</published>
    <updated>2023-05-12T03:37:35.202Z</updated>
    
    <content type="html"><![CDATA[<p>本文详细整理了关于group by子句的增强聚合语法grouping sets&#x2F;CUBE&#x2F;rollup的具体用法，语法的<a href="https://cwiki.apache.org/confluence/display/Hive/Enhanced+Aggregation%2C+Cube%2C+Grouping+and+Rollup">hive官方介绍文档</a> 。</p><h1 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h1><p>首先声明使用的hive版本为 <code>2.3.9</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> if <span class="keyword">exists</span> travel_data;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> travel_data(</span><br><span class="line">      province string,</span><br><span class="line">      city string,</span><br><span class="line">      attraction string,</span><br><span class="line">      star_level <span class="type">int</span>,</span><br><span class="line">      Price <span class="keyword">double</span>,</span><br><span class="line">      sales <span class="type">int</span>,</span><br><span class="line">      sale_date string</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> travel_data</span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;河南省&#x27;</span>,<span class="string">&#x27;郑州市&#x27;</span>,<span class="string">&#x27;方特&#x27;</span>,<span class="number">4</span>,<span class="number">312.22</span>,<span class="number">15789</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;河南省&#x27;</span>,<span class="string">&#x27;郑州市&#x27;</span>,<span class="string">&#x27;二七广场&#x27;</span>,<span class="number">4</span>,<span class="number">0</span>,<span class="number">5942</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;河南省&#x27;</span>,<span class="string">&#x27;郑州市&#x27;</span>,<span class="string">&#x27;河南省博物馆&#x27;</span>,<span class="number">4</span>,<span class="number">1.22</span>,<span class="number">943</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;河南省&#x27;</span>,<span class="string">&#x27;洛阳市&#x27;</span>,<span class="string">&#x27;白云山&#x27;</span>,<span class="number">4</span>,<span class="number">324.44</span>,<span class="number">16843</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;河南省&#x27;</span>,<span class="string">&#x27;洛阳市&#x27;</span>,<span class="string">&#x27;白马寺&#x27;</span>,<span class="number">4</span>,<span class="number">23.45</span>,<span class="number">2567</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;河南省&#x27;</span>,<span class="string">&#x27;洛阳市&#x27;</span>,<span class="string">&#x27;龙门石窟&#x27;</span>,<span class="number">4</span>,<span class="number">45</span>,<span class="number">15784</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;广东省&#x27;</span>,<span class="string">&#x27;深圳市&#x27;</span>,<span class="string">&#x27;东部华侨城&#x27;</span>,<span class="number">4</span>,<span class="number">86</span>,<span class="number">9523</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;广东省&#x27;</span>,<span class="string">&#x27;深圳市&#x27;</span>,<span class="string">&#x27;欢乐谷&#x27;</span>,<span class="number">4</span>,<span class="number">54</span>,<span class="number">2573</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;广东省&#x27;</span>,<span class="string">&#x27;深圳市&#x27;</span>,<span class="string">&#x27;世界之窗&#x27;</span>,<span class="number">4</span>,<span class="number">34</span>,<span class="number">5644</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;广东省&#x27;</span>,<span class="string">&#x27;广州市&#x27;</span>,<span class="string">&#x27;长隆&#x27;</span>,<span class="number">4</span>,<span class="number">46</span>,<span class="number">25673</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;广东省&#x27;</span>,<span class="string">&#x27;广州市&#x27;</span>,<span class="string">&#x27;广州塔&#x27;</span>,<span class="number">4</span>,<span class="number">35</span>,<span class="number">9735</span>,<span class="string">&#x27;2019-02-03&#x27;</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure><h1 id="grouping-set语句"><a href="#grouping-set语句" class="headerlink" title="grouping set语句"></a>grouping set语句</h1><p>官方说明</p><blockquote><p>The GROUPING SETS clause in GROUP BY allows us to specify more than one GROUP BY option in the same record set. All GROUPING SET clauses can be logically expressed in terms of several GROUP BY queries connected by UNION. Table-1 shows several such equivalent statements. This is helpful in forming the idea of the GROUPING SETS clause. A blank set ( ) in the GROUPING SETS clause calculates the overall aggregate.</p></blockquote><p>grouping set子句可以实现对同一个数据集指定多个group by条件，适合多维聚合场景下使用。其执行效果等同于对多个group by查询进行union all操作。</p><p><code>SELECT a, b, SUM(c) FROM tab1 GROUP BY a, b GROUPING SETS ( (a,b) )</code>等同下面语句</p><blockquote><p>SELECT a, b, SUM(c) FROM tab1 GROUP BY a, b</p></blockquote><p><code>SELECT a, b, SUM( c ) FROM tab1 GROUP BY a, b GROUPING SETS ( (a, b), a, b, ( ) )</code>等同下面语句</p><blockquote><p>SELECT a, b, SUM( c ) FROM tab1 GROUP BY a, b<br>UNION<br>SELECT a, null, SUM( c ) FROM tab1 GROUP BY a, null<br>UNION<br>SELECT null, b, SUM( c ) FROM tab1 GROUP BY null, b<br>UNION<br>SELECT null, null, SUM( c ) FROM tab1</p></blockquote><p><strong>语法</strong></p><ol><li>grouping sets子句必须跟在group by语句后，且出现在grouping sets的字段必须出现在group by语句中，但是出现在group by中字段不一定要出现在grouping sets语句中</li><li>出现在group by中但是没有在grouping sets中的字段将会被赋值为null</li><li>grouping__id字段可以区分不同的聚合粒度，表示当前行数据数据哪个分组集合</li><li>grouping函数可以处理空值，grouping()接受一个列名作为参数，如果结果对应行使用了参数列做聚合，返回0，此时意味着NULL来自输入数据；否则返回1，此时意味着NULL是grouping sets的占位符。</li></ol><p><strong>测试sql：从省&amp;市聚合维度统计销售数量</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    td.province,</span><br><span class="line">    td.city,</span><br><span class="line">    IF(<span class="keyword">grouping</span>(td.city) <span class="operator">=</span> <span class="number">0</span>,td.city,<span class="string">&#x27;城市&#x27;</span>) <span class="keyword">as</span> city2, <span class="comment">-- 进行空值判断，替换输出更有实际意义的值</span></span><br><span class="line">    <span class="built_in">sum</span>(sales) <span class="keyword">as</span> sales,</span><br><span class="line">    grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    travel_data td</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    td.province,</span><br><span class="line">    td.city</span><br><span class="line">    <span class="keyword">grouping</span> SETS (td.province,td.city)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> grouping__id</span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>查询结果：</p><p><img src="https://i.328888.xyz/2023/05/05/iTpX0x.png" alt="iTpX0x.png"></p><ul><li>第一列按照province</li><li>第二列按照city</li><li>第三列按照city分组，并对空值进行替换</li><li>第四列按照province或city分组，进行统计计算</li><li>第五列grouping__id表示当前行数据属于哪个分组，1表示province，2表示city</li></ul><p><strong>测试sql：从省&amp;市、省&amp;日期、省三个聚合维度统计销售数量</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">td.province ,</span><br><span class="line">td.city,</span><br><span class="line"><span class="built_in">sum</span>(sales) <span class="keyword">as</span> sales,</span><br><span class="line">td.sale_date ,</span><br><span class="line">grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">travel_data td</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">td.province ,</span><br><span class="line">td.city,</span><br><span class="line">td.sale_date</span><br><span class="line"><span class="keyword">grouping</span> SETS (</span><br><span class="line">(td.province , td.city)</span><br><span class="line">,(td.province, td.sale_date)</span><br><span class="line">,td.province </span><br><span class="line">)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">grouping__id</span><br></pre></td></tr></table></figure><h1 id="cube语句"><a href="#CUBE语句" class="headerlink" title="CUBE语句"></a>CUBE语句</h1><p>CUBE函数跟group by语句一起使用，可以对group by的所有字段进行组合再进行聚合计算。</p><p><code>group by a,b,c with CUBE</code>执行效果等同于 <code>group by a, b, c grouping sets ( (a, b, c), (a, b), (b, c), (a, c), (a), (b), (c), ( ))</code></p><p><strong>测试sql</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    province ,</span><br><span class="line">    city,</span><br><span class="line">    <span class="built_in">sum</span>(sales) <span class="keyword">as</span> sales,</span><br><span class="line">    grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    travel_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    province,city</span><br><span class="line"><span class="keyword">with</span> <span class="keyword">CUBE</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    grouping__id</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 或者下面这种写法</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    province ,</span><br><span class="line">    city,</span><br><span class="line">    <span class="built_in">sum</span>(sales) <span class="keyword">as</span> sales,</span><br><span class="line">    grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    travel_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    <span class="keyword">CUBE</span>(province,city)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    grouping__id</span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>查询结果：</p><p><img src="https://i.328888.xyz/2023/05/06/iatksp.png" alt="iatksp.png"></p><p>从上面的结果数据可以看到，对聚合字段 <code>(province,city)</code>使用CUBE函数后，返回结果有4种聚合维度：<code>(province,city)</code>、<code>(province)</code>、<code>(city)</code>、<code>()</code></p><h1 id="rollup语句"><a href="#rollup语句" class="headerlink" title="rollup语句"></a>rollup语句</h1><p>rollup是CUBE的子集，以最左侧的维度为主，从该维度进行层级聚合，可以实现上钻和下钻的效果</p><p><code>group by a,b,c with rollup</code>假设层次结构是 “a “向下钻到 “b “向下钻到 “c”，执行效果等同于 <code>group by a, b, c grouping sets ( (a, b, c), (a, b), (a), ( ))</code></p><p><strong>测试sql</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    province ,</span><br><span class="line">    city,</span><br><span class="line">    sale_date ,</span><br><span class="line">    <span class="built_in">sum</span>(sales) <span class="keyword">as</span> sales,</span><br><span class="line">    grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    travel_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    province,city,sale_date</span><br><span class="line"><span class="keyword">with</span> <span class="keyword">rollup</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">    grouping__id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 或者下面这种写法</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">province ,</span><br><span class="line">city,</span><br><span class="line">sale_date ,</span><br><span class="line"><span class="built_in">sum</span>(sales) <span class="keyword">as</span> sales,</span><br><span class="line">grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">travel_data </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line"><span class="keyword">rollup</span>(province,city,sale_date)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">grouping__id</span><br></pre></td></tr></table></figure><p>查询结果：</p><p><img src="https://i.328888.xyz/2023/05/06/iakvoL.png" alt="iakvoL.png"></p><p>从上面的结果数据可以看到，对聚合字段 <code>(province,city,sale_date)</code>使用rollup函数后，返回结果有4种聚合维度：<code>(province,city,sale_date)</code>、<code>(province,city)</code>、<code>(province)</code>、<code>()</code></p><h1 id="grouping__id计算方法"><a href="#grouping-id计算方法" class="headerlink" title="grouping__id计算方法"></a>grouping__id计算方法</h1><p>从rollup函数的例子可以看到，grouping__id的数值并不是连续的，下面总结下grouping__id计算方法</p><ol><li>按group by语句的字段顺序（不理解网上有说法是按字段倒序排序）。所以这里要注意groupby字段顺序变化是会影响grouping__id计算结果的。</li><li>对于每个字段，若出现在了当前粒度中，则该字段位置赋值为0，否则为1。</li><li>这样就形成了一个二进制数，将这个二进制数转为十进制，即为当前粒度对应的 grouping__id。</li></ol><p>以统计粒度 <code>group by province,city,sale_date</code>为例，</p><ul><li>字段顺序为:province,city,sale_date</li><li>所有聚合维度对应的二进制数为：</li></ul><table><thead><tr><th align="center">grouping sets</th><th align="center">按字段顺序赋值二进制数</th><th align="center">转换为十进制的grouping__id</th></tr></thead><tbody><tr><td align="center">province,city,sale_date</td><td align="center">000</td><td align="center">0</td></tr><tr><td align="center">province,city</td><td align="center">001</td><td align="center">1</td></tr><tr><td align="center">province,sale_date</td><td align="center">010</td><td align="center">2</td></tr><tr><td align="center">province</td><td align="center">011</td><td align="center">3</td></tr><tr><td align="center">city,sale_date</td><td align="center">100</td><td align="center">4</td></tr><tr><td align="center">city</td><td align="center">101</td><td align="center">5</td></tr><tr><td align="center">sale_date</td><td align="center">110</td><td align="center">6</td></tr><tr><td align="center">无</td><td align="center">111</td><td align="center">7</td></tr></tbody></table><p><strong>测试sql：</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">td.province ,</span><br><span class="line">city,</span><br><span class="line">td.sale_date ,</span><br><span class="line"><span class="built_in">sum</span>(sales) <span class="keyword">as</span> sales,</span><br><span class="line">grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">travel_data td</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line"><span class="keyword">CUBE</span>(td.province,td.city,td.sale_date)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span></span><br><span class="line">grouping__id</span><br></pre></td></tr></table></figure><p>查询结果：</p><p><img src="https://i.328888.xyz/2023/05/05/iT55Jb.png" alt="iT55Jb.png"></p><p>从上面的结果可以看到，grouping__id的数值与计算规则得出来的一致。hive2.3版本前关于grouping__id的计算方式可能不同，可以参见<a href="https://blog.csdn.net/Dax1n/article/details/104308886">其他博客</a></p><h1 id="grouping-sets和union-all性能对比"><a href="#grouping-sets和union-all性能对比" class="headerlink" title="grouping sets和union all性能对比"></a>grouping sets和union all性能对比</h1><p><strong>实现逻辑</strong><br>如果说 <code>union all</code>是先聚合再联合，那么 <code>grouping sets</code>就是先联合再聚合。<code>grouping sets</code>根据 <code>N</code>个分组对每条数据进行计算，不在当前分组的字段置为null，将数据量扩展成原来的 <code>N</code>倍，再按 <code>group by</code>的字段做聚合计算。</p><p><code>group by province,city grouping sets ((province,city),province,())</code>计算效果图如下：</p><p><img src="https://i.328888.xyz/2023/05/06/iacyut.png" alt="iacyut.png"></p><p><code>…… group by province,city union all …… group by province</code>计算效果图如下：</p><p><img src="https://i.328888.xyz/2023/05/06/iaRuvE.png" alt="iaRuvE.png"></p><p>分析源码，grouping__id在process的时候将newKeysGroupingSets的值赋予具体的行</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org/apache/hadoop/hive/ql/exec/GroupByOperator.java</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(Object row, <span class="type">int</span> tag)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">……</span><br><span class="line">    <span class="keyword">if</span> (groupingSetsPresent) &#123;</span><br><span class="line">    Object[] newKeysArray = newKeys.getKeyArray();</span><br><span class="line">    Object[] cloneNewKeysArray = <span class="keyword">new</span> <span class="title class_">Object</span>[newKeysArray.length];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">keyPos</span> <span class="operator">=</span> <span class="number">0</span>; keyPos &lt; groupingSetsPosition; keyPos++) &#123;</span><br><span class="line">    cloneNewKeysArray[keyPos] = newKeysArray[keyPos];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">groupingSetPos</span> <span class="operator">=</span> <span class="number">0</span>; groupingSetPos &lt; groupingSets.size(); groupingSetPos++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">keyPos</span> <span class="operator">=</span> <span class="number">0</span>; keyPos &lt; groupingSetsPosition; keyPos++) &#123;</span><br><span class="line">    newKeysArray[keyPos] = <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">FastBitSet</span> <span class="variable">bitset</span> <span class="operator">=</span> groupingSetsBitSet[groupingSetPos];</span><br><span class="line">    <span class="comment">// Some keys need to be left to null corresponding to that grouping set.</span></span><br><span class="line">    <span class="comment">// 按照bitSet保留原值，对于group by a, b, c 如果bitSet是010，则表示keyPos为0和2就表示ClearBit，需要保留原值，1其他就为null</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">keyPos</span> <span class="operator">=</span> bitset.nextClearBit(<span class="number">0</span>); keyPos &lt; groupingSetsPosition;</span><br><span class="line">          keyPos = bitset.nextClearBit(keyPos+<span class="number">1</span>)) &#123;</span><br><span class="line">          newKeysArray[keyPos] = cloneNewKeysArray[keyPos];</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">// 这里就是给当前这条数据赋予GROUPING_ID的值</span></span><br><span class="line">    newKeysArray[groupingSetsPosition] = newKeysGroupingSets[groupingSetPos];</span><br><span class="line">    processKey(row, rowInspector);</span><br><span class="line">    &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    processKey(row, rowInspector);</span><br><span class="line">    &#125;  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>下面通过执行计划分析两种方式的差异。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span></span><br><span class="line">    province,</span><br><span class="line">    city,</span><br><span class="line">    grouping__id</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    travel_data </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    province,</span><br><span class="line">    city</span><br><span class="line">    <span class="keyword">grouping</span> SETS ((province,city),province,())</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> grouping__id</span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>hive执行计划：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">Explain                                                                                                      |</span><br><span class="line">-------------------------------------------------------------------------------------------------------------+</span><br><span class="line">STAGE DEPENDENCIES:                                                                                          |</span><br><span class="line">  Stage-1 is a root stage                                                                                    |</span><br><span class="line">  Stage-2 depends on stages: Stage-1                                                                         |</span><br><span class="line">  Stage-0 depends on stages: Stage-2                                                                         |</span><br><span class="line">                                                                                                             |</span><br><span class="line">STAGE PLANS:                                                                                                 |</span><br><span class="line">  Stage: Stage-1                                                                                             |</span><br><span class="line">    Map Reduce                                                                                               |</span><br><span class="line">      Map Operator Tree:                                                                                     |</span><br><span class="line">          TableScan                                                                                          |</span><br><span class="line">            alias: travel_data                                                                               |</span><br><span class="line">            Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE                 |</span><br><span class="line">            Select Operator                                                                                  |</span><br><span class="line">              expressions: province (type: string), city (type: string)                                      |</span><br><span class="line">              outputColumnNames: _col0, _col1                                                                |</span><br><span class="line">              Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE               |</span><br><span class="line">              Group By Operator                                                                              |</span><br><span class="line">                keys: _col0 (type: string), _col1 (type: string), 0 (type: int)                              |</span><br><span class="line">                mode: hash                                                                                   |</span><br><span class="line">                outputColumnNames: _col0, _col1, _col2                                                       |</span><br><span class="line">                Statistics: Num rows: 33 Data size: 1791 Basic stats: COMPLETE Column stats: NONE            |  这里读取数据后按grouping sets的3个分组维度，将数据由11条扩充为33条</span><br><span class="line">                Reduce Output Operator                                                                       |</span><br><span class="line">                 ……</span><br><span class="line">      Reduce Operator Tree:                                                                                  |</span><br><span class="line">        Group By Operator                                                                                    |</span><br><span class="line">          keys: KEY._col0 (type: string), KEY._col1 (type: string), KEY._col2 (type: int)                    |</span><br><span class="line">          mode: mergepartial                                                                                 |</span><br><span class="line">          outputColumnNames: _col0, _col1, _col2                                                             |</span><br><span class="line">          Statistics: Num rows: 16 Data size: 868 Basic stats: COMPLETE Column stats: NONE                   |</span><br><span class="line">          Select Operator                                                                                    |</span><br><span class="line">            expressions: _col0 (type: string), _col1 (type: string), _col2 (type: int)                       |</span><br><span class="line">            outputColumnNames: _col0, _col1, _col2                                                           |</span><br><span class="line">            Statistics: Num rows: 16 Data size: 868 Basic stats: COMPLETE Column stats: NONE                 |</span><br><span class="line">            ……</span><br><span class="line">                                                                                                             |</span><br><span class="line">  Stage: Stage-2                                                                                             |</span><br><span class="line">    Map Reduce                                                                                               |</span><br><span class="line">      Map Operator Tree:                                                                                     |</span><br><span class="line">          TableScan                                                                                          |</span><br><span class="line">            Reduce Output Operator                                                                           |</span><br><span class="line">              key expressions: _col2 (type: int)                                                             |</span><br><span class="line">              sort order: +                                                                                  |</span><br><span class="line">              Statistics: Num rows: 16 Data size: 868 Basic stats: COMPLETE Column stats: NONE               |</span><br><span class="line">              value expressions: _col0 (type: string), _col1 (type: string)                                  |</span><br><span class="line">      Reduce Operator Tree:                                                                                  |</span><br><span class="line">        Select Operator                                                                                      |</span><br><span class="line">          expressions: VALUE._col0 (type: string), VALUE._col1 (type: string), KEY.reducesinkkey0 (type: int)|  这里KEY.reducesinkkey0即为grouping__id</span><br><span class="line">          outputColumnNames: _col0, _col1, _col2                                                             |</span><br><span class="line">          Statistics: Num rows: 16 Data size: 868 Basic stats: COMPLETE Column stats: NONE                   |</span><br><span class="line">          ……                                                                                        |</span><br><span class="line"> </span><br><span class="line">                                 |</span><br><span class="line">                                                                                                             |</span><br><span class="line">  Stage: Stage-0                                                                                             |</span><br><span class="line">    ……                                                                                   </span><br></pre></td></tr></table></figure><p>从上面的执行计划可以看到，<code>Stage-1</code>在读取数据时，在<code>map</code>阶段根据<code>grouping sets</code>有3个分组维度，将数据量扩充至原来的3倍，然后在<code>reduce</code>阶段做<code>group by province,city</code>操作。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">province,</span><br><span class="line">city</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">travel_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    province,city</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    province,</span><br><span class="line">    <span class="keyword">NULL</span> <span class="keyword">as</span> city</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">travel_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    province </span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>hive执行计划：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">Explain                                                                                           |</span><br><span class="line">--------------------------------------------------------------------------------------------------+</span><br><span class="line">STAGE DEPENDENCIES:                                                                               |</span><br><span class="line">  Stage-1 is a root stage                                                                         |</span><br><span class="line">  Stage-2 depends on stages: Stage-1, Stage-3                                                     |</span><br><span class="line">  Stage-3 is a root stage                                                                         |</span><br><span class="line">  Stage-0 depends on stages: Stage-2                                                              |</span><br><span class="line">                                                                                                  |</span><br><span class="line">STAGE PLANS:                                                                                      |</span><br><span class="line">  Stage: Stage-1                                                                                  |</span><br><span class="line">    Map Reduce                                                                                    |</span><br><span class="line">      Map Operator Tree:                                                                          |</span><br><span class="line">          TableScan                                                                               |</span><br><span class="line">            alias: travel_data                                                                    |</span><br><span class="line">            Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE      |</span><br><span class="line">            Select Operator                                                                       |</span><br><span class="line">              expressions: province (type: string), city (type: string)                           |</span><br><span class="line">              outputColumnNames: province, city                                                   |</span><br><span class="line">              Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE    |</span><br><span class="line">              Group By Operator                                                                   |</span><br><span class="line">                keys: province (type: string), city (type: string)                                |</span><br><span class="line">                mode: hash                                                                        |</span><br><span class="line">                outputColumnNames: _col0, _col1                                                   |</span><br><span class="line">                Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE  |  这里数据量没有变化</span><br><span class="line">                Reduce Output Operator                                                            |</span><br><span class="line">                  ……</span><br><span class="line">      Reduce Operator Tree:                                                                       |</span><br><span class="line">        Group By Operator                                                                         |</span><br><span class="line">          keys: KEY._col0 (type: string), KEY._col1 (type: string)                                |</span><br><span class="line">          mode: mergepartial                                                                      |</span><br><span class="line">          outputColumnNames: _col0, _col1                                                         |</span><br><span class="line">          Statistics: Num rows: 5 Data size: 271 Basic stats: COMPLETE Column stats: NONE         |</span><br><span class="line">          ……</span><br><span class="line">                                                                                                  |</span><br><span class="line">  Stage: Stage-2                                                                                  |</span><br><span class="line">    Map Reduce                                                                                    |</span><br><span class="line">      Map Operator Tree:                                                                          |</span><br><span class="line">          TableScan                                                                               |</span><br><span class="line">            Union                                                                                 |</span><br><span class="line">              Statistics: Num rows: 10 Data size: 542 Basic stats: COMPLETE Column stats: NONE    |</span><br><span class="line">              ……                  |</span><br><span class="line">          TableScan                                                                               |</span><br><span class="line">            Union                                                                                 |</span><br><span class="line">              Statistics: Num rows: 10 Data size: 542 Basic stats: COMPLETE Column stats: NONE    |</span><br><span class="line">              ……               </span><br><span class="line">  Stage: Stage-3                                                                                  |</span><br><span class="line">    Map Reduce                                                                                    |</span><br><span class="line">      Map Operator Tree:                                                                          |</span><br><span class="line">          TableScan                                                                               |</span><br><span class="line">            alias: travel_data                                                                    |</span><br><span class="line">            Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE      |</span><br><span class="line">            Select Operator                                                                       |</span><br><span class="line">              expressions: province (type: string)                                                |</span><br><span class="line">              outputColumnNames: province                                                         |</span><br><span class="line">              Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE    |</span><br><span class="line">              Group By Operator                                                                   |</span><br><span class="line">                keys: province (type: string)                                                     |</span><br><span class="line">                mode: hash                                                                        |</span><br><span class="line">                outputColumnNames: _col0                                                          |</span><br><span class="line">                Statistics: Num rows: 11 Data size: 597 Basic stats: COMPLETE Column stats: NONE  |  这里数据量没有变化</span><br><span class="line">                Reduce Output Operator                                                            |</span><br><span class="line">                  ……</span><br><span class="line">      Reduce Operator Tree:                                                                       |</span><br><span class="line">        Group By Operator                                                                         |</span><br><span class="line">          keys: KEY._col0 (type: string)                                                          |</span><br><span class="line">          mode: mergepartial                                                                      |</span><br><span class="line">          outputColumnNames: _col0                                                                |</span><br><span class="line">          Statistics: Num rows: 5 Data size: 271 Basic stats: COMPLETE Column stats: NONE         |</span><br><span class="line">            ……             </span><br><span class="line">                                                                                                  |</span><br><span class="line">  Stage: Stage-0                                                                                  |</span><br><span class="line">    ……                     </span><br></pre></td></tr></table></figure><p>从上面的执行计划可以看到，<code>Stage-1</code>和<code>Stage-3</code>都是读取数据，再分别按照<code>group by province,city</code>和<code>group by province</code>做聚合操作，最后在<code>Stage-2</code>做<code>union</code>操作合并数据。<code>union all</code>这种写法对表<code>travel_data</code>重复读取两次，查询性能上比<code>grouping sets</code>写法要差些。在集群空闲的情况下，对两种写法的sql分别执行5次，得到如下结果：</p><blockquote><p>grouping sets写法执行5次的耗时:</p><blockquote><p>select province, city, grouping__id from travel_data group by province, city grouping SETS ((province,city),province) order by grouping__id ;</p></blockquote><p>Time taken: 54.807 seconds, Fetched: 6 row(s)<br>Time taken: 56.261 seconds, Fetched: 6 row(s)<br>Time taken: 52.671 seconds, Fetched: 6 row(s)<br>Time taken: 62.945 seconds, Fetched: 6 row(s)<br>Time taken: 57.337 seconds, Fetched: 6 row(s)</p></blockquote><blockquote><p>union all写法执行5次的耗时:</p><blockquote><p>select province,city from travel_data group by province,city union all select province, NULL as city from travel_data group by province;</p></blockquote><p>Time taken: 83.91 seconds, Fetched: 6 row(s)<br>Time taken: 94.466 seconds, Fetched: 6 row(s)<br>Time taken: 86.253 seconds, Fetched: 6 row(s)<br>Time taken: 75.509 seconds, Fetched: 6 row(s)<br>Time taken: 88.633 seconds, Fetched: 6 row(s)</p></blockquote><p>可以算出，<code>grouping sets</code>写法的平均耗时为56.8s，<code>union all</code>写法的平均耗时为85.7s，耗时是前者的1.5倍。</p><p>所以，<code>grouping sets</code>写法的sql不仅在表达上更加简洁，在查询性能上也更加高效。</p><h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://juejin.cn/post/7223211123961200700">Hive分析函数详解：GROUPING SETS&#x2F;CUBE&#x2F;ROLLUP</a></p><p><a href="https://zhuanlan.zhihu.com/p/536981356">从源码深入理解 Spark SQL 中的 Grouping Sets 语句</a></p><p><a href="https://zhuanlan.zhihu.com/p/408391394">Hive虚拟列的生成与计算【1】</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文详细整理了关于group by子句的增强聚合语法grouping sets&amp;#x2F;CUBE&amp;#x2F;rollup的具体用法，语法的&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Enhanced+</summary>
      
    
    
    
    <category term="SQL" scheme="https://llye-hub.github.io/categories/SQL/"/>
    
    
    <category term="grouping sets" scheme="https://llye-hub.github.io/tags/grouping-sets/"/>
    
  </entry>
  
  <entry>
    <title>关于数据仓库建设的一些思考</title>
    <link href="https://llye-hub.github.io/posts/49066d40.html"/>
    <id>https://llye-hub.github.io/posts/49066d40.html</id>
    <published>2023-04-14T09:02:13.000Z</published>
    <updated>2023-05-09T09:36:46.989Z</updated>
    
    <content type="html"><![CDATA[<p>基于在海拍客的工作经历，沉淀了一些关于数据仓库的思考，没有框架，想到什么写什么</p><h1 id="数据仓库解决什么问题"><a href="#数据仓库解决什么问题？" class="headerlink" title="数据仓库解决什么问题？"></a>数据仓库解决什么问题？</h1><p>1、避免”烟囱式”开发，减少由于业务变化带来的维护成本<br>烟囱式开发，所有报表都是基于原始数据加工，SQL复杂度高，模型和指标无法复用，大量重复计算逻辑。一但某个业务变化，模型维护成本极高，而且大量的重复计算对资源消耗非常大，极易造成队列阻塞，影响数据产出</p><p>2、统一数据指标口径，保证数据一致性：定义一致、计算口径一致、数据源一致</p><ul><li>中文博大精深，一个简单的中文词经常包含些隐含信息。</li></ul><p>比如交易金额，当需求方说要取今天的交易额的时候，很多时候说的是今天的成功的交易金额，然而在逻辑角度，交易金额指的的订单表上支付金额+优惠券金额，不进行交易状态的条件过滤。</p><ul><li>鸡同鸭讲，说的是两个人沟通时说的不是同一个东西。</li></ul><p>比如订单的发货时间，对于财务业务，指的是订单表中的delivery_time字段，表示的是供货商提供的物流订单后第一次抓取到发货状态的时间；对于门店用户角度，指的是物流表中最终发送到用户手上那个订单的物流的发货时间。</p><p>3、数据结构清晰，方便数据查找和理解<br>数仓的分层设计能明晰每张表的作用域和职责，在需要查询使用时，能快速找到要用的表和理解每个字段的含义</p><h1 id="公司数仓存在什么问题"><a href="#公司数仓存在什么问题？" class="headerlink" title="公司数仓存在什么问题？"></a>公司数仓存在什么问题？</h1><ul><li>一张订单宽表打天下，其中包含了订单、交易、退款、物流、门店、供应商等多维度信息，下游以一个个数据烟囱的方式时间使用dw层的明细数据，无法收缩口径，保证数据的一致性。</li><li>基于onedate理论建设的数仓模型没有长期推广和取代订单宽表，人就有大量新报表从订单宽表获取数据</li></ul><h1 id="数据仓库模型分层设计方案"><a href="#数据仓库模型分层设计方案" class="headerlink" title="数据仓库模型分层设计方案"></a>数据仓库模型分层设计方案</h1><h2 id="基于主题域建设"><a href="#基于主题域建设" class="headerlink" title="基于主题域建设"></a>基于主题域建设</h2><h2 id><a href="#" class="headerlink" title></a></h2><h1 id="好的数据仓库设计评价标准"><a href="#好的数据仓库设计评价标准" class="headerlink" title="好的数据仓库设计评价标准"></a>好的数据仓库设计评价标准</h1><p>好的数仓设计标准应该是数据丰富完善、数据复用性强、数据规范性高。以下面的数仓架构为例<br><img src="https://i.328888.xyz/2023/04/24/iSq1LE.png" alt="iSq1LE.png"></p><h2 id="完善度"><a href="#完善度" class="headerlink" title="完善度"></a>完善度</h2><ul><li><p>dwd层完善度：衡量dwd层的完善度，看ods层被dw&#x2F;dws&#x2F;ads&#x2F;dim层依赖的数量（跨层引用率）。ods层被越多的非dwd层引用，说明越多任务基于原始数据进行开发，各种数据清洗、数据格式化存在重复计算。好的数仓设计一般要求ods层只能被dwd层引用，即跨层引用率为100%。</p></li><li><p>dw&#x2F;dws&#x2F;ads层完善度：衡量汇总数据的完善度，看仅靠dw&#x2F;dws&#x2F;ads层数据就能满足的查询比例（汇总层查询比例）。若汇总层数据无法满足查询要求，则需要从原始数据自行加工计算。汇总层查询比例不可能完全做到100%，但值越高，说明数仓上层模型建设越完善。</p></li></ul><h2 id="复用度"><a href="#复用度" class="headerlink" title="复用度"></a>复用度</h2><ul><li>模型引用系数：⼀个模型被读取，直接产出下游模型的平均数量。若对所有dwd层表（有下游）的模型引用系数取均值，则可衡量dwd层的模型引用系数。系数越大，说明数仓复用度越高。从数据血缘图来看，自下而上一条线的模型设计复用性差，复杂场景下这条线会极其长，而理想的模型设计应是交织的发散型结构<br><img src="https://i.328888.xyz/2023/04/24/ioZnHZ.png" alt="ioZnHZ.png"></li></ul><h2 id="规范度"><a href="#规范度" class="headerlink" title="规范度"></a>规范度</h2><ul><li><p>表分层规范：有多少表不能划属到数仓架构的某一层，一般从表命名前缀体现。</p></li><li><p>表命名规范：⼀个规范的表命名应该包括所属分层、所属主题域、调度周期、全量&#x2F;增量等信息。</p></li><li><p>字段命名规范：相同字段应在不同表保持一样的命名。同样是用户id，不能在A表叫user_id，在B表却叫u_id.</p></li></ul><p>数仓规范度越高，表名包含的信息越多，在数据地图查找表越方便，也更利于提高模型表复用度。</p><h1 id="一些博客文章"><a href="#一些博客文章" class="headerlink" title="一些博客文章"></a>一些博客文章</h1><p><a href="https://blog.51cto.com/u_15259710/2932712">如何避免数仓模型“烟囱式”建设</a></p><p><a href="https://mp.weixin.qq.com/s/U-avCBgYbwStUDe7e1LsqA">数仓常见问题以及解决方案！</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;基于在海拍客的工作经历，沉淀了一些关于数据仓库的思考，没有框架，想到什么写什么&lt;/p&gt;
&lt;h1 id=&quot;数据仓库解决什么问题&quot;&gt;&lt;a href=&quot;#数据仓库解决什么问题？&quot; class=&quot;headerlink&quot; title=&quot;数据仓库解决什么问题？&quot;&gt;&lt;/a&gt;数据仓库解决什</summary>
      
    
    
    
    <category term="数据仓库" scheme="https://llye-hub.github.io/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>数仓建模之关于流量域建设</title>
    <link href="https://llye-hub.github.io/posts/bbbc8dfb.html"/>
    <id>https://llye-hub.github.io/posts/bbbc8dfb.html</id>
    <published>2023-04-14T08:56:16.000Z</published>
    <updated>2023-05-08T02:05:14.131Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="4304f858f102b5e1e05f225132d79abf84e95f7b78114b0fe4c30989e795a675">0ae7e196f2221a75e5346dcbb7e124f3b1b3c5930620d283013007149d4c4935b69ce92f61658828479c839b5ea9198d1bda489f76e02aefb6c8c1b6c4f32fd31f36e698664f02671ce11c574fe5628c2d85825c7895fbc00177c55eaf6dc5335488610a8b88d894b09d84d011efc5134b4573dfbe48ed2bf6c239d1fecd49fc54f965b6c70627686bc4d8b5209339f82930e76524144c0f1b5aaa60eef52f119b05e4136dc067e5e8ca67e8e0772186df70f115b895d7d8f368b79708fb1e4c54851da8d44365f6047c0fad077890a16bdd1a6ce5d908272fbbf4f3ee0664dfd07c0471c47bd5506baa027cb755c66a44a1e7277f99d9e2ee2202bd050c0bff1e7d335c69ba839e217bb9e0d3c3eebe6e72bacfd7dda5938764aa615d6f61ed67ed2b24bdcd393e307a817bb140ddb80654ca6f812585d0c73d00616a462225de61da0fc1629df0558f3ee47d9cecd1800ddc7e1d26428f625b965c2e48ac61c2a647927e16629ad85603f6a9378530d503ae19fbace06786266ea4e64eac41d7f818b58581c1086db366efa626abcfc9b024e24da4a29a84e2109cfe15b3fc4f486af813e69865ed2f2ae6b0b48844db76d51998001273c492f1ba476fb840b757be323d45fc5e3fe94eccb2131d4490c4ca9fda3b8088132ec133e5af1c60a7c297a3496af60720a9f2eeca0cf3cc43f5ddd4af9a1297eb760d777ea0626e3a9ad3e2168591d480999c1e7d13dfeb07f4835a8c12500d23c84a42935d3581287ab81ac6ffc7a61afb2eac4dd07742903b802d69292c3d7c56ffa992fa2556e2fc12cc6e52e60a3effa93e3d295e2b7149769d628962d5157c1d24ae1e28b632e676e76f487194ce8c0a434727916a1b8864513f4d69fa39d6a11d868a01dd69c0af40db273372ca9e8c832fea678c5842f86ee27e302472f3101ffbcbf7acc58cdbd720be68548958012f88480fd3af182ea95d5641a911905cc06e3ae93106941854c87263e3fba2445b0ee9b5e5ef894c1a4bba66165a51e1d256d8d186e704ed5e03ae2708a34c0fd18d12cc364164c8b49862a30ccb66621a9a00e10b911882fa0a44156c9686c81e3d0af11c400cc49f94663aa6db8511244e709be165369752e37546cdf7f5d4426a8a45088b2c546ffddb0710c07bdf0256f1e62514037ffdddb1245e6b6ab90d6503a50236f96dacbbe60d1353df2e9edd3b9ff638e32aa3dd29941692520119ba4ad15b060b64f1fb75bfa9e260011a92286c6033803626c66224641b78cd9d7c6e6b8ce6d3b439dd55e05dc95d4bca8009f5cc4d91aa275b41a3f558acbd64c86ea7ba7ebffaaff75acae85274fe26e0d739cf8cdcbf891c2a81a1c9e7bc3a4be7812357246c8a6ada9174133ebbc096984f8b324d5d2a13bb2a3ca4ca6cb44e971ea79ec807547e4421c5dc012bd4c633f805d07718f3906f4f28b7f2457e4c6d4badb98b7a126f3e170d32635bcca3aaa493acce8ef23435e755908f907c4d2786521d3fc0eba03d272015a567009ded9cf1b1730b8b40c7d3b16d9d9fdb734727e277da59dc74f90d3ab88019fa0f31a42161b568de2f8e79321055ff90c038bc71ae84799c93b9bc40aaa4b0ce38fea856e3479dcae13bcb0972ea996c083ea6d3abd6cb45844127558d16f547fa24c6b600fbd84d747f0590f3058fb1d4c5609c8e1a9b926d7b2f3ef3d119557c8519cb2cf49d6027256b75ff51844347463da6205855fca3987416daa6cff5f216c3dd3f5488d10f76f63cea20ac8c9f40f1ad6f7b87b412f1ce8de19e9a8b413bc57e4f5c3c63f680c7d7f71f31f8922b1907815a3e87e2db2a7433b7a2f93f6dd5b703d8c43ed34ee84e652d7225d0cda6dc1cf28cb8704e4cc70588542d8076d687197f40575d4b178184474d2c5a147b883f0fd88a7081f4947ecfaddece704619ac093393174f43a6808f48e40fffc1fc1d7427374af1b9b4e8fb15f47e7ffec46b7292c75eeedb6ce93c94d4c36c246873c258485a41864fc7a46f8beb92d89cc99d8c9bf5ba3837fe64518016646aade36cc72c13b72386fb67423e330e40834d158fe6d889d02bac2745b02278bc4f8616cfe8050c1c17ee2408218915aa74f7df41144896e73bdbd743cc93eca87e78798211d29722134d4ca765e934268e0591c7c0f260792d91bdecc238e531c81da5853102904028580b37c7b2c1fc67c3b7e485a10b46fe636230207b95859bb01229e2a71a60fbce2bfc27013984550bd5ba38a7c4a5169d87ed63d74d51cdb07dca8a1fbaae7e99e2f83227c70427295b2f033c327ad0debcd39972446d355bb4024c6f9f5a36ea0879a8ce63fb90bdec6f3be6c71709bdbf97079fd120217ed4d5f1e89669ca5330fe35d9576db186edf7d520f6161fb224d0a50fad62903dc59fcf83b91cb63edb46bb7b28ea42292888b5509b59ec75cbf486cb6b5c8128f2afe5e23f3a652467efa509826e32426ac0deba3b8842b78f77fc31f110ad08e37d6a586b092e171abf1c43414de5491225c42334c4e6436f7f93c163503fd3b3056ef53e7ea5a77c8322d9f5ed6028ab1e8869515a46b79bb5e58c6a1aeabbbafce68805d768b72b7233f8c73d56622e84eec13d927205ca7e6c4858b9882980607b77faba4f82fe8135d1934a936c927487e596e3e735b82828105a8564353682855d27323bec7490e3ed445305c25fb895fca89647b8bf138b03deaf7622ecad90653159daca153b3df86b0236f978f851fbd9652ce78b94dba6be505f42eafdf2b3c1d3323d59c067118ff4873f7b3af8c8f25d8a251ffc4528ebb206043dcd20560bdf2458281f8c44082ff04152d873f9a9225fe739d61cc74948428e17a1d5d76c8365b9965cbac70a5cf4fb0fd637cd01020f7c52ea00961dbbee810888289c769cce32542960817050608756792754596b5f9d939bc9da9b49e7b28899ab16d465e96fd883ebba0a1cfaf5a1c140cdf1aa06572f9cb1bfb1c86244e95234170c53c4fe97f60821614025d5b107a97a715ea088277509efcdf048a4f61d2840dd40588b62cd4e46a6d2ca0ac77baea8b5b986f39bd9c2cd5a205f77189fffc292f416e43ca35574c153c5f2a7bfb74ec1fe7ceb20e79fbb3fd9dafd8391e7783827787a6c80467a96e8b94a22037f5d8d3ed3ad42f1a0200802b4f290eea664de60c76ef0643b993e5f05fd4964556665ecb7dba9040b65f566613480c1782d497d898ebe18df29b22cd07b948eb87371bc64b4e1d76a27df605b9cb07e5bd2e7a1a2c6e11bbd61125e859ab15e2e116d93e3f9ad34ca2c2d0c4b18f9bcc4ea9361e34ca54cc94256e8a0e41dca8be7ee4cf63f092c8cd765fed448ef98c2af893a8f2a5499bbba2ff2e0ffacd44829f0868b4428026a380fa832e35cde44bbc2f5cd7cfdb9bbb85a72d310de5b6f09da4f39dea6e0c9f8dcdecb56ae25b320063d3bcfe4da51b4d6003a6c6a63973fa927e8083a56f91923207bf7e61d4694851e06600b6a86dc3eb65fe86f978036d0c420f5f128aa5be5b68c3b8b95f1dd86006d63181950c5050dd784b91d08ae8e84eb604e4b862f8020b965fedb8a14bc718d217c25acadc5987c508dc369c8bd399d6241d138196721673f78bd358b0b76370bd56adb3ea516668ada2bc680108084159ee8bf21e8b102d315d3764de07eec5e27105713a36898e161b076bda7bf29c0855336bbce1e096ba5c888331e6e6ae777416547bb7bfc0d8f7c2a2a77c5528177d0223015b8f27707ce76b8766908a4de59fa00128a76bd15456c570058f7db0b6811e85acc09e6e407fd86c3d6c112ef96c35f5403dbe5013d8e85292315ad0b3e4d5ae616d381da0e9de2e468c20998d755961c3826f98a0e054fa1c8d70a7c9ffbddf4683f456ef612d0d615d6ff40fb956761746083b29ce90d4e5ea705cb930043377a775b762717390ad3790d41827aadb6a259233a690475af89d00ded680760637c62eba2a1c59681e869da63b8bd65beb2d1a0173c7005e9b1c3c683486767ccf92ae5b2cdd2d4c90811d347839245cbedb7cae6b07d85e8b58787ff23e9e54afd405e0be59b79bc73f302fbf7bb662e2b87de660328ea2e6be77451cc5f25bf6a25dd929a0f48785ca9fe77535acdffadb0b36e0da29b9d44157c12b727495fb1ade0ef22d45b2f194c68d83898407fd8da7542f857629540122f36dc7e70fd5b4fec7201d078ba13607d5bcb5ec75838b0d7f3cc981c6a2d93a5fdff1054ad72b7f05ec96c4a4ac2fa56efdaa1b936ae305b28213dd7898239c13b360a8d38fe0854b3bdc102707d6a3a46673e35e6c265e01b13d7a7d72474bbcde3a0ef34ae9d2e9ce9705a4c8bdd1e99d97246e9197960cf49b58a239dd360e11e316211c339b58003b9dfb1a8c0330ae5a9d43894a06fc8efaae0a596778fca4fd629e3fd3eefbe608a6dd293d006a3009ac3d9b2b913315028267f2e895790632144253660efc5e5c960f62c3e1027a26cc42dd80e52f7b3a6b11ab3ec944a69128670ec935b5347cf9e77476b38daefa3203262e9b0f911ce81ae6f667305f165a4dbaccbdd49cd722e2146d8a486aec151813c250a295bc63cb9369622cbe531c8490f92c4ebae5f803373c2bacbfc68ea9f1cb583fa4828531768defff1a4f9ebeb23cb542c5461055cfb4d4d5007f5a50552fcd5127fa3145adbe910caf93b214cb1c164bbf39b1d3b707572d1e0b6132e47e48125e15afa4a7b14530f46d46d0dd798064c73e65e3aea8fdc22c80e6f8fa79e7cd1d3ee46438029060c01a3e5a8adab4717e94d1034951f03fe7ca7c63501f613c0e66c7dbc56d22f1024209b8467cf2ee291bae87e113fb63c9e63f5cfc989284d9480115cffa8cfb1ae24bec3aae6e560473afb2136951f7462c4edc5785b93e7d1f60f1f1bd97536207925fc9fe186f7d34a92e5b2c7d59b6c2c4b7e741d9e020ff9eb8cc4620b41bd026cb0afb7aa4d60a8ac6836c1eb81fe21acd80033df74120a146dcc76ca089f0a33e2112bde4b72d20870e076f783a7d13dc1344387352195485afa3867e8612df21709e93ea730c484217cf2c9d673204ff318c27c3b0232ae927e4481dcd7858bfffc2c59ede849589d5a25c22450a421245eae41dd95f17816c6ae5ff2befeec956ce12d74a1295a9f134d44ca7e072d12274f8ad8dd1dcd23dba8a2ef65c7e590c3b130e6cdbc3e32db0cb1703ef6d2c638420f71bd53b2e11f1227541ae163c0b10acdb91b10a1c840ee45cddec4afa2782f213dd74c885cfb4c9be150bd8c0e389f4b037ad34255e67ff628dacdcc128a771e0c698767148517ea8199785d010a9ff2f4d59973740be995cac9dc44909d981ca5be80eb673cd25830cb10f510a7c7d49cf6fbe7f4cf6bc74541d1470339f58972868d03bd49bc72e679e121d2226a42668b5718d6541a84513f33110539e888879bc77050fb2e6377c4265e80c6b8b4fadbf959f5cd32c46fe79436af2a3406e3754df2c5b348e658f5ec9e0681911d78ca946160d90b2854b8f34277485c7f3fcbb44383057b31bbc4d01c013100</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">这是一篇加密文章，需要密码才能继续阅读。</summary>
    
    
    
    <category term="数据仓库" scheme="https://llye-hub.github.io/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
    
    <category term="private" scheme="https://llye-hub.github.io/tags/private/"/>
    
    <category term="数仓建模" scheme="https://llye-hub.github.io/tags/%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1/"/>
    
  </entry>
  
  <entry>
    <title>在hive中嵌入自定义数据处理函数-UDF函数</title>
    <link href="https://llye-hub.github.io/posts/cafe49d7.html"/>
    <id>https://llye-hub.github.io/posts/cafe49d7.html</id>
    <published>2023-04-11T09:04:03.000Z</published>
    <updated>2023-04-18T07:45:38.183Z</updated>
    
    
    
    
    <category term="hive" scheme="https://llye-hub.github.io/categories/hive/"/>
    
    
    <category term="写UDF" scheme="https://llye-hub.github.io/tags/%E5%86%99UDF/"/>
    
  </entry>
  
  <entry>
    <title>hiveSQL之全面认识窗口函数</title>
    <link href="https://llye-hub.github.io/posts/ed2327bc.html"/>
    <id>https://llye-hub.github.io/posts/ed2327bc.html</id>
    <published>2023-03-31T02:46:52.000Z</published>
    <updated>2023-04-07T03:23:39.244Z</updated>
    
    <content type="html"><![CDATA[<p>本文内容来自文章<a href="https://mp.weixin.qq.com/s/VnQT-bidnJDduoLfJeRhxA">Hive SQL大厂必考常用窗口函数及面试题</a></p><p>受岗位性质和工作内容影响，在我从事数仓开发工作至今，对于窗口函数的使用场景都很基础，常用的也只有row_number、sum、max&#x2F;min，<br>偶尔碰到些其他场景，因为不熟悉，可能就需要反复查看官方文档确认。</p><p>所以在上面文章阅读过程中，基于个人理解，重新梳理写了本文</p><h1 id="窗口函数概述"><a href="#窗口函数概述" class="headerlink" title="窗口函数概述"></a>窗口函数概述</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics">hive官方介绍</a></p><p>窗口函数也称为OLAP函数，是数据分析最常用到的函数，熟练的掌握窗口函数的各种用法和骚操作对从事数据工作者是很重要的。</p><p>与聚合函数将多条记录聚合为一条不同，窗口函数每条记录都会执行，执行前后数据量不变，且窗口函数兼具分组和排序两种功能。</p><h2 id="窗口函数用法"><a href="#窗口函数用法" class="headerlink" title="窗口函数用法"></a>窗口函数用法</h2><h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">窗口函数</span>&gt;</span> over ([partition by <span class="tag">&lt;<span class="name">列名</span>&gt;</span>] [order by <span class="tag">&lt;<span class="name">排序列名</span>&gt;</span>] [window_frame])</span><br></pre></td></tr></table></figure><p>其中：</p><p>&lt;窗口函数&gt;: 指需要使用的分析函数，如row_number()、sum()等。</p><p>over() : 用来指定函数执行的窗口范围，这个数据窗口大小可能会随着行的变化而变化。<br>如果括号中什么都不写，则意味着窗口包含满足where条件的所有行，窗口函数基于所有行进行计算</p><p>window_frame: 在分组窗口基础上，可以进一步指定窗口计算边界</p><h2 id="设置窗口"><a href="#设置窗口" class="headerlink" title="设置窗口"></a>设置窗口</h2><h3 id="1partition-by子句"><a href="#1）partition-by子句" class="headerlink" title="1）partition by子句"></a>1）partition by子句</h3><p>窗口划分分组条件</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    uid,</span><br><span class="line">    score,</span><br><span class="line">    <span class="built_in">sum</span>(score) <span class="keyword">OVER</span>(<span class="keyword">PARTITION</span> <span class="keyword">BY</span> uid) <span class="keyword">AS</span> sum_score</span><br><span class="line"><span class="keyword">FROM</span> exam_record</span><br></pre></td></tr></table></figure><h3 id="2order-by子句"><a href="#2）order-by子句" class="headerlink" title="2）order by子句"></a>2）order by子句</h3><p>窗口排序条件</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    uid,</span><br><span class="line">    score,</span><br><span class="line">    <span class="built_in">sum</span>(score) <span class="keyword">OVER</span>(<span class="keyword">ORDER</span> <span class="keyword">BY</span> uid) <span class="keyword">AS</span> sum_score</span><br><span class="line"><span class="keyword">FROM</span> exam_record</span><br></pre></td></tr></table></figure><h3 id="3指定窗口大小"><a href="#3）指定窗口大小" class="headerlink" title="3）指定窗口大小"></a>3）指定窗口大小</h3><p>指定窗口大小，又称为窗口框架。框架是重新定义窗口计算边界，框架有两种范围限定方式：</p><ul><li><p>一种是使用 ROWS 子句，通过指定当前行之前或之后的固定数目的行来限制分区中的行数。</p></li><li><p>另一种是使用 RANGE 子句，按照排列序列的当前值，根据相同值来确定分区中的行数。</p></li></ul><p>语法<code>ORDER BY 字段名 RANGE|ROWS 边界规则0 | [BETWEEN 边界规则1 AND 边界规则2]</code>，边界规则的可取值如下：</p><ul><li><code>current row</code>：当前行</li><li><code>n preceding</code>：当前行及往前n行数据</li><li><code>unbounded preceding</code>：第一行至当前行数据</li><li><code>n following</code>：当前行及往后n行数据</li><li><code>unbounded following</code>：当前行至最后一行数据</li></ul><p>需要注意的是，</p><ul><li>使用框架时必须有order by子句</li><li>若仅有order by子句而未指定框架，则默认框架语句为<code>range unbounded preceding and current row</code>，<br><a href="https://llye-hub.github.io/posts/5af52219.html">详情见文章</a></li></ul><h3 id="4window_name"><a href="#4）window-name" class="headerlink" title="4）window_name"></a>4）window_name</h3><p>给窗口指定一个别名<code>WINDOW my_window_name AS (PARTITION BY uid ORDER BY score)</code>，<br>适用于一个窗口被多次使用，可以使sql简洁清晰，也易于维护</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    uid,</span><br><span class="line">    score,</span><br><span class="line">    <span class="built_in">rank</span>() <span class="keyword">OVER</span> my_window_name <span class="keyword">AS</span> rk_num,</span><br><span class="line">    <span class="built_in">row_number</span>() <span class="keyword">OVER</span> my_window_name <span class="keyword">AS</span> row_num,</span><br><span class="line">    <span class="built_in">dense_rank</span>() <span class="keyword">OVER</span> my_window_name <span class="keyword">AS</span> dr_num</span><br><span class="line"><span class="keyword">FROM</span> exam_record</span><br><span class="line"><span class="keyword">WHERE</span> score<span class="operator">&gt;=</span><span class="number">60</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> uid</span><br><span class="line"><span class="keyword">WINDOW</span> my_window_name <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> uid <span class="keyword">ORDER</span> <span class="keyword">BY</span> score)</span><br></pre></td></tr></table></figure><h2 id="窗口函数分类"><a href="#窗口函数分类" class="headerlink" title="窗口函数分类"></a>窗口函数分类</h2><p>窗口函数：</p><ul><li>first_value: 返回计算窗口内按排序条件的第一个值，语法<code>first_value(exp_str,true|false)</code></li><li>last_value: 返回计算窗口内按排序条件的最后一个值，语法<code>last_value(exp_str,true|false)</code></li><li>lag: 返回相对当前行，第前n行的数据，语法<code>lag(exp_str,offset,defval) over(partition by .. order by …)</code></li><li>lead: 返回相对当前行，第后n行的数据，语法<code>lead(exp_str,offset,defval) over(partition by .. order by …)</code></li></ul><p>配合over语句使用的聚合函数：</p><ul><li>sum</li><li>count([distinct])</li><li>max</li><li>min</li><li>avg</li></ul><p>分析函数：</p><ul><li>row_number: 连续排序——1、2、3、4</li><li>rank: 并列跳号排序——1、1、3、4</li><li>dense_rank: 并列连续排序——1、1、2、3</li><li>percent_rank: 将某个数值在数据集中的rank()排位作为数据集的百分比值返回，每行按照公式(rank-1) &#x2F; (rows-1)进行计算，百分比值的范围为 0 到 1。<br>可用于计算值在数据集内的相对位置。语法<code>percent_rank(exp_str)</code></li><li>cume_dist: 如果按升序排列，则统计：小于等于当前值的行数&#x2F;总行数。<br>       如果是降序排列，则统计：大于等于当前值的行数&#x2F;总行数。<br>       语法<code>cume_dist(exp_str)</code></li><li>ntiles: 将分组数据按照顺序平均切分成n组，并返回当前切片值。语法<code>ntiles(n)</code>。<br>    如果不能平均分配，则优先分配较小编号的切片，并且各个切片中能放的行数最多相差 1。<br>    可简单理解为，有 n 个桶，按编号 1-n 的顺序逐个将分组数据放到每个桶内，直至数据分配完毕。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文内容来自文章&lt;a href=&quot;https://mp.weixin.qq.com/s/VnQT-bidnJDduoLfJeRhxA&quot;&gt;Hive SQL大厂必考常用窗口函数及面试题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;受岗位性质和工作内容影响，在我从事数仓开发工作至今，对于窗口函数的使用</summary>
      
    
    
    
    <category term="SQL" scheme="https://llye-hub.github.io/categories/SQL/"/>
    
    
    <category term="hiveSQL" scheme="https://llye-hub.github.io/tags/hiveSQL/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记之数据仓库工具箱维度建模权威指南(第3版)</title>
    <link href="https://llye-hub.github.io/posts/4142350a.html"/>
    <id>https://llye-hub.github.io/posts/4142350a.html</id>
    <published>2023-03-29T06:31:37.000Z</published>
    <updated>2023-04-18T08:14:08.029Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="fe1d605873a64a776899cd24903c2cfb2b3f6754276eb8f0e33aa5b5ff6dec62">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">这是一篇加密文章，需要密码才能继续阅读。</summary>
    
    
    
    <category term="阅读笔记" scheme="https://llye-hub.github.io/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="读书笔记" scheme="https://llye-hub.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    <category term="private" scheme="https://llye-hub.github.io/tags/private/"/>
    
  </entry>
  
  <entry>
    <title>内置函数之reflect</title>
    <link href="https://llye-hub.github.io/posts/1d24daf8.html"/>
    <id>https://llye-hub.github.io/posts/1d24daf8.html</id>
    <published>2023-03-22T09:39:53.000Z</published>
    <updated>2023-03-29T03:43:07.269Z</updated>
    
    
    
    
    <category term="SQL" scheme="https://llye-hub.github.io/categories/SQL/"/>
    
    
    <category term="内置函数" scheme="https://llye-hub.github.io/tags/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>搭建spark on yarn源码调试</title>
    <link href="https://llye-hub.github.io/posts/5e1f3fb0.html"/>
    <id>https://llye-hub.github.io/posts/5e1f3fb0.html</id>
    <published>2023-03-21T09:02:06.000Z</published>
    <updated>2023-03-29T03:43:07.272Z</updated>
    
    <content type="html"><![CDATA[<p><strong>参考文章</strong><br><a href="https://www.cnblogs.com/qixing/p/14017875.html">Spark3.0.1各种集群模式搭建及spark on yarn日志配置</a><br><a href="https://www.jianshu.com/p/aa6f3a366727">Spark on Yarn集群搭建详细过程</a></p><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><p>jdk8+Hadoop3.3.1 </p><h1 id="spark的几种部署方式"><a href="#spark的几种部署方式" class="headerlink" title="spark的几种部署方式"></a>spark的几种部署方式</h1><p>Spark作为准实时大数据计算引擎，Spark的运行需要依赖资源调度和任务管理，Spark自带了standalone模式资源调度和任务管理工具，运行在其他资源管理和任务调度平台上，如Yarn、Mesos、Kubernates容器等。</p><p>spark的搭建和Hadoop差不多，主要有下面几种部署方式：</p><ul><li><p>Local：多用于本地测试，如在eclipse，idea中写程序测试等。</p></li><li><p>Standalone：Standalone是Spark自带的一个资源调度框架，它支持完全分布式。</p></li><li><p>Yarn：Hadoop生态圈里面的一个资源调度框架，Spark也是可以基于Yarn来计算的。</p></li></ul><p>基于个人学习需求，本文仅记录Local模式部署过程。</p><h1 id="下载spark源码"><a href="#下载spark源码" class="headerlink" title="下载spark源码"></a>下载spark源码</h1><p><a href="https://archive.apache.org/dist/spark/">下载地址</a></p><p><strong>解压</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zcvf spark-3.2.0-bin-hadoop3.2.tgz</span><br></pre></td></tr></table></figure><p><strong>配置环境变量</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">SPARK_HOME=/Users/llye/workspace/spark-3.2.0-bin-hadoop3.2</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$PATH</span></span></span><br><span class="line">vi ~/.bash_profile </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生效</span></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><h1 id="本地local模式"><a href="#本地local模式" class="headerlink" title="本地local模式"></a>本地local模式</h1><p><strong>测试样例</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/bin </span><br><span class="line">run-example SparkPi 10  # 可计算出结果</span><br></pre></td></tr></table></figure><p><img src="https://i.328888.xyz/2023/03/24/iV6lXq.png" alt="iV6lXq.png"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell  # 启动成功，说明Local模式部署成功</span><br></pre></td></tr></table></figure><p><img src="https://i.328888.xyz/2023/03/24/iV6HUw.png" alt="iV6HUw.png"></p><p>启动成功后，访问<code>http://localhost:4040/</code> 即可进行web UI监控页面访问</p><h1 id="standalone模式未完成不具参考性"><a href="#Standalone模式（未完成，不具参考性）" class="headerlink" title="Standalone模式（未完成，不具参考性）"></a>Standalone模式（未完成，不具参考性）</h1><p>配置Spark on Yarn集群</p><p><strong>修改spark-env.sh文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/conf</span><br><span class="line">cat &gt; spark-env.sh &lt;&lt; EOF</span><br><span class="line">JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home/</span><br><span class="line">SCALA_HOME=/Users/llye/soft/scala/</span><br><span class="line">HADOOP_HOME=/Users/llye/soft/hadoop-3.3.1/</span><br><span class="line">HADOOP_CONF_DIR=/Users/llye/soft/hadoop-3.3.1/etc/hadoop/</span><br><span class="line">YARN_CONF_DIR=/Users/llye/soft/hadoop-3.3.1/etc/hadoop/etc/hadoop/</span><br><span class="line">SPARK_MASTER_HOST=spark    # 主节点机器名称</span><br><span class="line">SPARK_MASTER_PORT=7077     # 默认端口号7077</span><br><span class="line">SPARK_HOME=/Users/llye/workspace/spark-3.2.0-bin-hadoop3.2/</span><br><span class="line">SPARK_LOCAL_DIRS=/Users/llye/workspace/spark-3.2.0-bin-hadoop3.2/</span><br><span class="line">SPARK_LIBARY_PATH=/Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home/lib/:/Users/llye/soft/hadoop-3.3.1/lib/native/</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><strong>修改slaves配置文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/sbin </span><br><span class="line">vi slaves</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">spark001</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">spark002</span></span><br></pre></td></tr></table></figure><p><strong>将spark目录发送到其他机器</strong></p><p>创建workers文件，指定Worker节点：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/conf</span><br><span class="line">cat &gt; workers &lt;&lt; EOF</span><br><span class="line">worker1</span><br><span class="line">worker2</span><br><span class="line">worker3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h1 id="启动spark-on-yarn集群"><a href="#启动Spark-on-Yarn集群" class="headerlink" title="启动Spark on Yarn集群"></a>启动Spark on Yarn集群</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/sbin</span><br></pre></td></tr></table></figure><p>在Spark节点上启动Spark Master节点：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-master.sh</span><br></pre></td></tr></table></figure><p>在Worker节点上启动Spark Worker节点：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-worker.sh spark://spark:7077</span><br></pre></td></tr></table></figure><h1 id="登录spark-on-yarn集群"><a href="#登录Spark-on-Yarn集群" class="headerlink" title="登录Spark on Yarn集群"></a>登录Spark on Yarn集群</h1><p>登录Master：</p><p>登录Worker：<code>http://localhost:8081/</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;&lt;br&gt;&lt;a href=&quot;https://www.cnblogs.com/qixing/p/14017875.html&quot;&gt;Spark3.0.1各种集群模式搭建及spark on yarn日志配置&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;ht</summary>
      
    
    
    
    <category term="spark" scheme="https://llye-hub.github.io/categories/spark/"/>
    
    
    <category term="spark on yarn" scheme="https://llye-hub.github.io/tags/spark-on-yarn/"/>
    
  </entry>
  
  <entry>
    <title>hive本机安装</title>
    <link href="https://llye-hub.github.io/posts/47d5b7b0.html"/>
    <id>https://llye-hub.github.io/posts/47d5b7b0.html</id>
    <published>2023-03-15T02:49:23.000Z</published>
    <updated>2023-05-05T03:32:22.681Z</updated>
    
    <content type="html"><![CDATA[<p><strong>参考文章</strong></p><p><a href="https://zhuanlan.zhihu.com/p/68748400">Hive源码系列（一）hive2.1.1+hadoop2.7.3环境搭建</a></p><p><a href="https://juejin.cn/post/7114252763621490719">Hive安装超详细教程</a></p><p><a href="https://www.cnblogs.com/swordfall/p/13426569.html#auto_id_14">Hive架构与源码分析</a></p><p><a href="https://datavalley.github.io/2015/10/16/Hive%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA">Hive:源码解析之本地环境搭建</a></p><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><p>jdk8 + Hadoop3.3.1</p><h1 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h1><p><a href="https://dlcdn.apache.org/hive/">下载地址</a></p><p><strong>解压安装包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-2.3.9-bin.tar.gz</span><br></pre></td></tr></table></figure><p><strong>环境变量配置</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HIVE_HOME=/Users/llye/soft/hive-2.3.9</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> PATH=<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$PATH</span></span></span><br><span class="line">vi ~/.bash_profile </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生效</span></span><br><span class="line">source ~/.bash_profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证</span></span><br><span class="line">hive --version</span><br></pre></td></tr></table></figure><p><strong>修改配置文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd $HIVE_HOME/conf</span><br></pre></td></tr></table></figure><p><code>vi hive-site.xml</code>编辑内容如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  以mysql作为hive元数据库  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hivedb?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="symbol">&amp;amp;</span>useSSL=false<span class="symbol">&amp;amp;</span>serverTimezone=GMT<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>hive metastore连接串<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.cj.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Hive metastore JDBC驱动<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Mysql登录账号<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rootroot<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Mysql登录密码<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 忽略HIVE 元数据库版本的校验，如果非要校验就得进入MYSQL升级版本 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--  配置hive用户名、密码  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.jdbc_passwd.auth.root<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rootroot<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.jdbc_passwd.auth.llye<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rootroot<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- hiveserver2 --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  配置用户安全认证方式  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.authentication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>NONE<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">            Expects one of [nosasl, none, ldap, kerberos, pam, custom].</span><br><span class="line">            Client authentication types.</span><br><span class="line">            NONE: no authentication check</span><br><span class="line">            LDAP: LDAP/AD based authentication</span><br><span class="line">            KERBEROS: Kerberos/GSSAPI authentication</span><br><span class="line">            CUSTOM: Custom authentication provider</span><br><span class="line">            (Use with property hive.server2.custom.authentication.class)</span><br><span class="line">            PAM: Pluggable authentication module</span><br><span class="line">            NOSASL:  Raw transport</span><br><span class="line">        <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.custom.authentication.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hive.contrib.auth.CustomPasswdAuthenticator<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>配置用于权限认证的类【这里实际没有】<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 hiveserver2 jdbc连接的 host+port --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>hiveserver2 jdbc连接的 host<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>hiveserver2 jdbc连接的端口号<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  配置webUI界面 host+port  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.webui.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.webui.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10002<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>下载连接MySQL的驱动包到hive的lib目录下</strong></p><p><code>mysql-connector-java-8.0.17.jar</code><a href="https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.17/mysql-connector-java-8.0.17.jar">下载地址</a></p><p><strong>初始化hive元数据库</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $HIVE_HOME/bin</span><br><span class="line">schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure><p><strong>验证初始化是否成功</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- mysql的hivedb库中，若展示多个数据表，即代表初始化成功</span></span><br><span class="line"><span class="keyword">show</span> tables;</span><br></pre></td></tr></table></figure><p><img src="https://i.328888.xyz/2023/03/15/JxW5E.png" alt="JxW5E.png"></p><p><strong>启动hive</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HADOOP_HOME/sbin/start-dfs.sh &amp;</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HADOOP_HOME/sbin/start-yarn.sh</span></span><br><span class="line">cd $HIVE_HOME </span><br><span class="line">hive </span><br></pre></td></tr></table></figure><p>遇到启动报错<code>org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /tmp/hive</code>时，执行命令<code>hdfs dfsadmin -safemode leave</code>关闭HDFS安全模式</p><p><strong>验证</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student(id <span class="type">int</span>, name string);</span><br><span class="line"><span class="comment">-- 插入数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> student <span class="keyword">values</span>(<span class="number">1</span>, <span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"><span class="comment">-- 查询数据</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure><p><img src="https://i.328888.xyz/2023/03/15/J73cF.png" alt="J73cF.png"></p><h1 id="beeline连接hiveserver2"><a href="#beeline连接hiveserver2" class="headerlink" title="beeline连接hiveserver2"></a>beeline连接hiveserver2</h1><p><strong>hadoop配置</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd $HADOOP_HOME/etc/hadoop</span><br></pre></td></tr></table></figure><p><code>vi core-site.xml</code>补充内容如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.llye.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.llye.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>重启hadoop</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HADOOP_HOME/sbin/stop-all.sh &amp;</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HADOOP_HOME/sbin/start-all.sh</span> </span><br></pre></td></tr></table></figure><p><strong>启动metastore</strong></p><p>配置了hive的环境变量，任意文件夹下执行即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive --service metastore</span><br></pre></td></tr></table></figure><p><strong>启动hiveserver2</strong></p><p>配置了hive的环境变量，任意文件夹下执行即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hiveserver2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或</span></span><br><span class="line">hive --service hiveserver2</span><br></pre></td></tr></table></figure><p>若<code>hiveserver2</code>启动失败，检查1000端口是否被占用，命令<code>lsof -i:10000</code>和<code>kill -9 xxx</code></p><p><strong>beeline连接</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">beeline</span><br><span class="line"><span class="meta prompt_">beeline&gt; </span><span class="language-bash">!connect jdbc:hive2://localhost:10000/default</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或</span></span><br><span class="line">beeline -u jdbc:hive2://localhost:10000/default </span><br></pre></td></tr></table></figure><p>遇到报错问题的参考：</p><p><a href="https://blog.csdn.net/qq_16633405/article/details/82190440">beeline连接hiveserver2报错：User: root is not allowed to impersonate root</a></p><p><a href="https://developer.aliyun.com/article/606803">Hive JDBC：Permission denied: user&#x3D;anonymous, access&#x3D;EXECUTE, inode&#x3D;”&#x2F;tmp”</a></p><h1 id="客户端jdbc连接hive库"><a href="#客户端jdbc连接hive库" class="headerlink" title="客户端jdbc连接hive库"></a>客户端jdbc连接hive库</h1><p><strong>启动metastore和hiveserver2</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive --service metastore</span><br><span class="line"></span><br><span class="line">hiveserver2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或</span></span><br><span class="line">hive --service hiveserver2</span><br></pre></td></tr></table></figure><p><code>DBeaver</code>连接，设置jdbc URL：<code>jdbc:hive2://localhost:10000/default</code></p><h1 id="hive源码编译"><a href="#hive源码编译" class="headerlink" title="hive源码编译"></a>hive源码编译</h1><p><strong>解压安装包</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-2.3.9-src.tar.gz</span><br></pre></td></tr></table></figure><p><strong>编译源码</strong></p><p>进入解压目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package -DskipTests -Phadoop-2 -Pdist</span><br></pre></td></tr></table></figure><p>编译过程中报错<code>An error has occurred in JavaDocs report generation:Exit code: 1 - javadoc: error - invalid flag: -author</code>，<a href="https://stackoverflow.com/questions/19181236/an-error-has-occurred-in-javadocs-report-generationexit-code-1-javadoc-erro">解决方案</a>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-javadoc-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;maven.javadoc.plugin.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>resourcesdoc.xml<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>javadoc<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">phase</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>$&#123;project.build.sourceEncoding&#125;<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">show</span>&gt;</span>public<span class="tag">&lt;/<span class="name">show</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">doclet</span>&gt;</span>com.sun.jersey.wadl.resourcedoc.ResourceDoclet<span class="tag">&lt;/<span class="name">doclet</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">docletArtifacts</span>&gt;</span></span><br><span class="line">          ……</span><br><span class="line">        <span class="tag">&lt;/<span class="name">docletArtifacts</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">additionalparam</span>&gt;</span>-output $&#123;project.build.outputDirectory&#125;/resourcedoc.xml<span class="tag">&lt;/<span class="name">additionalparam</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--  pom文件中加上此项配置  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">useStandardDocletOptions</span>&gt;</span>false<span class="tag">&lt;/<span class="name">useStandardDocletOptions</span>&gt;</span>   </span><br><span class="line">      <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>导入idea</strong></p><p>从hive的解压目录中选择pom.xml文件导入</p><p><strong>调试代码</strong></p><p>进入解压目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd  packaging/target/apache-hive-2.3.9-bin/apache-hive-2.3.9-bin</span><br><span class="line"></span><br><span class="line">hive --debug -hiveconf hive.root.logger=DEBUG,console</span><br></pre></td></tr></table></figure><p>成功时，界面出现：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Listening for transport dt_socket at address: 8000</span><br></pre></td></tr></table></figure><p>JVM会监听8000端口，等待客户端调试连接。</p><p>进入idea配置远程连接如下：<br><img src="https://i.328888.xyz/2023/03/20/Pz9vq.png" alt="Pz9vq.png"></p><p>hive的CLI的入口类为：<code>src/java/org/apache/hadoop/hive/cli/CliDriver.java</code>，断点调试成功如下：<br><img src="https://i.328888.xyz/2023/03/20/PFA3q.png" alt="PFA3q.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68748400&quot;&gt;Hive源码系列（一）hive2.1.1+hadoop2.7.3环境搭建&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;htt</summary>
      
    
    
    
    <category term="hive" scheme="https://llye-hub.github.io/categories/hive/"/>
    
    
    <category term="hive安装" scheme="https://llye-hub.github.io/tags/hive%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
</feed>
