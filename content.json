{"meta":{"title":"LLye","subtitle":"","description":"scsadad","author":"LLye","url":"https://llye-hub.github.io","root":"/"},"pages":[{"title":"Repositories","date":"2023-01-16T07:15:53.818Z","updated":"2023-01-16T07:15:53.818Z","comments":false,"path":"index.html","permalink":"https://llye-hub.github.io/index.html","excerpt":"","text":""},{"title":"About Me","date":"2023-01-17T08:41:32.555Z","updated":"2023-01-17T08:41:32.555Z","comments":false,"path":"about/index.html","permalink":"https://llye-hub.github.io/about/index.html","excerpt":"","text":"å·¥ä½œç»å†"},{"title":"å‹æƒ…é“¾æ¥","date":"2023-01-16T07:30:43.399Z","updated":"2023-01-16T07:30:43.399Z","comments":true,"path":"links/index.html","permalink":"https://llye-hub.github.io/links/index.html","excerpt":"","text":""},{"title":"æ ‡ç­¾","date":"2023-01-16T07:29:50.652Z","updated":"2023-01-16T07:29:50.652Z","comments":false,"path":"tags/index.html","permalink":"https://llye-hub.github.io/tags/index.html","excerpt":"","text":""},{"title":"åˆ†ç±»","date":"2023-02-17T05:46:56.411Z","updated":"2023-02-17T05:46:56.411Z","comments":false,"path":"categories/index.html","permalink":"https://llye-hub.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"hiveSQLä¹‹å…¨é¢è®¤è¯†çª—å£å‡½æ•°","slug":"SQL/hiveSQLä¹‹å…¨é¢è®¤è¯†çª—å£å‡½æ•°","date":"2023-03-31T02:46:52.000Z","updated":"2023-04-07T03:23:39.244Z","comments":true,"path":"posts/ed2327bc.html","link":"","permalink":"https://llye-hub.github.io/posts/ed2327bc.html","excerpt":"","text":"æœ¬æ–‡å†…å®¹æ¥è‡ªæ–‡ç« Hive SQLå¤§å‚å¿…è€ƒå¸¸ç”¨çª—å£å‡½æ•°åŠé¢è¯•é¢˜ å—å²—ä½æ€§è´¨å’Œå·¥ä½œå†…å®¹å½±å“ï¼Œåœ¨æˆ‘ä»äº‹æ•°ä»“å¼€å‘å·¥ä½œè‡³ä»Šï¼Œå¯¹äºçª—å£å‡½æ•°çš„ä½¿ç”¨åœºæ™¯éƒ½å¾ˆåŸºç¡€ï¼Œå¸¸ç”¨çš„ä¹Ÿåªæœ‰row_numberã€sumã€max&#x2F;minï¼Œå¶å°”ç¢°åˆ°äº›å…¶ä»–åœºæ™¯ï¼Œå› ä¸ºä¸ç†Ÿæ‚‰ï¼Œå¯èƒ½å°±éœ€è¦åå¤æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£ç¡®è®¤ã€‚ æ‰€ä»¥åœ¨ä¸Šé¢æ–‡ç« é˜…è¯»è¿‡ç¨‹ä¸­ï¼ŒåŸºäºä¸ªäººç†è§£ï¼Œé‡æ–°æ¢³ç†å†™äº†æœ¬æ–‡ çª—å£å‡½æ•°æ¦‚è¿°hiveå®˜æ–¹ä»‹ç» çª—å£å‡½æ•°ä¹Ÿç§°ä¸ºOLAPå‡½æ•°ï¼Œæ˜¯æ•°æ®åˆ†ææœ€å¸¸ç”¨åˆ°çš„å‡½æ•°ï¼Œç†Ÿç»ƒçš„æŒæ¡çª—å£å‡½æ•°çš„å„ç§ç”¨æ³•å’Œéªšæ“ä½œå¯¹ä»äº‹æ•°æ®å·¥ä½œè€…æ˜¯å¾ˆé‡è¦çš„ã€‚ ä¸èšåˆå‡½æ•°å°†å¤šæ¡è®°å½•èšåˆä¸ºä¸€æ¡ä¸åŒï¼Œçª—å£å‡½æ•°æ¯æ¡è®°å½•éƒ½ä¼šæ‰§è¡Œï¼Œæ‰§è¡Œå‰åæ•°æ®é‡ä¸å˜ï¼Œä¸”çª—å£å‡½æ•°å…¼å…·åˆ†ç»„å’Œæ’åºä¸¤ç§åŠŸèƒ½ã€‚ çª—å£å‡½æ•°ç”¨æ³•åŸºæœ¬è¯­æ³•1&lt;çª—å£å‡½æ•°&gt; over ([partition by &lt;åˆ—å&gt;] [order by &lt;æ’åºåˆ—å&gt;] [window_frame]) å…¶ä¸­ï¼š &lt;çª—å£å‡½æ•°&gt;: æŒ‡éœ€è¦ä½¿ç”¨çš„åˆ†æå‡½æ•°ï¼Œå¦‚row_number()ã€sum()ç­‰ã€‚ over() : ç”¨æ¥æŒ‡å®šå‡½æ•°æ‰§è¡Œçš„çª—å£èŒƒå›´ï¼Œè¿™ä¸ªæ•°æ®çª—å£å¤§å°å¯èƒ½ä¼šéšç€è¡Œçš„å˜åŒ–è€Œå˜åŒ–ã€‚å¦‚æœæ‹¬å·ä¸­ä»€ä¹ˆéƒ½ä¸å†™ï¼Œåˆ™æ„å‘³ç€çª—å£åŒ…å«æ»¡è¶³whereæ¡ä»¶çš„æ‰€æœ‰è¡Œï¼Œçª—å£å‡½æ•°åŸºäºæ‰€æœ‰è¡Œè¿›è¡Œè®¡ç®— window_frame: åœ¨åˆ†ç»„çª—å£åŸºç¡€ä¸Šï¼Œå¯ä»¥è¿›ä¸€æ­¥æŒ‡å®šçª—å£è®¡ç®—è¾¹ç•Œ è®¾ç½®çª—å£1ï¼‰partition byå­å¥çª—å£åˆ’åˆ†åˆ†ç»„æ¡ä»¶ 12345SELECT uid, score, sum(score) OVER(PARTITION BY uid) AS sum_scoreFROM exam_record 2ï¼‰order byå­å¥çª—å£æ’åºæ¡ä»¶ 12345SELECT uid, score, sum(score) OVER(ORDER BY uid) AS sum_scoreFROM exam_record 3ï¼‰æŒ‡å®šçª—å£å¤§å°æŒ‡å®šçª—å£å¤§å°ï¼Œåˆç§°ä¸ºçª—å£æ¡†æ¶ã€‚æ¡†æ¶æ˜¯é‡æ–°å®šä¹‰çª—å£è®¡ç®—è¾¹ç•Œï¼Œæ¡†æ¶æœ‰ä¸¤ç§èŒƒå›´é™å®šæ–¹å¼ï¼š ä¸€ç§æ˜¯ä½¿ç”¨ ROWS å­å¥ï¼Œé€šè¿‡æŒ‡å®šå½“å‰è¡Œä¹‹å‰æˆ–ä¹‹åçš„å›ºå®šæ•°ç›®çš„è¡Œæ¥é™åˆ¶åˆ†åŒºä¸­çš„è¡Œæ•°ã€‚ å¦ä¸€ç§æ˜¯ä½¿ç”¨ RANGE å­å¥ï¼ŒæŒ‰ç…§æ’åˆ—åºåˆ—çš„å½“å‰å€¼ï¼Œæ ¹æ®ç›¸åŒå€¼æ¥ç¡®å®šåˆ†åŒºä¸­çš„è¡Œæ•°ã€‚ è¯­æ³•ORDER BY å­—æ®µå RANGE|ROWS è¾¹ç•Œè§„åˆ™0 | [BETWEEN è¾¹ç•Œè§„åˆ™1 AND è¾¹ç•Œè§„åˆ™2]ï¼Œè¾¹ç•Œè§„åˆ™çš„å¯å–å€¼å¦‚ä¸‹ï¼š current rowï¼šå½“å‰è¡Œ n precedingï¼šå½“å‰è¡ŒåŠå¾€å‰nè¡Œæ•°æ® unbounded precedingï¼šç¬¬ä¸€è¡Œè‡³å½“å‰è¡Œæ•°æ® n followingï¼šå½“å‰è¡ŒåŠå¾€ånè¡Œæ•°æ® unbounded followingï¼šå½“å‰è¡Œè‡³æœ€åä¸€è¡Œæ•°æ® éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ ä½¿ç”¨æ¡†æ¶æ—¶å¿…é¡»æœ‰order byå­å¥ è‹¥ä»…æœ‰order byå­å¥è€ŒæœªæŒ‡å®šæ¡†æ¶ï¼Œåˆ™é»˜è®¤æ¡†æ¶è¯­å¥ä¸ºrange unbounded preceding and current rowï¼Œè¯¦æƒ…è§æ–‡ç«  4ï¼‰window_nameç»™çª—å£æŒ‡å®šä¸€ä¸ªåˆ«åWINDOW my_window_name AS (PARTITION BY uid ORDER BY score)ï¼Œé€‚ç”¨äºä¸€ä¸ªçª—å£è¢«å¤šæ¬¡ä½¿ç”¨ï¼Œå¯ä»¥ä½¿sqlç®€æ´æ¸…æ™°ï¼Œä¹Ÿæ˜“äºç»´æŠ¤ 12345678910SELECT uid, score, rank() OVER my_window_name AS rk_num, row_number() OVER my_window_name AS row_num, dense_rank() OVER my_window_name AS dr_numFROM exam_recordWHERE score&gt;=60ORDER BY uidWINDOW my_window_name AS (PARTITION BY uid ORDER BY score) çª—å£å‡½æ•°åˆ†ç±»çª—å£å‡½æ•°ï¼š first_value: è¿”å›è®¡ç®—çª—å£å†…æŒ‰æ’åºæ¡ä»¶çš„ç¬¬ä¸€ä¸ªå€¼ï¼Œè¯­æ³•first_value(exp_str,true|false) last_value: è¿”å›è®¡ç®—çª—å£å†…æŒ‰æ’åºæ¡ä»¶çš„æœ€åä¸€ä¸ªå€¼ï¼Œè¯­æ³•last_value(exp_str,true|false) lag: è¿”å›ç›¸å¯¹å½“å‰è¡Œï¼Œç¬¬å‰nè¡Œçš„æ•°æ®ï¼Œè¯­æ³•lag(exp_str,offset,defval) over(partition by .. order by â€¦) lead: è¿”å›ç›¸å¯¹å½“å‰è¡Œï¼Œç¬¬ånè¡Œçš„æ•°æ®ï¼Œè¯­æ³•lead(exp_str,offset,defval) over(partition by .. order by â€¦) é…åˆoverè¯­å¥ä½¿ç”¨çš„èšåˆå‡½æ•°ï¼š sum count([distinct]) max min avg åˆ†æå‡½æ•°ï¼š row_number: è¿ç»­æ’åºâ€”â€”1ã€2ã€3ã€4 rank: å¹¶åˆ—è·³å·æ’åºâ€”â€”1ã€1ã€3ã€4 dense_rank: å¹¶åˆ—è¿ç»­æ’åºâ€”â€”1ã€1ã€2ã€3 percent_rank: å°†æŸä¸ªæ•°å€¼åœ¨æ•°æ®é›†ä¸­çš„rank()æ’ä½ä½œä¸ºæ•°æ®é›†çš„ç™¾åˆ†æ¯”å€¼è¿”å›ï¼Œæ¯è¡ŒæŒ‰ç…§å…¬å¼(rank-1) &#x2F; (rows-1)è¿›è¡Œè®¡ç®—ï¼Œç™¾åˆ†æ¯”å€¼çš„èŒƒå›´ä¸º 0 åˆ° 1ã€‚å¯ç”¨äºè®¡ç®—å€¼åœ¨æ•°æ®é›†å†…çš„ç›¸å¯¹ä½ç½®ã€‚è¯­æ³•percent_rank(exp_str) cume_dist: å¦‚æœæŒ‰å‡åºæ’åˆ—ï¼Œåˆ™ç»Ÿè®¡ï¼šå°äºç­‰äºå½“å‰å€¼çš„è¡Œæ•°&#x2F;æ€»è¡Œæ•°ã€‚ å¦‚æœæ˜¯é™åºæ’åˆ—ï¼Œåˆ™ç»Ÿè®¡ï¼šå¤§äºç­‰äºå½“å‰å€¼çš„è¡Œæ•°&#x2F;æ€»è¡Œæ•°ã€‚ è¯­æ³•cume_dist(exp_str) ntiles: å°†åˆ†ç»„æ•°æ®æŒ‰ç…§é¡ºåºå¹³å‡åˆ‡åˆ†æˆnç»„ï¼Œå¹¶è¿”å›å½“å‰åˆ‡ç‰‡å€¼ã€‚è¯­æ³•ntiles(n)ã€‚ å¦‚æœä¸èƒ½å¹³å‡åˆ†é…ï¼Œåˆ™ä¼˜å…ˆåˆ†é…è¾ƒå°ç¼–å·çš„åˆ‡ç‰‡ï¼Œå¹¶ä¸”å„ä¸ªåˆ‡ç‰‡ä¸­èƒ½æ”¾çš„è¡Œæ•°æœ€å¤šç›¸å·® 1ã€‚ å¯ç®€å•ç†è§£ä¸ºï¼Œæœ‰ n ä¸ªæ¡¶ï¼ŒæŒ‰ç¼–å· 1-n çš„é¡ºåºé€ä¸ªå°†åˆ†ç»„æ•°æ®æ”¾åˆ°æ¯ä¸ªæ¡¶å†…ï¼Œç›´è‡³æ•°æ®åˆ†é…å®Œæ¯•ã€‚","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"hiveSQL","slug":"hiveSQL","permalink":"https://llye-hub.github.io/tags/hiveSQL/"}]},{"title":"è¯»ä¹¦ç¬”è®°ä¹‹æ•°æ®ä»“åº“å·¥å…·ç®±ç»´åº¦å»ºæ¨¡æƒå¨æŒ‡å—(ç¬¬3ç‰ˆ)","slug":"é˜…è¯»ç¬”è®°/è¯»ä¹¦ç¬”è®°ä¹‹æ•°æ®ä»“åº“å·¥å…·ç®±ç»´åº¦å»ºæ¨¡æƒå¨æŒ‡å—-ç¬¬3ç‰ˆ","date":"2023-03-29T06:31:37.000Z","updated":"2023-03-31T09:48:37.146Z","comments":true,"path":"posts/4142350a.html","link":"","permalink":"https://llye-hub.github.io/posts/4142350a.html","excerpt":"","text":"ç¬¬1ç«  æ•°æ®ä»“åº“ã€å•†ä¸šæ™ºèƒ½åŠç»´åº¦å»ºæ¨¡åˆæ­¥æ“ä½œå‹ç³»ç»Ÿä¿å­˜æ•°æ®ï¼ŒDW&#x2F;BIç³»ç»Ÿä½¿ç”¨æ•°æ®ã€‚å¯¹ç…§æ•°æ®åº“æ¥çœ‹ï¼Œåç«¯åº”ç”¨ä½¿ç”¨mysqlæ•°æ®åº“ç”¨æ¥ä¿å­˜ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œæ•°æ®ä»“åº“åˆ™ä»mysqlæŠ½å–å¹¶ä½¿ç”¨è¿™äº›ç”¨æˆ·è¡Œä¸ºæ•°æ®ã€‚ DW&#x2F;BIç³»ç»Ÿç‰¹ç‚¹ï¼šæ•°æ®ç›´è§‚æ˜“ç†è§£ã€æ•°æ®è´¨é‡é«˜ã€æŒ‡æ ‡å£å¾„ä¸€è‡´ã€æ‰©å±•æ€§å¼ºã€æ•°æ®åŠ å·¥å¿«ã€æ•°æ®ä¿å¯†æ€§ã€æ•°æ®èƒ½æ”¯æŒä¸šåŠ¡å†³ç­–ã€ä¸šåŠ¡è®¤å¯ã€‚å…¶ä¸­ï¼Œæ•°æ®èƒ½æ”¯æŒä¸šåŠ¡å†³ç­–å’Œä¸šåŠ¡è®¤å¯æ˜¯æœ€èƒ½ä½“ç° DW&#x2F;BI ç³»ç»Ÿä»·å€¼çš„ä¸¤ç‚¹ï¼Œä¹Ÿæ˜¯ä»äº‹æ•°æ®ç›¸å…³è¡Œä¸šçš„æœ€ç»ˆä»·å€¼ç›®æ ‡ï¼Œä½†ç°å®å·¥ä½œä¸­çš„é«˜è®¤å¯åº¦å¾ˆéš¾è¾¾åˆ°ï¼Œæ›´æ˜¯ä¸€ç›´è¢«å¿½ç•¥ ç»´åº¦å»ºæ¨¡ç»´åº¦å»ºæ¨¡çš„ç‰¹ç‚¹ï¼š 1ã€æ¨¡å‹è®¾è®¡ç®€å•ï¼Œæ˜“äºç”¨æˆ·ç†è§£ 2ã€ä¸šåŠ¡è¿‡ç¨‹æ¸…æ™°ï¼ŒæŸ¥è¯¢æ€§èƒ½é«˜","categories":[{"name":"é˜…è¯»ç¬”è®°","slug":"é˜…è¯»ç¬”è®°","permalink":"https://llye-hub.github.io/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"https://llye-hub.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"å†…ç½®å‡½æ•°ä¹‹reflect","slug":"SQL/å†…ç½®å‡½æ•°ä¹‹reflect","date":"2023-03-22T09:39:53.000Z","updated":"2023-03-29T03:43:07.269Z","comments":true,"path":"posts/1d24daf8.html","link":"","permalink":"https://llye-hub.github.io/posts/1d24daf8.html","excerpt":"","text":"","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"å†…ç½®å‡½æ•°","slug":"å†…ç½®å‡½æ•°","permalink":"https://llye-hub.github.io/tags/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"}]},{"title":"æ­å»ºspark on yarnæºç è°ƒè¯•","slug":"spark/æ­å»ºspark-on-yarnæºç è°ƒè¯•","date":"2023-03-21T09:02:06.000Z","updated":"2023-03-29T03:43:07.272Z","comments":true,"path":"posts/5e1f3fb0.html","link":"","permalink":"https://llye-hub.github.io/posts/5e1f3fb0.html","excerpt":"","text":"å‚è€ƒæ–‡ç« Spark3.0.1å„ç§é›†ç¾¤æ¨¡å¼æ­å»ºåŠspark on yarnæ—¥å¿—é…ç½®Spark on Yarné›†ç¾¤æ­å»ºè¯¦ç»†è¿‡ç¨‹ ç¯å¢ƒå‡†å¤‡jdk8+Hadoop3.3.1 sparkçš„å‡ ç§éƒ¨ç½²æ–¹å¼Sparkä½œä¸ºå‡†å®æ—¶å¤§æ•°æ®è®¡ç®—å¼•æ“ï¼ŒSparkçš„è¿è¡Œéœ€è¦ä¾èµ–èµ„æºè°ƒåº¦å’Œä»»åŠ¡ç®¡ç†ï¼ŒSparkè‡ªå¸¦äº†standaloneæ¨¡å¼èµ„æºè°ƒåº¦å’Œä»»åŠ¡ç®¡ç†å·¥å…·ï¼Œè¿è¡Œåœ¨å…¶ä»–èµ„æºç®¡ç†å’Œä»»åŠ¡è°ƒåº¦å¹³å°ä¸Šï¼Œå¦‚Yarnã€Mesosã€Kubernateså®¹å™¨ç­‰ã€‚ sparkçš„æ­å»ºå’ŒHadoopå·®ä¸å¤šï¼Œä¸»è¦æœ‰ä¸‹é¢å‡ ç§éƒ¨ç½²æ–¹å¼ï¼š Localï¼šå¤šç”¨äºæœ¬åœ°æµ‹è¯•ï¼Œå¦‚åœ¨eclipseï¼Œideaä¸­å†™ç¨‹åºæµ‹è¯•ç­‰ã€‚ Standaloneï¼šStandaloneæ˜¯Sparkè‡ªå¸¦çš„ä¸€ä¸ªèµ„æºè°ƒåº¦æ¡†æ¶ï¼Œå®ƒæ”¯æŒå®Œå…¨åˆ†å¸ƒå¼ã€‚ Yarnï¼šHadoopç”Ÿæ€åœˆé‡Œé¢çš„ä¸€ä¸ªèµ„æºè°ƒåº¦æ¡†æ¶ï¼ŒSparkä¹Ÿæ˜¯å¯ä»¥åŸºäºYarnæ¥è®¡ç®—çš„ã€‚ åŸºäºä¸ªäººå­¦ä¹ éœ€æ±‚ï¼Œæœ¬æ–‡ä»…è®°å½•Localæ¨¡å¼éƒ¨ç½²è¿‡ç¨‹ã€‚ ä¸‹è½½sparkæºç ä¸‹è½½åœ°å€ è§£å‹ 1tar -zcvf spark-3.2.0-bin-hadoop3.2.tgz é…ç½®ç¯å¢ƒå˜é‡ 1234567# ç¼–è¾‘# SPARK_HOME=/Users/llye/workspace/spark-3.2.0-bin-hadoop3.2 # export PATH=$SPARK_HOME/bin:$PATHvi ~/.bash_profile # ç”Ÿæ•ˆsource ~/.bash_profile æœ¬åœ°localæ¨¡å¼æµ‹è¯•æ ·ä¾‹ 12cd $SPARK_HOME/bin run-example SparkPi 10 # å¯è®¡ç®—å‡ºç»“æœ 1spark-shell # å¯åŠ¨æˆåŠŸï¼Œè¯´æ˜Localæ¨¡å¼éƒ¨ç½²æˆåŠŸ å¯åŠ¨æˆåŠŸåï¼Œè®¿é—®http://localhost:4040/ å³å¯è¿›è¡Œweb UIç›‘æ§é¡µé¢è®¿é—® Standaloneæ¨¡å¼ï¼ˆæœªå®Œæˆï¼Œä¸å…·å‚è€ƒæ€§ï¼‰é…ç½®Spark on Yarné›†ç¾¤ ä¿®æ”¹spark-env.shæ–‡ä»¶ 12345678910111213cd $SPARK_HOME/confcat &gt; spark-env.sh &lt;&lt; EOFJAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home/SCALA_HOME=/Users/llye/soft/scala/HADOOP_HOME=/Users/llye/soft/hadoop-3.3.1/HADOOP_CONF_DIR=/Users/llye/soft/hadoop-3.3.1/etc/hadoop/YARN_CONF_DIR=/Users/llye/soft/hadoop-3.3.1/etc/hadoop/etc/hadoop/SPARK_MASTER_HOST=spark # ä¸»èŠ‚ç‚¹æœºå™¨åç§°SPARK_MASTER_PORT=7077 # é»˜è®¤ç«¯å£å·7077SPARK_HOME=/Users/llye/workspace/spark-3.2.0-bin-hadoop3.2/SPARK_LOCAL_DIRS=/Users/llye/workspace/spark-3.2.0-bin-hadoop3.2/SPARK_LIBARY_PATH=/Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home/lib/:/Users/llye/soft/hadoop-3.3.1/lib/native/EOF ä¿®æ”¹slavesé…ç½®æ–‡ä»¶ 1234cd $SPARK_HOME/sbin vi slaves# spark001# spark002 å°†sparkç›®å½•å‘é€åˆ°å…¶ä»–æœºå™¨ åˆ›å»ºworkersæ–‡ä»¶ï¼ŒæŒ‡å®šWorkerèŠ‚ç‚¹ï¼š 123456cd $SPARK_HOME/confcat &gt; workers &lt;&lt; EOFworker1worker2worker3EOF å¯åŠ¨Spark on Yarné›†ç¾¤1cd $SPARK_HOME/sbin åœ¨SparkèŠ‚ç‚¹ä¸Šå¯åŠ¨Spark MasterèŠ‚ç‚¹ï¼š 1start-master.sh åœ¨WorkerèŠ‚ç‚¹ä¸Šå¯åŠ¨Spark WorkerèŠ‚ç‚¹ï¼š 1start-worker.sh spark://spark:7077 ç™»å½•Spark on Yarné›†ç¾¤ç™»å½•Masterï¼š ç™»å½•Workerï¼šhttp://localhost:8081/","categories":[{"name":"spark","slug":"spark","permalink":"https://llye-hub.github.io/categories/spark/"}],"tags":[{"name":"spark on yarn","slug":"spark-on-yarn","permalink":"https://llye-hub.github.io/tags/spark-on-yarn/"}]},{"title":"hiveæœ¬æœºå®‰è£…","slug":"hive/hiveæœ¬æœºå®‰è£…","date":"2023-03-15T02:49:23.000Z","updated":"2023-03-27T05:47:19.779Z","comments":true,"path":"posts/47d5b7b0.html","link":"","permalink":"https://llye-hub.github.io/posts/47d5b7b0.html","excerpt":"","text":"å‚è€ƒæ–‡ç«  Hiveæºç ç³»åˆ—ï¼ˆä¸€ï¼‰hive2.1.1+hadoop2.7.3ç¯å¢ƒæ­å»º Hiveå®‰è£…è¶…è¯¦ç»†æ•™ç¨‹ Hiveæ¶æ„ä¸æºç åˆ†æ Hive:æºç è§£æä¹‹æœ¬åœ°ç¯å¢ƒæ­å»º ç¯å¢ƒå‡†å¤‡jdk8 + Hadoop3.3.1 ä¸‹è½½å®‰è£…ä¸‹è½½åœ°å€ è§£å‹å®‰è£…åŒ… 1tar -zxvf apache-hive-2.3.9-bin.tar.gz ç¯å¢ƒå˜é‡é…ç½® 12345678910# ç¼–è¾‘# HIVE_HOME=/Users/llye/soft/hive-2.3.9# export PATH=$HIVE_HOME/bin:$PATHvi ~/.bash_profile # ç”Ÿæ•ˆsource ~/.bash_profile# éªŒè¯hive --version ä¿®æ”¹é…ç½®æ–‡ä»¶ 1cd $HIVE_HOME/conf vi hive-site.xmlç¼–è¾‘å†…å®¹å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;configuration&gt; &lt;!-- ä»¥mysqlä½œä¸ºhiveå…ƒæ•°æ®åº“ --&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost:3306/hivedb?createDatabaseIfNotExist=true&amp;amp;characterEncoding=UTF-8&amp;amp;useSSL=false&amp;amp;serverTimezone=GMT&lt;/value&gt; &lt;description&gt;hive metastoreè¿æ¥ä¸²&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;/value&gt; &lt;description&gt;Hive metastore JDBCé©±åŠ¨&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;Mysqlç™»å½•è´¦å·&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;rootroot&lt;/value&gt; &lt;description&gt;Mysqlç™»å½•å¯†ç &lt;/description&gt; &lt;/property&gt; &lt;!-- å¿½ç•¥HIVE å…ƒæ•°æ®åº“ç‰ˆæœ¬çš„æ ¡éªŒï¼Œå¦‚æœéè¦æ ¡éªŒå°±å¾—è¿›å…¥MYSQLå‡çº§ç‰ˆæœ¬ --&gt; &lt;property&gt; &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.current.db&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.cli.print.header&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- é…ç½®hiveç”¨æˆ·åã€å¯†ç  --&gt; &lt;property&gt; &lt;name&gt;hive.jdbc_passwd.auth.root&lt;/name&gt; &lt;value&gt;rootroot&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.jdbc_passwd.auth.llye&lt;/name&gt; &lt;value&gt;rootroot&lt;/value&gt; &lt;/property&gt; &lt;!-- hiveserver2 --&gt; &lt;!-- é…ç½®ç”¨æˆ·å®‰å…¨è®¤è¯æ–¹å¼ --&gt; &lt;property&gt; &lt;name&gt;hive.server2.authentication&lt;/name&gt; &lt;value&gt;NONE&lt;/value&gt; &lt;description&gt; Expects one of [nosasl, none, ldap, kerberos, pam, custom]. Client authentication types. NONE: no authentication check LDAP: LDAP/AD based authentication KERBEROS: Kerberos/GSSAPI authentication CUSTOM: Custom authentication provider (Use with property hive.server2.custom.authentication.class) PAM: Pluggable authentication module NOSASL: Raw transport &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.custom.authentication.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hive.contrib.auth.CustomPasswdAuthenticator&lt;/value&gt; &lt;description&gt;é…ç½®ç”¨äºæƒé™è®¤è¯çš„ç±»ã€è¿™é‡Œå®é™…æ²¡æœ‰ã€‘&lt;/description&gt; &lt;/property&gt; &lt;!-- æŒ‡å®š hiveserver2 jdbcè¿æ¥çš„ host+port --&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt; &lt;value&gt;localhost&lt;/value&gt; &lt;description&gt;hiveserver2 jdbcè¿æ¥çš„ host&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.port&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;description&gt;hiveserver2 jdbcè¿æ¥çš„ç«¯å£å·&lt;/description&gt; &lt;/property&gt; &lt;!-- é…ç½®webUIç•Œé¢ host+port --&gt; &lt;property&gt; &lt;name&gt;hive.server2.webui.host&lt;/name&gt; &lt;value&gt;localhost&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.webui.port&lt;/name&gt; &lt;value&gt;10002&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; ä¸‹è½½è¿æ¥MySQLçš„é©±åŠ¨åŒ…åˆ°hiveçš„libç›®å½•ä¸‹ mysql-connector-java-8.0.17.jarä¸‹è½½åœ°å€ åˆå§‹åŒ–hiveå…ƒæ•°æ®åº“ 12cd $HIVE_HOME/binschematool -initSchema -dbType mysql -verbose éªŒè¯åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ 12-- mysqlçš„hivedbåº“ä¸­ï¼Œè‹¥å±•ç¤ºå¤šä¸ªæ•°æ®è¡¨ï¼Œå³ä»£è¡¨åˆå§‹åŒ–æˆåŠŸshow tables; å¯åŠ¨hive 1234$HADOOP_HOME/sbin/start-dfs.sh &amp;$HADOOP_HOME/sbin/start-yarn.shcd $HIVE_HOME hive é‡åˆ°å¯åŠ¨æŠ¥é”™org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /tmp/hiveæ—¶ï¼Œæ‰§è¡Œå‘½ä»¤hdfs dfsadmin -safemode leaveå…³é—­HDFSå®‰å…¨æ¨¡å¼ éªŒè¯ 123456-- å»ºè¡¨create table student(id int, name string);-- æ’å…¥æ•°æ®insert into table student values(1, &#x27;abc&#x27;);-- æŸ¥è¯¢æ•°æ®select * from student; beelineè¿æ¥hiveserver2hadoopé…ç½® 1cd $HADOOP_HOME/etc/hadoop vi core-site.xmlè¡¥å……å†…å®¹å¦‚ä¸‹ï¼š 12345678910111213141516&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.llye.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.llye.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; é‡å¯hadoop 12$HADOOP_HOME/sbin/stop-all.sh &amp;$HADOOP_HOME/sbin/start-all.sh å¯åŠ¨metastore é…ç½®äº†hiveçš„ç¯å¢ƒå˜é‡ï¼Œä»»æ„æ–‡ä»¶å¤¹ä¸‹æ‰§è¡Œå³å¯ 1hive --service metastore å¯åŠ¨hiveserver2 é…ç½®äº†hiveçš„ç¯å¢ƒå˜é‡ï¼Œä»»æ„æ–‡ä»¶å¤¹ä¸‹æ‰§è¡Œå³å¯ 123hiveserver2# æˆ–hive --service hiveserver2 è‹¥å¯åŠ¨å¤±è´¥ï¼Œæ£€æŸ¥1000ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼Œå‘½ä»¤lsof -i:10000å’Œkill -9 xxx beelineè¿æ¥ 1234beelinebeeline&gt; !connect jdbc:hive2://localhost:10000/default# æˆ–beeline -u jdbc:hive2://localhost:10000/default é‡åˆ°æŠ¥é”™é—®é¢˜çš„å‚è€ƒï¼š beelineè¿æ¥hiveserver2æŠ¥é”™ï¼šUser: root is not allowed to impersonate root Hive JDBCï¼šPermission denied: user&#x3D;anonymous, access&#x3D;EXECUTE, inode&#x3D;â€&#x2F;tmpâ€ å®¢æˆ·ç«¯jdbcè¿æ¥hiveåº“å¯åŠ¨metastoreå’Œhiveserver2 12345hive --service metastorehiveservice2# æˆ–hive --service hiveserver2 DBeaverè¿æ¥ï¼Œè®¾ç½®jdbc URLï¼šjdbc:hive2://localhost:10000/default hiveæºç ç¼–è¯‘è§£å‹å®‰è£…åŒ… 1tar -zxvf apache-hive-2.3.9-src.tar.gz ç¼–è¯‘æºç  è¿›å…¥è§£å‹ç›®å½• 1mvn clean package -DskipTests -Phadoop-2 -Pdist ç¼–è¯‘è¿‡ç¨‹ä¸­æŠ¥é”™An error has occurred in JavaDocs report generation:Exit code: 1 - javadoc: error - invalid flag: -authorï¼Œè§£å†³æ–¹æ¡ˆ: 1234567891011121314151617181920212223242526&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.javadoc.plugin.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;resourcesdoc.xml&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;javadoc&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;configuration&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;show&gt;public&lt;/show&gt; &lt;doclet&gt;com.sun.jersey.wadl.resourcedoc.ResourceDoclet&lt;/doclet&gt; &lt;docletArtifacts&gt; â€¦â€¦ &lt;/docletArtifacts&gt; &lt;additionalparam&gt;-output $&#123;project.build.outputDirectory&#125;/resourcedoc.xml&lt;/additionalparam&gt; &lt;!-- pomæ–‡ä»¶ä¸­åŠ ä¸Šæ­¤é¡¹é…ç½® --&gt; &lt;useStandardDocletOptions&gt;false&lt;/useStandardDocletOptions&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; å¯¼å…¥idea ä»hiveçš„è§£å‹ç›®å½•ä¸­é€‰æ‹©pom.xmlæ–‡ä»¶å¯¼å…¥ è°ƒè¯•ä»£ç  è¿›å…¥è§£å‹ç›®å½• 123cd packaging/target/apache-hive-2.3.9-bin/apache-hive-2.3.9-binhive --debug -hiveconf hive.root.logger=DEBUG,console æˆåŠŸæ—¶ï¼Œç•Œé¢å‡ºç°ï¼š 1Listening for transport dt_socket at address: 8000 JVMä¼šç›‘å¬8000ç«¯å£ï¼Œç­‰å¾…å®¢æˆ·ç«¯è°ƒè¯•è¿æ¥ã€‚ è¿›å…¥ideaé…ç½®è¿œç¨‹è¿æ¥å¦‚ä¸‹ï¼š hiveçš„CLIçš„å…¥å£ç±»ä¸ºï¼šsrc/java/org/apache/hadoop/hive/cli/CliDriver.javaï¼Œæ–­ç‚¹è°ƒè¯•æˆåŠŸå¦‚ä¸‹ï¼š","categories":[{"name":"hive","slug":"hive","permalink":"https://llye-hub.github.io/categories/hive/"}],"tags":[{"name":"hiveå®‰è£…","slug":"hiveå®‰è£…","permalink":"https://llye-hub.github.io/tags/hive%E5%AE%89%E8%A3%85/"}]},{"title":"hadoopæœ¬æœºå®‰è£…","slug":"hadoop/hadoopæœ¬æœºå®‰è£…","date":"2023-03-15T02:49:02.000Z","updated":"2023-03-17T08:31:42.984Z","comments":true,"path":"posts/2cb81866.html","link":"","permalink":"https://llye-hub.github.io/posts/2cb81866.html","excerpt":"","text":"å‚è€ƒæ–‡ç«  Hiveæºç ç³»åˆ—ï¼ˆä¸€ï¼‰hive2.1.1+hadoop2.7.3ç¯å¢ƒæ­å»º Hadoopã€å•æœºå®‰è£…-æµ‹è¯•ç¨‹åºWordCountã€‘ Hadoop å®‰è£…æœ‰ä¸‰ç§æ–¹å¼ï¼š å•æœºæ¨¡å¼ï¼šå®‰è£…ç®€å•ï¼Œå‡ ä¹ä¸ç”¨åšä»»ä½•é…ç½®ï¼Œä½†ä»…é™äºè°ƒè¯•ç”¨é€”ï¼› ä¼ªåˆ†å¸ƒæ¨¡å¼ï¼šåœ¨å•èŠ‚ç‚¹ä¸ŠåŒæ—¶å¯åŠ¨ NameNodeã€DataNodeã€JobTrackerã€TaskTrackerã€Secondary Namenode ç­‰ 5 ä¸ªè¿›ç¨‹ï¼Œæ¨¡æ‹Ÿåˆ†å¸ƒå¼è¿è¡Œçš„å„ä¸ªèŠ‚ç‚¹ï¼› å®Œå…¨åˆ†å¸ƒå¼æ¨¡å¼ï¼šæ­£å¸¸çš„ Hadoop é›†ç¾¤ï¼Œç”±å¤šä¸ªå„å¸å…¶èŒçš„èŠ‚ç‚¹æ„æˆã€‚ æœ¬äººé€‰æ‹©çš„æ˜¯ä¼ªåˆ†å¸ƒæ¨¡å¼å®‰è£… ä¸‹è½½å®‰è£… ä¸‹è½½åœ°å€ è§£å‹å®‰è£…åŒ…1tar -zxvf hadoop-3.3.1.tar.gz ç¯å¢ƒå˜é‡é…ç½® 12345678910# ç¼–è¾‘# HADOOP_HOME=/Users/llye/soft/hadoop-3.3.1# export PATH=$HADOOP_HOME/bin:$PATHvi ~/.bash_profile # ç”Ÿæ•ˆsource ~/.bash_profile# éªŒè¯hadoop version ä¿®æ”¹é…ç½®æ–‡ä»¶ 1cd $HADOOP_HOME/etc/hadoop vi core-site.xmlç¼–è¾‘å†…å®¹å¦‚ä¸‹ï¼š 1234567&lt;configuration&gt;&lt;!-- é…ç½®åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿçš„schemaå’Œipä»¥åŠport,é»˜è®¤8020--&gt;&lt;property&gt;&lt;name&gt;fs.defaultFS&lt;/name&gt;&lt;value&gt;hdfs://localhost:8020&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; vi hdfs-site.xmlç¼–è¾‘å†…å®¹å¦‚ä¸‹ï¼š 1234567&lt;configuration&gt;&lt;!-- é…ç½®å‰¯æœ¬æ•°ï¼Œæ³¨æ„ï¼Œä¼ªåˆ†å¸ƒæ¨¡å¼åªèƒ½æ˜¯1ã€‚--&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt;&lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; vi hadoop-env.shç¼–è¾‘å†…å®¹å¦‚ä¸‹ï¼š 1export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_301.jdk/Contents/Home vi mapred-site.xmlç¼–è¾‘å†…å®¹å¦‚ä¸‹ï¼š 12345678910111213141516171819&lt;configuration&gt;&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; vi yarn-site.xmlç¼–è¾‘å†…å®¹å¦‚ä¸‹ï¼š 12345678&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; sshå…å¯†ç ç™»å½• 123ssh-keygen -t rsa -P &#x27;&#x27; -f ~/.ssh/id_rsacat ~/.ssh/id_rsa.pub&gt;&gt; ~/.ssh/authorized_keyschmod 0600~/.ssh/authorized_keys ä»¥å‰å®‰è£…å…¶ä»–è½¯ä»¶å·²æ“ä½œè¿‡ï¼Œæ‰€ä»¥æ­¤æ­¥éª¤å¿½ç•¥ æ ¼å¼åŒ–namenode 1hdfs namenode -format å¿½ç•¥SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1 æœ‰INFO common.Storage: Storage directory /tmp/hadoop-llye/dfs/name has been successfully formatted.å³è¯´æ˜æ“ä½œæˆåŠŸã€‚ å¯åŠ¨ 12$HADOOP_HOME/sbin/start-dfs.sh &amp;$HADOOP_HOME/sbin/start-yarn.sh éªŒè¯ 12345678910root@localhost hadoop % jps11440 11169 74514 NameNode # åç§°èŠ‚ç‚¹74756 SecondaryNameNode74999 ResourceManager75098 NodeManager75834 Jps19771 Launcher74620 DataNode # æ•°æ®èŠ‚ç‚¹ è®¿é—®UIï¼šip+port All Applicationsï¼šhttp://localhost:8088/cluster/apps Applications running on this nodeï¼šhttp://localhost:8042/node/allApplications Browse Hdfsï¼šhttp://localhost:9870/ è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå› ä¸ºå®‰è£…çš„æ˜¯3.xç‰ˆæœ¬ï¼Œæ‰€ä»¥ç«¯å£å·ä¸º9870 è‹¥å®‰è£…çš„æ˜¯2.xç‰ˆæœ¬ï¼Œåˆ™ç«¯å£å·ä¸º50070 æµ‹è¯•ç¨‹åº æµ‹è¯•ä¸€ 12cd $HADOOP_HOMEhadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar pi 2 100 æµ‹è¯•äºŒ 123456789101112131415161718192021222324252627cd $HADOOP_HOME# åˆ›å»ºä¸€ä¸ªhdfsç›®å½•hdfs dfs -mkdir /wordcount# é€ æ•°æ®# hello hadoop# hello world# hello hadoop# hello hangzhou# hello hangzhou# hello hadoopmkdir wordCountcd wordCounttouch wc.inputvi wc.inputcat wc.input# ä¸Šä¼ æœ¬åœ°æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•hdfs dfs -put wc.input /wordcount# è¿è¡Œmrç¨‹åºcd $HADOOP_HOMEhadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar wordcount /wordcount/ /wordcount/output# æŸ¥çœ‹mrè®¡ç®—ç»“æœhadoop fs -cat /wordcount/output/part-r-00000 åœæ­¢ 12$HADOOP_HOME/sbin/stop-dfs.sh &amp;$HADOOP_HOME/sbin/stop-yarn.sh","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://llye-hub.github.io/categories/hadoop/"}],"tags":[{"name":"hadoopå®‰è£…","slug":"hadoopå®‰è£…","permalink":"https://llye-hub.github.io/tags/hadoop%E5%AE%89%E8%A3%85/"}]},{"title":"ç»ˆç«¯å¸¸ç”¨å‘½ä»¤æ±‡æ€»","slug":"shell/ç»ˆç«¯å¸¸ç”¨å‘½ä»¤æ±‡æ€»","date":"2023-03-15T02:29:05.000Z","updated":"2023-03-21T08:09:18.234Z","comments":true,"path":"posts/84fddb38.html","link":"","permalink":"https://llye-hub.github.io/posts/84fddb38.html","excerpt":"","text":"è·å–æœ¬æœºipåœ°å€12345678910#!/bin/shlocal_ip=`ifconfig -a|grep inet|grep -v 127.0.0.1|grep -v inet6|awk &#x27;&#123;print $2&#125;&#x27;|tr -d &quot;addr:&quot;â€‹`echo &quot;$&#123;local_ip&#125;&quot;ifconfig -a //å’Œwindowä¸‹æ‰§è¡Œæ­¤å‘½ä»¤ä¸€æ ·é“ç†ï¼Œè¿”å›æœ¬æœºæ‰€æœ‰ipä¿¡æ¯grep inet //æˆªå–åŒ…å«ipçš„è¡Œgrep -v 127.0.0.1 //å»æ‰æœ¬åœ°æŒ‡å‘çš„é‚£è¡Œgrep -v inet6 //å»æ‰åŒ…å«inet6çš„è¡Œawk &#123; print $2&#125; //$2 è¡¨ç¤ºé»˜è®¤ä»¥ç©ºæ ¼åˆ†å‰²çš„ç¬¬äºŒç»„ åŒç† $1è¡¨ç¤ºç¬¬ä¸€ç»„â€‹tr -d &quot;addr:&quot; //åˆ é™¤&quot;addr:&quot;è¿™ä¸ªå­—ç¬¦ä¸² https://blog.csdn.net/finghting321/article/details/108476650 æŸ¥æ‰¾æ–‡ä»¶1find / -iname $filename 2&gt; /dev/null","categories":[{"name":"shell","slug":"shell","permalink":"https://llye-hub.github.io/categories/shell/"}],"tags":[{"name":"shellå‘½ä»¤","slug":"shellå‘½ä»¤","permalink":"https://llye-hub.github.io/tags/shell%E5%91%BD%E4%BB%A4/"}]},{"title":"ç»ˆç«¯å…å¯†ç™»å½•mysql","slug":"shell/ç»ˆç«¯å…å¯†ç™»å½•mysql","date":"2023-03-14T07:29:49.000Z","updated":"2023-03-14T08:04:15.277Z","comments":true,"path":"posts/b31f5f52.html","link":"","permalink":"https://llye-hub.github.io/posts/b31f5f52.html","excerpt":"","text":"å‚è€ƒèµ„æ–™ï¼šMysql Shellå…å¯†ç™»å½•çš„æ€è€ƒåŠå®é™…åº”ç”¨æ¡ˆä¾‹ å¸¸è§ç»ˆç«¯ç™»å½•mysqlçš„æ–¹å¼æ˜¯é€šè¿‡å‘½ä»¤mysql -u&#123;user&#125; -p&#123;password&#125;ï¼Œæ¯æ¬¡ç™»å½•éƒ½éœ€è¦è¾“å…¥ä¸€é•¿ä¸²å‘½ä»¤å’Œå‚æ•°ï¼Œæˆ‘è§‰å¾—éº»çƒ¦ï¼Œä¸”è¿™ç§æ–¹å¼ä¸‹å¯†ç ç›´æ¥æš´éœ²å‡ºæ¥æ˜¯ä¸å®‰å…¨çš„ è™½ç„¶ä¹Ÿå¯ç”¨å‘½ä»¤mysql -u&#123;user&#125; -p + æ‰‹åŠ¨è¾“å…¥å¯†ç ï¼Œä¹Ÿæ˜¯éº»çƒ¦çš„ï¼Œè€Œä¸”è¿˜è¦è®°å¯†ç  æ‰€ä»¥ï¼Œå¦‚æœä»…ç”¨å‘½ä»¤mysqlå³å¯å®ç°ç™»å½•ï¼Œé‚£å¾—å¤šæ–¹ä¾¿ ä»ç½‘ä¸Šæœç´¢åå‘ç°ï¼Œå¯ä»¥é€šè¿‡æ˜æ–‡é…ç½®æ–‡ä»¶çš„æ–¹å¼å®ç°mysqlå…å¯†ç™»å½• å…·ä½“å‘½ä»¤å¦‚ä¸‹ï¼š 1234567891011121314# ç¼–è¾‘é…ç½®æ–‡ä»¶# [mysql]# user=xxx# password=xxxsudo vi /etc/my.cnf# æŸ¥çœ‹æ–‡ä»¶å†…å®¹cat /etc/my.cnf# æŒ‡å®šmysql serverä»…ä»è¿™ä¸ªé…ç½®æ–‡ä»¶è¯»å–å‚æ•°mysql --defaults-file=/etc/my.cnf# éªŒè¯è¯»å–é…ç½®æƒ…å†µmysql --defaults-file=/etc/my.cnf --print-defaults","categories":[{"name":"shell","slug":"shell","permalink":"https://llye-hub.github.io/categories/shell/"}],"tags":[{"name":"å…å¯†ç™»å½•","slug":"å…å¯†ç™»å½•","permalink":"https://llye-hub.github.io/tags/%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"}]},{"title":"sqlç»ƒä¹ ä¹‹è¿ç»­ç™»å½•é—®é¢˜","slug":"é¢˜é›†/sqlç»ƒä¹ ä¹‹è¿ç»­ç™»å½•é—®é¢˜","date":"2023-03-10T08:22:38.000Z","updated":"2023-03-13T02:51:54.944Z","comments":true,"path":"posts/67cc9ac.html","link":"","permalink":"https://llye-hub.github.io/posts/67cc9ac.html","excerpt":"","text":"é¢˜ç›®æ¥æº é¢˜ç›®è¦æ±‚æ±‚å‡ºè¿ç»­3å¤©ç™»å½•çš„ç”¨æˆ·id æ•°æ®12345678910111213141516CREATE TABLE if not exists one.user_login( id int COMMENT &#x27;ç”¨æˆ·ä¸»é”®&#x27;, dt varchar(20) COMMENT &#x27;ç™»å½•æ—¥æœŸ&#x27; );insert into user_login values(1001,&#x27;2021-12-12&#x27;);insert into user_login values(1002,&#x27;2021-12-12&#x27;);insert into user_login values(1001,&#x27;2021-12-13&#x27;);insert into user_login values(1001,&#x27;2021-12-14&#x27;);insert into user_login values(1001,&#x27;2021-12-16&#x27;);insert into user_login values(1002,&#x27;2021-12-16&#x27;);insert into user_login values(1001,&#x27;2021-12-19&#x27;);insert into user_login values(1002,&#x27;2021-12-17&#x27;);insert into user_login values(1001,&#x27;2021-12-20&#x27;); è§£é¢˜è§£æ³•ä¸€ï¼šè‡ªå…³è”12345678910111213141516171819202122232425select distinct idfrom ( SELECT id from ( select a.id , a.dt as dt1 , b.dt as dt2 from user_login a left join user_login b on a.id = b.id and (b.dt between DATE_SUB(a.dt, interval 2 day) and a.dt) ) tmp1 group by id, dt1 having count(1) = 3 )tmp2;","categories":[{"name":"é¢˜é›†","slug":"é¢˜é›†","permalink":"https://llye-hub.github.io/categories/%E9%A2%98%E9%9B%86/"}],"tags":[{"name":"sqlç»ƒä¹ ","slug":"sqlç»ƒä¹ ","permalink":"https://llye-hub.github.io/tags/sql%E7%BB%83%E4%B9%A0/"}]},{"title":"SQLä¹‹çª—å£å‡½æ•°çš„è¾¹ç•Œ","slug":"SQL/SQLä¹‹çª—å£å‡½æ•°çš„è¾¹ç•Œ","date":"2023-02-28T08:25:40.000Z","updated":"2023-03-01T07:30:20.176Z","comments":true,"path":"posts/5af52219.html","link":"","permalink":"https://llye-hub.github.io/posts/5af52219.html","excerpt":"","text":"å‰è¨€çª—å£å‡½æ•°å¸¸ç”¨äºåœ¨SQLæ•°æ®åˆ†æè®¡ç®—å„ç§ç»Ÿè®¡æŒ‡æ ‡ï¼Œä¹Ÿæ˜¯æ—¥å¸¸sqlå¼€å‘ä¸­å¸¸è§çš„å‡½æ•°äº†ï¼Œä½†æ˜¯æœ€è¿‘å‘ç°è‡ªå·±åœ¨è¿™æ–¹é¢å­˜åœ¨ä¸€äº›è¯¯è§£ æ¯”å¦‚ä¸‹é¢è¿™æ®µsql 1234select col1 ,sum(col2) over(partition by col1 order by col3) as sum1 ,sum(col2) over(partition by col1) as sum2from (select * from (VALUES(&#x27;a&#x27;,1,4),(&#x27;a&#x27;,2,7),(&#x27;a&#x27;,3,6)) t(col1,col2,col3)) a ç¬¬ä¸€çœ¼æ„Ÿè§‰sum1å’Œsum2å­—æ®µè®¡ç®—å€¼æ˜¯ä¸€æ ·çš„ï¼Œä½†å®é™…è¿è¡Œå‡ºæ¥çš„ç»“æœä¸º(mysql+hiveSQL) col1 sum1 sum2 a 1 6 a 4 6 a 6 6 ä»æ‰§è¡Œç»“æœä¸Šæ¥çœ‹ï¼Œsum1å­—æ®µä¸ºçª—å£å†…çš„ç´¯åŠ å€¼ï¼Œsum2å­—æ®µå€¼ä¸ºçª—å£å†…æ‰€æœ‰å€¼ä¹‹å’Œ ä¸ºä»€ä¹ˆæœ‰æ— order byå·®å¼‚è¿™ä¹ˆå¤§æœ‰äººä¼šè¯´ï¼Œèšåˆå‡½æ•°sum()çš„çª—å£å†…æœ‰order byå­å¥æ—¶ï¼Œè®¡ç®—ç»“æœæœ¬å°±æ˜¯ç´¯åŠ æ€§è´¨ã€‚ä»æ‰§è¡Œç»“æœä¸Šæ¥çœ‹ï¼Œè¿™ä¹ˆè¯´æ˜¯å¯¹çš„ï¼Œä½†æ˜¯è¿™ç§è§£é‡Šå¤ªæµäºè¡¨é¢ï¼Œå¹¶æ²¡æœ‰çœŸæ­£ä»å‡½æ•°å®šä¹‰ä¸Šè§£é‡Šä¸ºä»€ä¹ˆ è¿™é‡Œé‡æ–°å›é¡¾ä¸‹çª—å£å‡½æ•°åŸºæœ¬è¯­æ³•ï¼š 1&lt;window_function&gt; over (partition by &lt;column_name&gt; order by &lt;column_name&gt; &lt;window_frame&gt;) ä¸»è¦æœ‰å››ä¸ªéƒ¨åˆ†ï¼š window_functionï¼šå‡½æ•°ï¼Œæ¯”å¦‚ï¼šsumã€row_numberã€first_value partition byï¼šçª—å£åˆ†åŒºå­å¥ order byï¼šçª—å£æ’åºå­å¥ window_frameï¼šçª—å£æ¡†æ¶ï¼Œé™åˆ¶çª—å£çš„è¾¹ç•Œå¤§å° å¯¹ç…§åŸºæœ¬è¯­æ³•ï¼Œæœ‰order byå­å¥çš„æ‰§è¡Œç»“æœå°±æ˜¯è®¡ç®—çª—å£è¾¹ç•Œä¸ºèµ·å§‹è¡Œè‡³å½“å‰è¡Œçš„sumç»“æœï¼Œå³sum(col2) over(partition by col1 order by col3)ç­‰åŒäºsum(col2) over(partition by col1 order by col3 rows between unbounded preceding and current row) çª—å£å‡½æ•°çš„å®˜æ–¹è¯´æ˜mysqlå®˜æ–¹æ–‡æ¡£ hiveå®˜æ–¹æ–‡æ¡£ mysqlå…³äºçª—å£å‡½æ•°çš„window_frameæœ‰å¦‚ä¸‹è¯´æ˜ï¼š hiveå…³äºçª—å£å‡½æ•°çš„window_frameæœ‰å¦‚ä¸‹è¯´æ˜ï¼š æ ¹æ®ä»¥ä¸Šå®˜æ–¹è¯´æ˜å¯çŸ¥ï¼Œå½“window_frameå­å¥å’Œorder byå­å¥éƒ½æ²¡æœ‰æ—¶ï¼Œçª—å£è®¡ç®—é»˜è®¤åŒ…å«çª—å£å†…çš„æ‰€æœ‰æ•°æ®ï¼Œå³window_frame=ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWINGï¼›å½“ä»…æœ‰order byå­å¥ï¼Œæ²¡æœ‰window_frameå­å¥æ—¶ï¼Œçª—å£è®¡ç®—é»˜è®¤ä»…åŒ…å«æ’åºåèµ·å§‹è¡Œè‡³å½“å‰è¡Œçš„æ•°æ®ï¼Œå³window_frame=ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"çª—å£å‡½æ•°","slug":"çª—å£å‡½æ•°","permalink":"https://llye-hub.github.io/tags/%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/"}]},{"title":"å…³äºJava PriorityQueueç±»çš„ä½¿ç”¨åœºæ™¯","slug":"é¢˜é›†/å…³äºJava-PriorityQueueç±»çš„ä½¿ç”¨åœºæ™¯","date":"2023-02-23T08:53:35.000Z","updated":"2023-03-29T03:42:57.496Z","comments":true,"path":"posts/76a5661e.html","link":"","permalink":"https://llye-hub.github.io/posts/76a5661e.html","excerpt":"","text":"æœ€è¿‘åœ¨leetcodeåˆ·é¢˜çš„æ—¶å€™ï¼Œå‘ç°å¾ˆå¤šé¢˜æ¨èè§£æ³•æ˜¯ç”¨ä¼˜å…ˆé˜Ÿåˆ—çš„ç‰¹æ€§ï¼Œæ¯”å¦‚ï¼šæ»‘åŠ¨çª—å£çš„æœ€å¤§å€¼ ã€ä¸‘æ•° ä»¥å‰å®Œå…¨æ²¡æœ‰ç”¨ä¸ªè¿™ä¸ªç±»ï¼Œæ‰€ä»¥åœ¨æ­¤æ•´ç†ä¸€ä¸‹å¯¹ä¼˜å…ˆé˜Ÿåˆ—çš„è®¤è¯†å’Œåˆ·é¢˜åœºæ™¯ ä¼˜å…ˆé˜Ÿåˆ—çš„ç‰¹æ€§å¾ˆæ˜æ˜¾ï¼Œä¼˜å…ˆé˜Ÿåˆ—ä¹Ÿæ˜¯ä¸€ç§é˜Ÿåˆ—ï¼Œåªä¸è¿‡å…¶å‡ºé˜Ÿé¡ºåºå’Œä¸€èˆ¬é˜Ÿåˆ—ä¸åŒï¼Œä¼˜å…ˆé˜Ÿåˆ—çš„å‡ºé˜Ÿé¡ºåºæ˜¯æŒ‰ç…§ä¸€å®šçš„ä¼˜å…ˆçº§æ¥çš„ï¼Œä¹Ÿå°±æ˜¯è¯´å‡ºé˜Ÿè§„åˆ™å¯ä»¥éšæ„å®šåˆ¶ ä¼˜å…ˆé˜Ÿåˆ—ADTæ˜¯ä¸€ç§æ•°æ®ç»“æ„ï¼Œå®ƒæ”¯æŒæ’å…¥ã€åˆ é™¤æœ€å°å€¼æ“ä½œï¼ˆè¿”å›å¹¶åˆ é™¤æœ€å°å…ƒç´ ï¼‰ã€åˆ é™¤æœ€å¤§å€¼æ“ä½œï¼ˆè¿”å›å¹¶åˆ é™¤æœ€å¤§å…ƒç´ ï¼‰ ä¼˜å…ˆé˜Ÿåˆ—çš„ä¸»è¦æ“ä½œï¼šä¼˜å…ˆé˜Ÿåˆ—æ˜¯å…ƒç´ çš„å®¹å™¨ï¼Œæ¯ä¸ªå…ƒç´ æœ‰ä¸€ä¸ªç›¸å…³çš„é”®å€¼ insert(key, data)ï¼šæ’å…¥é”®å€¼ä¸ºkeyçš„æ•°æ®åˆ°ä¼˜å…ˆé˜Ÿåˆ—ä¸­ï¼Œå…ƒç´ ä»¥å…¶keyè¿›è¡Œæ’åº deleteMin&#x2F;deleteMaxï¼šåˆ é™¤å¹¶è¿”å›æœ€å°&#x2F;æœ€å¤§é”®å€¼çš„å…ƒç´  getMinimum&#x2F;getMaximumï¼šè¿”å›æœ€å°&#x2F;æœ€å¤§å‰‘æŒ‡çš„å…ƒç´ ï¼Œä½†ä¸åˆ é™¤å®ƒ ä¼˜å…ˆé˜Ÿåˆ—çš„è¾…åŠ©æ“ä½œï¼š ç¬¬kæœ€å°&#x2F;ç¬¬kæœ€å¤§ï¼šè¿”å›ä¼˜å…ˆé˜Ÿåˆ—ä¸­é”®å€¼ä¸ºç¬¬kä¸ªæœ€å°&#x2F;æœ€å¤§çš„å…ƒç´  å¤§å°ï¼ˆsizeï¼‰ï¼šè¿”å›ä¼˜å…ˆé˜Ÿåˆ—ä¸­çš„å…ƒç´ ä¸ªæ•° å †æ’åºï¼ˆHeap Sortï¼‰ï¼šåŸºäºé”®å€¼çš„ä¼˜å…ˆçº§å°†ä¼˜å…ˆé˜Ÿåˆ—ä¸­çš„å…ƒç´ è¿›è¡Œæ’åº åœ¨æŸäº›åœºæ™¯ä¸‹ï¼Œæ¯”å¦‚è¦æ±‚é˜Ÿåˆ—ä¸­çš„æœ€å°å…ƒç´ å…ˆå‡ºå³å¯ç”¨ä¼˜å…ˆé˜Ÿåˆ—ï¼Œåœ¨javaä¸­çš„å®ç°ç±»ä¸ºjava.util.PriorityQueueã€‚ è®¤è¯†ä¸‹PriorityQueueç±»çš„æ–¹æ³•åˆ›å»ºå¯¹è±¡12345678// é»˜è®¤æƒ…å†µä¸‹ï¼Œä¼˜å…ˆçº§é˜Ÿåˆ—çš„å¤´æ˜¯é˜Ÿåˆ—ä¸­æœ€å°çš„å…ƒç´ ï¼Œå…ƒç´ å°†æŒ‰å‡åºä»é˜Ÿåˆ—ä¸­ç§»é™¤PriorityQueue&lt;Integer&gt; nums = new PriorityQueue&lt;&gt;();// å€ŸåŠ© Comparator æ¥å£è‡ªå®šä¹‰å…ƒç´ çš„é¡ºåºï¼Œå¤´æ˜¯é˜Ÿåˆ—ä¸­æœ€å¤§çš„å…ƒç´ ï¼ŒæŒ‰é™åºä»é˜Ÿåˆ—ä¸­ç§»é™¤PriorityQueue&lt;int[]&gt; win = new PriorityQueue&lt;int[]&gt;(new Comparator&lt;int[]&gt;() &#123; public int compare(int[] a, int[] b) &#123; return a[0] != b[0] ? b[0] - a[0] : b[1] - a[1]; &#125;&#125;); æ’å…¥å…ƒç´ ï¼šaddã€offer12345678910111213141516171819202122232425class Main &#123; public static void main(String[] args) &#123; //åˆ›å»ºä¼˜å…ˆé˜Ÿåˆ— PriorityQueue&lt;Integer&gt; numbers = new PriorityQueue&lt;&gt;(); //ä½¿ç”¨add()æ–¹æ³•ï¼Œå¦‚æœé˜Ÿåˆ—å·²æ»¡ï¼Œåˆ™ä¼šå¼•å‘å¼‚å¸¸ numbers.add(4); numbers.add(2); System.out.println(&quot;PriorityQueue: &quot; + numbers); //ä½¿ç”¨offer()æ–¹æ³•ï¼Œå¦‚æœé˜Ÿåˆ—å·²æ»¡ï¼Œåˆ™è¿”å›false numbers.offer(1); System.out.println(&quot;æ›´æ–°åçš„PriorityQueue: &quot; + numbers); &#125;&#125;/* * è¾“å‡ºç»“æœï¼š * PriorityQueue: [2, 4] * æ›´æ–°åçš„PriorityQueue: [1, 4, 2] * * ä»¥ä¸Šç»“æœä¸­ï¼Œé˜Ÿåˆ—çš„å¤´æ˜¯æœ€å°å…ƒç´  */ è®¿é—®å…ƒç´ ï¼špeek12345678//ä½¿ç”¨ peek() æ–¹æ³•int number = nums.peek();System.out.println(&quot;è®¿é—®å…ƒç´ : &quot; + number);/* * è¾“å‡ºç»“æœï¼š * è®¿é—®å…ƒç´ : 1 */ åˆ é™¤å…ƒç´ ï¼šremoveã€poll12345678910111213//ä½¿ç”¨remove()æ–¹æ³•ï¼Œä»é˜Ÿåˆ—ä¸­åˆ é™¤æŒ‡å®šçš„å…ƒç´ boolean result = numbers.remove(2);System.out.println(&quot;å…ƒç´ 2æ˜¯å¦å·²åˆ é™¤? &quot; + result);//ä½¿ç”¨poll()æ–¹æ³•ï¼Œè¿”å›å¹¶åˆ é™¤é˜Ÿåˆ—çš„å¤´int number = numbers.poll();System.out.println(&quot;ä½¿ç”¨poll()åˆ é™¤çš„å…ƒç´ : &quot; + number);/* * è¾“å‡ºç»“æœï¼š * å…ƒç´ 2æ˜¯å¦å·²åˆ é™¤? true * ä½¿ç”¨poll()åˆ é™¤çš„å…ƒç´ : 1 */ æ˜¯å¦åŒ…å«å…ƒç´ ï¼šcontains12345678//ä½¿ç”¨contains()æ–¹æ³•ï¼Œä»é˜Ÿåˆ—ä¸­æœç´¢æŒ‡å®šçš„å…ƒç´ ï¼Œæ‰¾åˆ°åˆ™è¿”å›trueï¼Œå¦åˆ™falseã€‚boolean result = numbers.contains(4);System.out.println(&quot;é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰å…ƒç´  4 ï¼Ÿ&quot; + result);/* * è¾“å‡ºç»“æœï¼š * é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰å…ƒç´  4 ï¼Ÿ true */ åˆ·é¢˜åœºæ™¯æ»‘åŠ¨çª—å£çš„æœ€å¤§å€¼123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//ç»™å®šä¸€ä¸ªæ•°ç»„ nums å’Œæ»‘åŠ¨çª—å£çš„å¤§å° kï¼Œè¯·æ‰¾å‡ºæ‰€æœ‰æ»‘åŠ¨çª—å£é‡Œçš„æœ€å¤§å€¼ã€‚ //ç¤ºä¾‹: //è¾“å…¥: nums = [1,3,-1,-3,5,3,6,7], å’Œ k = 3//è¾“å‡º: [3,3,5,5,6,7] //è§£é‡Š:// æ»‘åŠ¨çª—å£çš„ä½ç½® æœ€å¤§å€¼//--------------- -----//[1 3 -1] -3 5 3 6 7 3// 1 [3 -1 -3] 5 3 6 7 3// 1 3 [-1 -3 5] 3 6 7 5// 1 3 -1 [-3 5 3] 6 7 5// 1 3 -1 -3 [5 3 6] 7 6// 1 3 -1 -3 5 [3 6 7] 7import java.util.Comparator;import java.util.PriorityQueue;/* * è§£é¢˜æ€è·¯ï¼šåˆ©ç”¨ä¼˜å…ˆé˜Ÿåˆ—çš„ç‰¹æ€§ï¼Œè§„å®šå †é¡¶å…ƒç´ å°±æ˜¯çª—å£æœ€å¤§å€¼ * */class Solution &#123; public int[] maxSlidingWindow(int[] nums, int k) &#123; int len = nums.length; PriorityQueue&lt;int[]&gt; win = new PriorityQueue&lt;int[]&gt;(new Comparator&lt;int[]&gt;() &#123; // é‡æ–°å®šä¹‰å‡ºé˜Ÿè§„åˆ™ @Override public int compare(int[] a, int[] b) &#123; return a[0] != b[0] ? b[0] - a[0] : b[1] - a[1]; &#125; &#125;); // åˆå§‹åŒ–çª—å£ for (int i = 0; i &lt; k; ++i) &#123; win.offer(new int[]&#123;nums[i], i&#125;); &#125; // åˆ›å»ºæŒ‡å®šé•¿åº¦çš„ç»“æœæ•°ç»„ int[] res = new int[len-k+1]; // ç¬¬ä¸€ä¸ªçª—å£çš„æœ€å¤§å€¼ res[0] = win.peek()[0]; // éå†æ»‘åŠ¨çª—å£ for (int i = k; i &lt; len; ++i) &#123; // æ·»åŠ æ–°å…ƒç´  win.offer(new int[]&#123;nums[i], i&#125;); // åˆ é™¤çª—å£é•¿åº¦å¤–çš„å…ƒç´  while (win.peek()[1] &lt;= i - k) &#123; win.poll(); &#125; // è¿”å›å½“å‰çª—å£çš„æœ€å¤§å€¼ res[i - k + 1] = win.peek()[0]; &#125; return res; &#125;&#125; ä¸‘æ•°12345678910111213141516171819202122232425262728293031323334353637383940// æˆ‘ä»¬æŠŠåªåŒ…å«è´¨å› å­ 2ã€3 å’Œ 5 çš„æ•°ç§°ä½œä¸‘æ•°ï¼ˆUgly Numberï¼‰ã€‚æ±‚æŒ‰ä»å°åˆ°å¤§çš„é¡ºåºçš„ç¬¬ n ä¸ªä¸‘æ•°ã€‚// ç¤ºä¾‹: // è¾“å…¥: n = 10// è¾“å‡º: 12// è§£é‡Š: 1, 2, 3, 4, 5, 6, 8, 9, 10, 12 æ˜¯å‰ 10 ä¸ªä¸‘æ•°ã€‚ // è¯´æ˜:// 1 æ˜¯ä¸‘æ•°ã€‚ // n ä¸è¶…è¿‡1690ã€‚import java.util.HashSet;import java.util.PriorityQueue;import java.util.Set;/* * è§£é¢˜æ€è·¯ï¼šæœ€å°å †ï¼Œéœ€å€ŸåŠ©javaçš„PriorityQueueç±»çš„ç‰¹æ€§å®ç°ï¼šhttps://www.cainiaojc.com/java/java-priorityqueue.html * åˆå§‹åŒ–å †ï¼Œå°†æœ€å°ä¸‘æ•°1æ”¾å…¥å † * æ¯æ¬¡å–å‡ºå †é¡¶å…ƒç´ xï¼Œxå…ƒç´ ä¹Ÿæ˜¯å †ä¸­æœ€å°çš„ä¸‘æ•°ï¼Œéœ€æ’é™¤é‡å¤å…ƒç´ ï¼Œä¾æ¬¡å°† 2x,3x,5x åŠ å…¥å † * ç¬¬næ¬¡å–å‡ºçš„å †é¡¶å…ƒç´ å°±æ˜¯ç¬¬nä¸ªä¸‘æ•° * */class Solution &#123; public int nthUglyNumber(int n) &#123; int[] factors = &#123;2,3,5&#125;; PriorityQueue&lt;Long&gt; heap = new PriorityQueue&lt;Long&gt;(); //ä¼˜å…ˆçº§é˜Ÿåˆ—çš„å¤´æ˜¯é˜Ÿåˆ—ä¸­æœ€å°çš„å…ƒç´  heap.offer(1L); // åˆå§‹åŒ–æœ€å°å †ï¼Œæ”¾å…¥æœ€å°ä¸‘æ•°1 int ugly = 0; for(int i=0; i&lt;n; i++)&#123; long cur = heap.poll(); //è¿”å›å¹¶åˆ é™¤é˜Ÿåˆ—çš„å¤´ï¼Œå³æœ€å°å…ƒç´  ugly = (int) cur; for (int factor : factors)&#123; long next = cur*factor; //æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å…ƒç´  if(!heap.contains(next))&#123; heap.offer(next); &#125; &#125; &#125; return ugly; &#125;&#125; æ•°æ®æµä¸­çš„ä¸­ä½æ•°1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* è§£é¢˜æ€è·¯ï¼šä¼˜å…ˆé˜Ÿåˆ—* åˆ©ç”¨ä¼˜å…ˆé˜Ÿåˆ—çš„ç‰¹æ€§å®ç°ï¼Œé˜Ÿå¤´æ˜¯æœ€å¤§å€¼* */class MedianFinder &#123; // åˆå§‹åŒ–ä¸¤ä¸ªä¼˜å…ˆé˜Ÿåˆ—ï¼Œåˆ†åˆ«å­˜æ”¾ å°äºç­‰äº å’Œ å¤§äº ä¸­ä½æ•°çš„æ•°å€¼ PriorityQueue&lt;Integer&gt; queueMin; PriorityQueue&lt;Integer&gt; queueMax; /** initialize your data structure here. */ public MedianFinder() &#123; // queueMiné˜Ÿå¤´ä¸ºé˜Ÿåˆ—æœ€å¤§å€¼ï¼ŒqueueMaxå¯¹å¤´ä¸ºé˜Ÿåˆ—æœ€å°å€¼ queueMin = new PriorityQueue&lt;Integer&gt;((a,b) -&gt;(b-a)); queueMax = new PriorityQueue&lt;Integer&gt;((a,b) -&gt;(a-b)); &#125; public void addNum(int num) &#123; // numå°äºç­‰äºä¸­ä½æ•°ï¼Œåˆ™numæ”¾å…¥queueMiné˜Ÿåˆ—ï¼›numå¤§äºä¸­ä½æ•°ï¼Œåˆ™numæ”¾å…¥queueMaxé˜Ÿåˆ— // æ³¨æ„ifæ¡ä»¶è¯­å¥çš„å…ˆåé¡ºåºå¾ˆé‡è¦ if (queueMin.isEmpty() || num &lt;= queueMin.peek()) &#123; queueMin.add(num); // queueMiné˜Ÿåˆ—å¤§å°è¶…å‡ºï¼Œåˆ™å°†max(queueMin)å…ƒç´ æ”¾å…¥queueMaxé˜Ÿåˆ— if (queueMin.size() &gt; queueMax.size() + 1) &#123; queueMax.add(queueMin.poll()); &#125; &#125; else &#123; queueMax.add(num); // queueMaxé˜Ÿåˆ—å¤§å°è¶…å‡ºï¼Œåˆ™å°†min(queueMin)å…ƒç´ æ”¾å…¥queueMiné˜Ÿåˆ— if (queueMax.size() &gt; queueMin.size()) &#123; queueMin.add(queueMax.poll()); &#125; &#125; &#125; public double findMedian() &#123; // ä»æ•°æ®æµä¸­è¯»å‡ºå¥‡æ•°ä¸ªæ•°å€¼ if (queueMin.size() &gt; queueMax.size()) &#123; return queueMin.peek(); &#125; // ä»æ•°æ®æµä¸­è¯»å‡ºå¶æ•°ä¸ªæ•°å€¼ return (queueMin.peek() + queueMax.peek()) / 2.0; &#125;&#125;/** * Your MedianFinder object will be instantiated and called as such: * MedianFinder obj = new MedianFinder(); * obj.addNum(num); * double param_2 = obj.findMedian(); */ å‚è€ƒèµ„æ–™æ•°æ®ç»“æ„ä¸ç®—æ³•(4)â€”â€”ä¼˜å…ˆé˜Ÿåˆ—å’Œå † Java PriorityQueue","categories":[{"name":"é¢˜é›†","slug":"é¢˜é›†","permalink":"https://llye-hub.github.io/categories/%E9%A2%98%E9%9B%86/"}],"tags":[{"name":"java","slug":"java","permalink":"https://llye-hub.github.io/tags/java/"},{"name":"æ•°æ®ç»“æ„","slug":"æ•°æ®ç»“æ„","permalink":"https://llye-hub.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"hiveã€Sparkå’ŒMaxcomputeçš„SQLè¯­æ³•å¯¹æ¯”åˆ†æ","slug":"SQL/hiveã€Sparkå’ŒMaxcomputeçš„SQLè¯­æ³•å¯¹æ¯”åˆ†æ","date":"2023-02-21T02:33:16.000Z","updated":"2023-02-22T06:42:32.480Z","comments":true,"path":"posts/e6b1209.html","link":"","permalink":"https://llye-hub.github.io/posts/e6b1209.html","excerpt":"","text":"having å·®å¼‚å·®å¼‚ç‚¹hiveå’Œsparkæ”¯æŒçª—å£å‡½æ•°åå¸¦havingmaxcomputer çš„havingè¯­æ³•åªæ”¯æŒ åœ¨ group å’Œ distinct åä½¿ç”¨ ä¸¾ä¾‹1234select order_id,sum(trd_amt) over(partition by province) as trd_amt_stdfrom orderhaving trd_amt_std&gt;0 ä»¥ä¸Šsqlåœ¨hiveä¸­å¯ä»¥è¿è¡Œï¼Œä½†æ˜¯åœ¨maxcomputerä¸­ä¼šæç¤ºé”™è¯¯ï¼Œé”™è¯¯å¦‚ä¸‹ï¼š æ›¿æ¢æ–¹æ¡ˆåœ¨è¯­å¥ä¸­ä½¿ç”¨å­æŸ¥è¯¢ï¼Œå°†havingæ›¿æ¢ä¸ºwhere 1234567select *from(select order_id,sum(trd_amt) over(partition by province) as trd_amt_stdfrom order) awhere a.trd_amt_std&gt;0 maxcomputer - cross join è¶…è¿‡ä¸€å®šæ¡æ•°åï¼Œä¾ç„¶ä¼šæç¤ºç¬›å¡å°”ç§¯é£é™©å·®å¼‚ç‚¹hiveå¯ä»¥ä½¿ç”¨ cross joinè¯­æ³•æ¥è¡¨ç¤ºç¬›å¡å°”ç§¯å…³è”maxcomputer çš„cross joinï¼Œåœ¨æ¡æ•°è¶…è¿‡ä¸€å®šæ•°æ®é‡åï¼Œä¼šæç¤ºç¬›å¡å°”ç§¯é£é™© ä¸¾ä¾‹1234567select a.*,b.*from(select * from table_a) across join(select * from table_b) b ä»¥ä¸Šsqlåœ¨hiveä¸­å¯ä»¥è¿è¡Œï¼Œä½†æ˜¯åœ¨maxcomputerä¸­ä¼šæç¤ºé”™è¯¯ï¼Œé”™è¯¯å¦‚ä¸‹ï¼š æ›¿æ¢æ–¹æ¡ˆåœ¨å·¦å³ç¬›å¡å°”ç§¯è¡¨ä¸­æ–°å¢å¸¸é‡å­—æ®µï¼Œç”¨äºå…³è” 12345678select a.*,b.*from(select *,1 as cro_col from table_a) across join(select *,1 as cro_col from table_b) bon a.cro_col=b.cro_col ä¸ç­‰å€¼join å·®å¼‚å·®å¼‚ç‚¹1ã€spark æ”¯æŒä¸ç­‰å€¼joinè¯­æ³•2ã€hive 2.2.0ç‰ˆæœ¬ä¹‹å‰ä¸æ”¯æŒä¸ç­‰å€¼è¯­æ³•ï¼Œ2.2.0åŠä»¥åæ”¯æŒä¸ç­‰å€¼joinè¯­æ³•3ã€maxcomputerä¸æ”¯æŒä¸ç­‰å€¼è¯­æ³• ä¸¾ä¾‹æµ‹è¯•sql 12345678910111213141516171819202122232425with table_a as (select 1 as id_a,&#x27;testa&#x27; as value_a union all select 4 as id_a ,&#x27;testd&#x27; as value_a),table_b as (select 3 as id_b,&#x27;testc&#x27; as value_b union all select 2 as id_b ,&#x27;testb&#x27; as value_b)select table_a.id_a,table_a.value_a,table_b.id_b,table_b.value_bfrom table_aleft join table_bon table_a.id_a &lt; table_b.id_b sqlè¯´æ˜ :è¯¥sqlå‡†å¤‡äº†ä¸¤å¼ è¡¨table_aå’Œtable_bç”¨äºè¿æ¥æµ‹è¯•ä½¿ç”¨left join onè¯­æ³•ï¼Œä½†æ˜¯å…³è”å…³ç³»ä½¿ç”¨çš„æ˜¯ &lt; ä¸ç­‰å€¼å…³è”ç¬¦å· maxcomputerè¿è¡Œç»“æœmaxcomputerä¼šæŠ¥å¼‚å¸¸ï¼š FAILED: ODPS-0130071:[15,4] Semantic analysis exception - expect equality expression (i.e., only use â€˜&#x3D;â€™ and â€˜ANDâ€™) for join condition without mapjoin hint æç¤ºçš„æ˜¯æœŸæœ›joinçš„æ˜¯ç­‰å€¼è¡¨è¾¾å¼ hive1.2.1è¿è¡Œç»“æœ hiveä¼šæŠ¥é”™ï¼š Error while compiling statement: FAILED: SemanticException [Error 10017]: line 15:3 Both left and right aliases encountered in JOIN â€˜id_bâ€™ æç¤ºçš„æ˜¯åœ¨joinä¸­é‡åˆ°å·¦å³åˆ«å ä¸å¾—ä¸è¯´ï¼Œhiveçš„é”™è¯¯ä¿¡æ¯æœ‰ç‚¹äº‘é‡Œé›¾é‡Œï¼Œå…¶å®å°±æ˜¯ä¸ç­‰å€¼joiné€ æˆçš„ã€‚ hive2.2.3è¿è¡Œç»“æœ hive 2.2.0+ç‰ˆæœ¬é¡ºåˆ©å¾—åˆ°æ­£ç¡®ç»“æœ sparkè¿è¡Œç»“æœ spark2.3ä¹Ÿé¡ºåˆ©å¾—åˆ°ç»“æœ æ›¿æ¢æ–¹æ¡ˆé’ˆå¯¹ä¸ç­‰å€¼joinçš„æ›¿æ¢æ–¹æ¡ˆæœ‰ä¸¤ç§ 1ã€é’ˆå¯¹å°è¡¨ï¼Œä½¿ç”¨mapjoinï¼Œé¿å…joinæ“ä½œ 2ã€å°†onçš„ä¸ç­‰å€¼å…³è”è¯­å¥æ”¾å…¥whereè¯­å¥ä¸­ ç”±äºmapjoiné¿å…shuffleï¼Œæ€§èƒ½è¾ƒå¥½ï¼Œå†å¯ä»¥çš„æƒ…å†µä¸‹ï¼Œä¼˜å…ˆä½¿ç”¨æ–¹æ¡ˆ1 1ã€é’ˆå¯¹å°è¡¨ï¼Œä½¿ç”¨mapjoinï¼Œé¿å…joinæ“ä½œmaxcomputerä¸­çš„mapjoin hintè¯­æ³•ä¸ºï¼š &#x2F;*+ mapjoin() *&#x2F; ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹mapjoin hint 12345678910111213141516with table_a as (select 1 as id_a,&#x27;testa&#x27; as value_a),table_b as (select 2 as id_b,&#x27;testb&#x27; as value_b)select /*+ mapjoin(table_b) */table_a.id_a,table_a.value_a,table_b.id_b,table_b.value_bfrom table_aleft join table_bon table_a.id_a&lt;table_b.id_b å¯ä»¥çœ‹åˆ°ï¼Œä½¿ç”¨mapjoin hintè¯­æ³•åï¼Œsqlåœ¨maxcomputerä¸­è¿è¡Œæ­£ç¡®ï¼Œé¡ºåˆ©æ‹¿åˆ°äº†é¢„æœŸç»“æœ 2ã€å°†onçš„ä¸ç­‰å€¼å…³è”è¯­å¥æ”¾å…¥whereè¯­å¥ä¸­inner join æ¯”è¾ƒç®€å• 12345678910111213141516171819202122232425262728293031with table_a as (select 1 as id_a,&#x27;testa&#x27; as value_a,1 as join_col union all select 4 as id_a ,&#x27;testd&#x27; as value_a ,1 as join_col),table_b as (select 2 as id_b,&#x27;testb&#x27; as value_b,1 as join_col union all select 3 as id_b ,&#x27;testc&#x27; as value_b ,1 as join_col)selecttable_a.id_a,table_a.value_a,table_b.id_b,table_b.value_bfrom table_ainner join table_bon table_a.join_col=table_b.join_colwhere table_a.id_a&lt;table_b.id_b å¯ä»¥çœ‹åˆ°ï¼Œå°†&lt;åˆ¤æ–­è¯­å¥æ”¾å…¥whereåï¼Œsqlåœ¨maxcomputerè¿è¡Œæ­£ç¡®ï¼Œé¡ºåˆ©æ‹¿åˆ°äº†é¢„æœŸç»“æœ left join æ¯”è¾ƒå¤æ‚ï¼Œå»ºè®®ä½¿ç”¨map hintï¼Œå®åœ¨æ²¡åŠæ³•åœ¨ä½¿ç”¨æ­¤æ–¹æ¡ˆ 123456789101112131415161718192021222324252627282930313233343536373839404142with table_a as (select 1 as id_a,&#x27;testa&#x27; as value_a,1 as join_col union all select 4 as id_a ,&#x27;testd&#x27; as value_a ,1 as join_col),table_b as (select 2 as id_b,&#x27;testb&#x27; as value_b,1 as join_col union all select 3 as id_b ,&#x27;testc&#x27; as value_b ,1 as join_col)-- èƒ½å…³è”ä¸Šçš„éƒ¨åˆ†,join_part as (selecttable_a.id_a,table_a.value_a,table_b.id_b,table_b.value_bfrom table_ainner join table_bon table_a.join_col=table_b.join_colwhere table_a.id_a&lt;table_b.id_b)-- ä»¥è‡ªå·±ä¸ºä¸»è¡¨ï¼Œleft joinèƒ½å…³è”ä¸Šçš„éƒ¨åˆ†ï¼Œå®ç° left joinä¸ç­‰å€¼æ•ˆæœselect table_a.id_a,table_a.value_a,join_part.id_b,join_part.value_bfrom table_aleft join join_parton table_a.id_a=join_part.id_a å¯ä»¥çœ‹åˆ°ï¼Œå°†&lt;åˆ¤æ–­è¯­å¥æ”¾å…¥whereåï¼Œsqlåœ¨maxcomputerè¿è¡Œæ­£ç¡®ï¼Œé¡ºåˆ©æ‹¿åˆ°äº†é¢„æœŸç»“æœ array_contains å·®å¼‚å·®å¼‚ç‚¹sparkçš„array_containsæ”¯æŒç±»å‹çš„éšå¼è½¬æ¢hiveå’Œmaxcomputer array_containsä¸æ”¯æŒï¼Œåªæ”¯æŒåŒç±»å‹ä½¿ç”¨ ä¸¾ä¾‹æµ‹è¯•sql 1select array_contains(split(&quot;1,2,3,4&quot;,&quot;,&quot;),1) sqlè¯´æ˜è¯¥sqlé¦–å…ˆä½¿ç”¨splitä¸€ä¸ªå­—ç¬¦ä¸²è·å–ä¸€ä¸ªarrayå¯¹è±¡ç”¨äºæµ‹è¯•ï¼Œä¹‹åä½¿ç”¨array_containså‡½æ•°è¿›è¡Œåˆ¤æ–­splitåçš„arrayå¯¹è±¡ä¸ºä¸€ä¸ªstringæ•°ç»„ï¼Œè€Œåˆ¤æ–­è¢«åŒ…å«çš„æ•°å­—ã€1ã€‘ä¸ºä¸€ä¸ªint å¯¹è±¡ maxcomputerè¿è¡Œç»“æœmaxcomputerä¼šæŠ¥å¼‚å¸¸ï¼š FAILED: ODPS-0130071:[1,44] Semantic analysis exception - invalid type INT of argument 2 for function array_contains, expect STRING, implicit conversion is not allowed æç¤ºçš„æ˜¯array_containsç¬¬äºŒä¸ªå‚æ•°æœŸæœ›çš„æ˜¯stringï¼Œä½†æ˜¯ä¼ å…¥çš„æ˜¯intï¼Œéšå¼ç±»å‹è½¬æ¢ä¸æ”¯æŒ hiveè¿è¡Œç»“æœ hiveä¼šæŠ¥é”™ï¼š Error while compiling statement: FAILED: SemanticException [Error 10016]: line 1:43 Argument type mismatch â€˜1â€™: â€œstringâ€ expected at function ARRAY_CONTAINS, but â€œintâ€ is found æç¤ºçš„æ˜¯array_containså‡½æ•°æœŸæœ›çš„æ˜¯stringï¼Œä½†æ˜¯ä¼ å…¥çš„æ˜¯intï¼Œç±»å‹ä¸åŒ¹é… sparkè¿è¡Œç»“æœ sparkèƒ½é¡ºåˆ©äº§å‡ºç»“æœï¼Œç»“æœä¸ºtrueï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆsparkå¯ä»¥æˆåŠŸå‘¢ï¼Ÿ å¤§æ¦‚ç‡æ˜¯sparkæ™ºèƒ½çš„å°†1ä»intè½¬æ¢ä¸ºäº†stringç±»å‹ï¼Œä½¿å¾—ç±»å‹å¾—ä»¥åŒ¹é…ï¼Œé€šè¿‡explainæŸ¥çœ‹ç‰©ç†æ‰§è¡Œè®¡åˆ’æ¥éªŒè¯ åœ¨ä¸Šå›¾æ ‡çº¢çš„åœ°æ–¹å¯ä»¥çœ‹åˆ°ï¼Œsparkåœ¨ç‰©ç†æ‰§è¡Œè®¡åˆ’å±‚é¢ï¼Œå°†intçš„1éšå¼çš„è½¬æ¢ä¸ºäº†stringç±»å‹ï¼ŒéªŒè¯äº†æˆ‘ä»¬ä¸€å¼€å§‹çš„çŒœæƒ³ã€‚ æ›¿æ¢æ–¹æ¡ˆæ—¢ç„¶çŸ¥é“äº†åœ¨hiveå’Œmaxcomputerä¸­æ˜¯ç±»å‹ä¸åŒ¹é…å¯¼è‡´çš„array_containså‡½æ•°æŠ¥é”™ï¼Œé‚£ä¹ˆåªéœ€è¦æ˜¾ç¤ºçš„å°†ç±»å‹è¿›è¡Œè½¬æ¢å³å¯ 1select array_contains(split(&quot;1,2,3,4&quot;,&quot;,&quot;),cast(1 as string)) å­—æ®µç±»å‹è½¬æ¢ ARRAY&lt;&gt; to STRINGå·®å¼‚ç‚¹sparkçš„array_containsæ”¯æŒç±»å‹çš„éšå¼è½¬æ¢ hiveå’Œmaxcomputer array_containsä¸æ”¯æŒï¼Œåªæ”¯æŒåŒç±»å‹ä½¿ç”¨ ä¸¾ä¾‹æµ‹è¯•sql 1select cast(array(1, 2, 3, 4) as string) as array_to_string; maxcomputeè¿è¡Œç»“æœ maxcomputeæŠ¥å¼‚å¸¸ï¼šFAILED: ODPS-0130141:[1,8] Illegal implicit type cast - cannot cast from ARRAY to STRING æç¤ºçš„æ˜¯ ARRAY&lt;&gt;ç±»å‹å­—æ®µ ä¸èƒ½å¼ºåˆ¶è½¬æ¢ä¸º STRING ç±»å‹ hiveè¿è¡Œç»“æœ hiveæŠ¥å¼‚å¸¸ï¼šSQLè¯­ä¹‰é”™è¯¯: Error while compiling statement: FAILED: ClassCastException org.apache.hadoop.hive.serde2.typeinfo.ListTypeInfo cannot be cast to org.apache.hadoop.hive.serde2.typeinfo.PrimitiveTypeInfo æç¤ºçš„æ˜¯ä¸åŒç±»å‹ä¸èƒ½å¼ºè½¬ sparkè¿è¡Œç»“æœ sparkèƒ½é¡ºåˆ©äº§å‡ºç»“æœ æ›¿æ¢æ–¹æ¡ˆä½¿ç”¨ array_joinå‡½æ•° å°†arrayçš„å…ƒç´ æ‹¼æ¥æˆå­—ç¬¦ä¸²ï¼Œå†åœ¨é¦–å°¾åŠ ä¸Š â€˜[ â€˜ å’Œ â€˜]â€™ å­—ç¬¦å¯ä»¥è¿˜åŸsparkä¸Šçš„è¿è¡Œç»“æœ 1select concat(&#x27;[&#x27;,array_join(array(1, 2, 3, 4),&#x27;,&#x27;),&#x27;]&#x27;) as array_to_string; ğŸ“¢æ³¨æ„macxcomputeçš„array_joinå‡½æ•°é»˜è®¤ä¼šå¿½ç•¥nullå…ƒç´ ï¼Œå¯åœ¨array_joinå‡½æ•°ä¸­è®¾ç½® nullreplacement å‚æ•°æ›¿ä»£NULLå…ƒç´  æ—¥æœŸæ ¼å¼to_date(â€˜xxxâ€™,â€™yyyyMMddHHmmssâ€™)å·®å¼‚ç‚¹hiveè¯­æ³•ä¸­ï¼Œto_dateå‡½æ•°ç”¨æ³•ä¸ºï¼što_date(string timestamp)ï¼Œè¿”å›DATEç±»å‹ï¼Œæ ¼å¼ä¸º yyyy-mm-dd ï¼Œä»…æœ‰ä¸€ä¸ªå‚æ•°ï¼Œæ”¯æŒç”¨formatæ ¼å¼è§£æ sparkè¯­æ³•ä¸­ï¼Œto_dateå‡½æ•°ç”¨æ³•ä¸ºï¼što_date(date_str[, fmt]) ï¼Œè¿”å›DATEç±»å‹ï¼Œæ ¼å¼ä¸º yyyy-mm-dd ï¼Œæ”¯æŒç”¨formatæ ¼å¼è§£ææ—¥æœŸ maxcomputeè¯­æ³•ä¸­ï¼Œto_dateå‡½æ•°ç”¨æ³•ä¸ºï¼što_date(string , string )ï¼Œè¿”å›DATETIMEç±»å‹ï¼Œæ ¼å¼ä¸º yyyy-mm-dd hh:mi:ss ï¼Œæ”¯æŒç”¨formatæ ¼å¼è§£ææ—¥æœŸ ğŸ“¢è¿™é‡Œè¦æ³¨æ„çš„æ˜¯ï¼Œè™½ç„¶sparkå’Œmaxcomputeä¸­ï¼Œto_dateå‡½æ•°éƒ½æ”¯æŒç”¨formatæ ¼å¼è§£ææ—¥æœŸï¼Œformatæ ¼å¼æ˜¯æœ‰å·®å¼‚çš„ï¼Œä¸»è¦è¡¨ç°åœ¨ åˆ†é’Ÿ ä½çš„æ ¼å¼ sparkçš„formatæ ¼å¼ï¼šyyyyä¸º4ä½æ•°çš„å¹´ï¼ŒMMä¸º2ä½æ•°çš„æœˆï¼Œddä¸º2ä½æ•°çš„æ—¥ï¼ŒHHä¸º24å°æ—¶åˆ¶çš„æ—¶ï¼Œmmä¸º2ä½æ•°çš„åˆ†é’Ÿï¼Œssä¸º2ä½æ•°çš„ç§’ï¼Œff3ä¸º3ä½ç²¾åº¦æ¯«ç§’maxcomputeçš„formatæ ¼å¼ï¼šyyyyä¸º4ä½æ•°çš„å¹´ï¼Œmmä¸º2ä½æ•°çš„æœˆï¼Œddä¸º2ä½æ•°çš„æ—¥ï¼Œhhä¸º24å°æ—¶åˆ¶çš„æ—¶ï¼Œmiä¸º2ä½æ•°çš„åˆ†é’Ÿï¼Œssä¸º2ä½æ•°çš„ç§’ï¼Œff3ä¸º3ä½ç²¾åº¦æ¯«ç§’ ä¸¾ä¾‹æµ‹è¯•sql 1select to_date(&#x27;20221118123456&#x27;,&#x27;yyyyMMddHHmmss&#x27;),to_date(&#x27;2022-11-18 12:34:56&#x27;,&#x27;yyyy-MM-dd HH:mm:ss&#x27;); maxcomputeè¿è¡Œç»“æœ maxcomputeæŠ¥å¼‚å¸¸ï¼š FAILED: ODPS-0121095:Invalid arguments - format string has second part, but doesnâ€™t have minute part : yyyyMMddHHmmss hiveè¿è¡Œç»“æœ hiveæŠ¥å¼‚å¸¸ï¼š Arguments length mismatch â€˜â€™yyyyMMddhhmmssâ€™â€™: to_date() requires 1 argument, got 2 æç¤ºçš„æ˜¯to_dateå‡½æ•°ä»…æœ‰1ä¸ªå‚æ•° å»æ‰formatå‚æ•°åçš„è¿è¡Œç»“æœä¸ºï¼š ä»ç»“æœå¯ä»¥çœ‹åˆ°ï¼Œto_dateä¸èƒ½è§£æ yyyyMMddhhmmss å’Œ yyyyMMdd æ ¼å¼ sparkè¿è¡Œç»“æœ sparkèƒ½é¡ºåˆ©äº§å‡ºç»“æœ æ›¿æ¢æ–¹æ¡ˆformatæ ¼å¼ä¿®æ”¹ï¼šyyyyä¸º4ä½æ•°çš„å¹´ï¼Œmmä¸º2ä½æ•°çš„æœˆï¼Œddä¸º2ä½æ•°çš„æ—¥ï¼Œhhä¸º24å°æ—¶åˆ¶çš„æ—¶ï¼Œmiä¸º2ä½æ•°çš„åˆ†é’Ÿï¼Œssä¸º2ä½æ•°çš„ç§’ï¼Œff3ä¸º3ä½ç²¾åº¦æ¯«ç§’ ä¿®æ”¹åçš„èƒ½æ­£å¸¸äº§å‡ºç»“æœï¼š å¦ï¼Œå¸¸è§ä½¿ç”¨to_dateæŠ¥é”™sqlä¸º date_format(date_add(to_date(pay_time,â€™yyyyMMddHHmmssâ€™),2),â€™yyyyMMddHHmmssâ€™) ï¼Œè§£è¯»sqlçš„ä½œç”¨æ˜¯å¯¹ pay_time åŠ  2 å¤©ï¼Œå»ºè®®ç”¨ UDF ä¿®æ”¹è¿™æ®µsqlä¸º yt_date_add(pay_time,2)ï¼Œä¿®æ”¹åç®€æ´æ˜äº† dateæ—¥æœŸå‡½æ•°å·®å¼‚ç‚¹sparkå’Œhiveçš„dateå‡½æ•°æ”¯æŒå°†æ ‡å‡†çš„æ—¥æœŸstringè½¬æ¢ä¸ºdateç±»å‹ maxcomputer dateå‡½æ•°åªæ”¯æŒæ ‡å‡†çš„æ—¥æœŸstringï¼Œå¸¦æ—¶åˆ†ç§’çš„æ—¶é—´stringä¸æ”¯æŒ ä¸¾ä¾‹æµ‹è¯•sql 1select date(&#x27;2022-12-21&#x27;),date(&#x27;2022-12-21 01:22:01&#x27;); maxcomputeè¿è¡Œç»“æœ maxcomputerå¯¹æ ‡å‡†çš„æ—¥æœŸstringã€2022-12-21ã€‘è½¬æ¢æ­£ç¡® ä½†æ˜¯å¯¹å¸¦æ—¶åˆ†ç§’çš„stringè½¬ä¸ºé”™è¯¯ï¼Œç›´æ¥ä¸ºnull hiveè¿è¡Œç»“æœ ç»“æœç¬¦åˆé¢„æœŸ sparkè¿è¡Œç»“æœ sparkèƒ½é¡ºåˆ©äº§å‡ºç»“æœ æ›¿æ¢æ–¹æ¡ˆå¦‚æœæ˜¯ä¸ºäº†æ ¼å¼è½¬æ¢ï¼Œä½¿ç”¨è‡ªå®šä¹‰ yt_date_format å‡½æ•° å¦‚æœæ˜¯ä¸ºäº†è·å–dateç±»å‹ï¼Œä½¿ç”¨ to_dateå‡½æ•° 12select yt_date_format(&#x27;2022-12-21 01:22:01&#x27;,&#x27;yyyy-MM-dd&#x27;),to_date(&#x27;2022-12-21 01:22:01&#x27;); from_unixtimeå‡½æ•°å·®å¼‚ç‚¹sparkå’Œhiveçš„from_unixtimeå‡½æ•°å°†æ—¶é—´æˆ³è½¬æ¢æˆæ ¼å¼åŒ–stringç±»å‹ï¼Œå½“æ—¶é—´æˆ³ä¸ºè´Ÿæ•°æ—¶ï¼Œæ­£å¸¸è½¬æ¢ maxcomputer from_unixtimeå‡½æ•°è½¬æ¢è´Ÿæ•°æ—¶é—´æˆ³æ—¶ï¼Œå­˜åœ¨æ—¶é—´ä¾¿å®œ ä¸¾ä¾‹æµ‹è¯•sqlselect â€˜1018-10-15 00:00:00â€™ â€“ yyyyMMddHHmmss æ—¶é—´æˆ³,unix_timestamp(â€˜1018-10-15 00:00:00â€™) â€“æ—¶é—´æˆ³,from_unixtime(unix_timestamp(â€˜1018-10-15 00:00:00â€™),â€™yyyyMMddHHmmssâ€™) â€“è½¬æ¢æ ¼å¼ maxcomputeè¿è¡Œç»“æœ å¯ä»¥çœ‹åˆ°ï¼ŒåŸå…ˆæ—¥æœŸä¸º â€˜1018-10-15 00:00:00â€™,è½¬æ¢æˆyyyyMMddHHmmssæ ¼å¼åŸæœ¬æœŸæœ›ä¸º 10181015000000 ä½†æ˜¯å®é™…ç»“æœä¸º10181008235417,å’Œé¢„æœŸä¸ç¬¦åˆ hiveè¿è¡Œç»“æœ hiveç»“æœç¬¦åˆé¢„æœŸ sparkè¿è¡Œç»“æœ sparkäº§å‡ºç»“æœæ­£ç¡® æ›¿æ¢æ–¹æ¡ˆä½¿ç”¨è‡ªå®šä¹‰ yt_date_format å‡½æ•° 123select &#x27;1018-10-15 00:00:00&#x27; -- yyyyMMddHHmmss æ—¶é—´æˆ³,unix_timestamp(&#x27;1018-10-15 00:00:00&#x27;) --æ—¶é—´æˆ³,yt_date_format(&#x27;1018-10-15 00:00:00&#x27;,&#x27;yyyyMMddHHmmss&#x27;) --è½¬æ¢æ ¼å¼ ä½¿ç”¨è‡ªå®šä¹‰udfåæ­£ç¡® concat_wså·®å¼‚å·®å¼‚ç‚¹sparkçš„concat_wsä¼šæ”¯æŒç±»å‹çš„éšå¼è½¬æ¢ hiveå’Œmaxcomputer concat_wsä¸æ”¯æŒï¼Œåªæ”¯æŒåŒç±»å‹ä½¿ç”¨ ä¸¾ä¾‹æµ‹è¯•sql 1select concat_ws(&quot;,&quot;,array(1,2,3)) maxcomputeè¿è¡Œç»“æœ æŠ¥é”™æç¤ºæ•°æ®ç±»å‹ä¸å¯¹ï¼Œconcat_wsåªèƒ½å¤„ç†ARRAYæ•°æ®ç±»å‹ï¼Œè€Œsqlä¸­æ˜¯ARRAYæ•°æ®ç±»å‹ï¼Œå®˜æ–¹æ–‡æ¡£ ä¸­æœ‰è¯¦ç»†è¯´æ˜ hiveè¿è¡Œç»“æœ æŠ¥é”™æç¤ºæ•°æ®ç±»å‹ä¸å¯¹ï¼Œä¸maxcomputeä¸€ä¸ªæ„æ€ï¼Œconcat_wsä¼ å…¥æ•°ç»„å¿…é¡»æ˜¯Arrayç±»å‹ sparkè¿è¡Œç»“æœ sparkæ‰§è¡Œç»“æœç¬¦åˆé¢„æœŸ æ›¿æ¢æ–¹æ¡ˆä½¿ç”¨é˜¿é‡Œäº‘æä¾›çš„array_joinå‡½æ•° 1select array_join(array(1,2,3),&quot;,&quot;);","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"Maxcompute","slug":"Maxcompute","permalink":"https://llye-hub.github.io/tags/Maxcompute/"}]},{"title":"mysqlå’ŒhiveSQLçš„è¯­æ³•å·®åˆ«","slug":"SQL/mysqlå’ŒhiveSQLçš„è¯­æ³•å·®åˆ«","date":"2023-02-17T08:06:16.000Z","updated":"2023-03-02T08:18:42.316Z","comments":true,"path":"posts/e912f2da.html","link":"","permalink":"https://llye-hub.github.io/posts/e912f2da.html","excerpt":"","text":"æœ€è¿‘åœ¨ç‰›å®¢ç½‘ä¸Šåˆ·sqlé¢˜ï¼Œä½†ç¼–ç¨‹è¯­è¨€å±…ç„¶åªæ”¯æŒmysqlï¼Œä¸€äº›å‡½æ•°ç”¨æ³•ä¸Šä¸å¹³æ—¶å·¥ä½œä½¿ç”¨çš„hiveSQLæœ‰è¾ƒå¤§å·®åˆ«ï¼Œæ‰€ä»¥åœ¨è¿™ç¯‡åšå®¢ä¸­æ•´ç†ä¸€ä¸‹ä¸¤ç§è¯­æ³•çš„å‡½æ•°ä½¿ç”¨å·®å¼‚ mysqlå†…ç½®å‡½æ•° hiveå†…ç½®å‡½æ•° æ—¥æœŸã€æ—¶é—´å‡½æ•° å‡½æ•°ç”¨é€” mysqlå‡½æ•° mysqlç”¨æ³• hiveå‡½æ•° hiveSQLç”¨æ³• æ—¥æœŸã€æ—¶é—´æ ¼å¼åŒ– date_format date_format(â€˜2008-08-08 22:23:01â€™, â€˜%Y%m%d%H%i%sâ€™) date_format date_format(â€˜2008-08-08 22:23:01â€™, â€˜yyyyMMddHHmmssâ€™) æ—¥æœŸã€æ—¶é—´åŠ  date_add date_add(â€˜2008-08-08 22:23:01â€™,interval 1 day&#x2F;hour&#x2F;minute&#x2F;second&#x2F;microsecond&#x2F;week&#x2F;month&#x2F;quarter&#x2F;year)ï¼Œè¿”å›dateTimeæ ¼å¼ date_add date_add(â€˜2008-08-08 22:23:01â€™,1)ï¼ŒåªåŠ daysï¼Œè¿”å›dateæ ¼å¼ æ—¥æœŸã€æ—¶é—´å‡ date_sub date_sub(â€˜2008-08-08 22:23:01â€™,interval 1 day&#x2F;hour&#x2F;minute&#x2F;second&#x2F;microsecond&#x2F;week&#x2F;month&#x2F;quarter&#x2F;year)ï¼Œè¿”å›dateTimeæ ¼å¼ date_sub date_sub(â€˜2008-08-08 22:23:01â€™,1)ï¼ŒåªåŠ daysï¼Œè¿”å›dateæ ¼å¼ æ—¥æœŸç›¸å·® datediff datediff(â€˜2008-08-08 22:22:00â€™,â€™2008-08-07 22:23:00â€™) datediff datediff(â€˜2008-08-08 22:22:00â€™,â€™2008-08-07 22:23:00â€™)","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[]},{"title":"æ’åºç®—æ³•","slug":"é¢˜é›†/æ’åºç®—æ³•","date":"2023-02-17T05:46:19.000Z","updated":"2023-03-10T08:21:11.251Z","comments":true,"path":"posts/735e5788.html","link":"","permalink":"https://llye-hub.github.io/posts/735e5788.html","excerpt":"","text":"æ•´ç†ä¸€äº›æ•°æ®ç»“æ„ä¸­å¸¸ç”¨çš„æ’åºç®—æ³•åŸç†å’Œjavaå®ç° å¿«é€Ÿæ’åºåŸç†åœ¨æ•°ç»„ä¸­æ‰¾åˆ°ä¸€ä¸ªåŸºå‡†å€¼tï¼Œå°†å°äºtçš„å€¼æ”¾å®ƒå‰é¢ï¼Œå¤§äºtçš„å€¼æ”¾å®ƒåé¢ï¼Œå†ä»¥æ­¤æ–¹æ³•å¯¹å­æ•°ç»„é€’å½’è¿›è¡Œå¿«é€Ÿæ’åº javaä»£ç ","categories":[{"name":"é¢˜é›†","slug":"é¢˜é›†","permalink":"https://llye-hub.github.io/categories/%E9%A2%98%E9%9B%86/"}],"tags":[]},{"title":"è§£é¢˜æ€è·¯ä¹‹åŠ¨æ€è§„åˆ’","slug":"é¢˜é›†/è§£é¢˜æ€è·¯ä¹‹åŠ¨æ€è§„åˆ’","date":"2023-02-16T09:11:19.000Z","updated":"2023-03-10T08:21:11.246Z","comments":true,"path":"posts/d6cdfd6a.html","link":"","permalink":"https://llye-hub.github.io/posts/d6cdfd6a.html","excerpt":"","text":"ä»€ä¹ˆæ˜¯åŠ¨æ€è§„åˆ’åŠ¨æ€è§„åˆ’ï¼Œè‹±æ–‡ï¼šDynamic Programmingï¼Œç®€ç§°DPã€‚ç®€å•ç†è§£ï¼ŒåŠ¨æ€è§„åˆ’çš„æ¯ä¸€ä¸ªçŠ¶æ€éƒ½èƒ½ç”±ä¸Šä¸€ä¸ªçŠ¶æ€æ¨å¯¼è€Œæ¥ è§£é¢˜æ­¥éª¤ä»¥æ–æ³¢é‚£å¥‘æ•°åˆ—ä¸ºä¾‹ï¼ŒåŠ¨æ€è§„åˆ’é—®é¢˜å¯ä»¥æ‹†è§£ä¸ºäº”æ­¥æ›²ï¼š 1ã€ç¡®å®šdpæ•°ç»„å’Œä¸‹æ ‡å«ä¹‰ï¼šç¬¬nä¸ªæ–æ³¢é‚£å¥‘æ•°æ˜¯dp[n] 2ã€ç¡®å®šé€’æ¨å…¬å¼ï¼ˆä¹Ÿå¯å«çŠ¶æ€è½¬ç§»æ–¹ç¨‹ï¼‰ï¼šdp[n] = dp[n-1] + dp[n-2] 3ã€dpæ•°ç»„åˆå§‹åŒ–ï¼šdp[0] = 0; dp[1] = 1 4ã€ç¡®å®šéå†é¡ºåºï¼šä»å‰åˆ°åéå†ï¼Œdp[n]ä¾èµ–dp[n-1]å’Œdp[n-2] 5ã€ä¸¾ä¾‹æ¨å¯¼dpæ•°ç»„ï¼šå½“n=10æ—¶ï¼Œdpæ•°ç»„åº”è¯¥ä¸ºï¼š0 1 1 2 3 5 8 13 21 34 55 å‚è€ƒèµ„æ–™ä»£ç éšæƒ³å½•ä¹‹åŠ¨æ€è§„åˆ’","categories":[{"name":"é¢˜é›†","slug":"é¢˜é›†","permalink":"https://llye-hub.github.io/categories/%E9%A2%98%E9%9B%86/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://llye-hub.github.io/tags/LeetCode/"}]},{"title":"SparkSQLä¼˜åŒ–ä¹‹æ•°æ®å€¾æ–œ","slug":"SQL/SparkSQLä¼˜åŒ–ä¹‹æ•°æ®å€¾æ–œ","date":"2023-02-09T02:19:52.000Z","updated":"2023-02-28T08:29:17.852Z","comments":true,"path":"posts/faab1ad7.html","link":"","permalink":"https://llye-hub.github.io/posts/faab1ad7.html","excerpt":"","text":"å‰è¨€åœ¨Sparkä½œä¸šä¼˜åŒ–åœºæ™¯ä¸­ï¼Œæœ€å¸¸è§ä¸”æ¯”è¾ƒæ£˜æ‰‹çš„å°±æ˜¯æ•°æ®å€¾æ–œé—®é¢˜ã€‚ä¸ªäººè®¤ä¸ºï¼Œå…·å¤‡æ•°æ®å€¾æ–œè°ƒä¼˜èƒ½åŠ›å¯¹ä»äº‹æ•°ä»“å¼€å‘äººå‘˜æ˜¯å¿…å¤‡çš„åŸºæœ¬è¦æ±‚ã€‚å½“ç„¶ï¼Œæ•°æ®å€¾æ–œçš„åœºæ™¯æ˜¯æ¯”è¾ƒå¤æ‚çš„ï¼Œé’ˆå¯¹ä¸åŒçš„æ•°æ®å€¾æ–œæœ‰ä¸åŒçš„å¤„ç†æ–¹æ¡ˆã€‚ å¦‚ä½•è¾¨åˆ«å’Œå®šä½æ•°æ®å€¾æ–œä»Sparkä½œä¸šçš„æ‰§è¡Œè®¡åˆ’çœ‹ï¼Œè‹¥å‡ºç°æŸä¸ªtaskä»»åŠ¡æ¯”å…¶ä»–taskä»»åŠ¡æ‰§è¡Œè€—æ—¶æå…¶ä¹…ï¼Œæ¯”å¦‚ï¼šæŸä¸ªstageæœ‰100ä¸ªtaskï¼Œå…¶ä¸­99ä¸ªtaskåœ¨1minå·¦å³å°±æ‰§è¡ŒæˆåŠŸï¼Œä½†æ˜¯æœ‰1ä¸ªtaskå´æ‰§è¡Œäº†1ä¸ªå°æ—¶ç”šè‡³æ›´ä¹…ï¼Œè¿™ç§æƒ…å†µæ˜¾ç„¶æ˜¯å‡ºç°äº†æ•°æ®å€¾æ–œã€‚ æ•°æ®å€¾æ–œé—®é¢˜ä»…å‡ºç°åœ¨shuffleè¿‡ç¨‹ï¼Œä¸€äº›ä¼šè§¦å‘shuffleçš„ç®—å­ï¼šdistinctã€groupByKeyã€reduceByKeyã€aggregateByKeyã€countByKeyã€joinã€cogroupã€repartitionç­‰ã€‚å¯¹åº”æäº¤çš„SparkSQLä¸­å¯èƒ½æœ‰distinctã€count(distinct)ã€group byã€partition byã€joinç­‰å…³é”®è¯ã€‚ å¸¸è§çš„æ•°æ®å€¾æ–œåœºæ™¯åŠè§£å†³æ–¹æ¡ˆç¢°åˆ°çš„æ•°æ®å€¾æ–œæ¡ˆä¾‹çª—å£åˆ†ç»„æ•°æ®å€¾æ–œå€¾æ–œåœºæ™¯ä¸šåŠ¡ä¸Šæœ‰ä¸€å¼ æ¶ˆæ¯è®°å½•è¡¨msg_recordsï¼Œsqlè¦æ±‚æ˜¯å–ä¸‹ä¸€æ¬¡å›å¤æ¶ˆæ¯ 12345678910111213141516171819202122232425262728WITH msg_tmp as( select id -- å”¯ä¸€é”®ï¼Œæ¶ˆæ¯id ,from_chat_id -- æ¶ˆæ¯å‘é€è€…id ,to_chat_id -- æ¶ˆæ¯æ¥å—è€…id ,msg_time -- æ¶ˆæ¯æ—¶é—´ from msg_records)select id ,msg_time ,first_value(if(type = &#x27;reply&#x27;,id,null),true) over(partition by from_chat_id,to_chat_id order by msg_time,id rows between 1 following and unbounded following) as reply_msg_id_n1t -- å–ä¸‹ä¸€æ¬¡å›å¤æ¶ˆæ¯from( select id ,from_chat_id ,to_chat_id ,msg_time ,&#x27;send&#x27; as type from msg_tmp union all -- è°ƒè½¬ï¼Œå–è¿”å›æ¶ˆæ¯ select id ,to_chat_id as from_chat_id ,from_chat_id as to_chat_id ,msg_time ,&#x27;reply&#x27; as type from msg_tmp) t1 sqlæ‰§è¡Œåˆ†ææœ‰ä¸€ä¸ªtaskæ‰§è¡Œè€—æ—¶1h æ•°æ®å€¾æ–œåˆ†ææ ¹æ®çª—å£å‡½æ•°çš„åˆ†ç»„from_chat_id + to_chat_idåˆ†æï¼Œæ•°æ®é‡å‡ºç°ä¸¥é‡å€¾æ–œï¼Œè¡¨æ€»æ•°æ®é‡1äº¿å¤šï¼Œå…¶ä¸­ï¼Œåˆ†ç»„from_chat_id=12 and to_chat_id=81867çš„æ•°æ®é‡æœ‰30wï¼Œå…¶ä»–åˆ†ç»„æ•°æ®é‡è‡³å¤š3wã€‚ å¦å¤–ï¼Œåˆ†ç»„from_chat_id=12 and to_chat_id=81867çš„æ•°æ®åœ¨ä¸šåŠ¡ä¸Šå¯å®šä¹‰ä¸ºè„æ•°æ®ï¼Œä¸”first_value()å‡½æ•°è®¡ç®—å‡ºçš„å€¼å…¨ä¸ºnullã€‚ ç»è¿‡æµ‹è¯•éªŒè¯å‘ç°ï¼Œæ²¡æœ‰ rows betweenè¯­å¥ æˆ–æ˜¯ è¿‡æ»¤å€¾æ–œæ•°æ® æ—¶ï¼ŒSQLæ‰§è¡Œå¾ˆå¿« ç»¼ä¸Šåˆ†æï¼Œå†å¯¹ç…§sparkæ‰§è¡Œè®¡åˆ’åŸºæœ¬å¯ä»¥å®šä½å€¾æ–œåŸå› ä¸ºçª—å£æ•°æ®å€¾æ–œå’Œrows betweenè®¡ç®—è€—æ—¶ è§£å†³æ–¹æ¡ˆç»“åˆä¸šåŠ¡çŸ¥è¯†ï¼Œåœ¨sqlé€»è¾‘ä¸­è¿‡æ»¤from_chat_id=12 and to_chat_id=81867çš„æ•°æ® æœ€ç»ˆï¼Œä»»åŠ¡æ‰§è¡Œè€—æ—¶ä»1hä¼˜åŒ–è‡³10min å‚è€ƒèµ„æ–™ç¾å›¢æŠ€æœ¯å›¢é˜Ÿï¼šSparkæ€§èƒ½ä¼˜åŒ–æŒ‡å—â€”â€”é«˜çº§ç¯‡","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"æ•°æ®å€¾æ–œ","slug":"æ•°æ®å€¾æ–œ","permalink":"https://llye-hub.github.io/tags/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"}]},{"title":"hiveSQLä¹‹ç”Ÿæˆè¿ç»­æ•°å­—","slug":"SQL/hiveSQLä¹‹ç”Ÿæˆè¿ç»­æ•°å­—","date":"2023-02-08T08:03:36.000Z","updated":"2023-02-20T03:39:51.495Z","comments":true,"path":"posts/3ce3d37f.html","link":"","permalink":"https://llye-hub.github.io/posts/3ce3d37f.html","excerpt":"","text":"sqlè¦æ±‚ç”Ÿæˆ100ä»¥å†…çš„å…¨éƒ¨æ•´æ•° æ¶‰åŠudtfå‡½æ•°posexplode(ARRAY&lt;T&gt; a) å®˜æ–¹è¯´æ˜ Return: Returns a row-set with two columns (pos int,val T), one row for each element from the array. Description: posexplode() is similar to explode but instead of just returning the elements of the array it returns the element as well as its position in the original array. ç”¨æ³•ç¤ºä¾‹ï¼šæœ‰å¦‚ä¸‹ä¸€å¼ è¡¨myTable (array&lt;int&gt;)myCol [100,200,300] [400,500,600] æ‰§è¡Œhive sql 12345678-- é€ æ•°æ®with myTable as ( select array(100,200,300) as myCol union all select array(300,400,500) as myCol)-- æŸ¥è¯¢sqlSELECT posexplode(myCol) AS (pos, val) FROM myTable å¾—åˆ°ç»“æœä¸ºï¼š (int)pos (int)val 0 100 1 200 2 300 0 400 1 500 2 600 sqlå®ç°å€ŸåŠ©posexplodeè¿”å›çš„poså³å¯å®ç° 12345select posexplode(split(space(99), &#x27; &#x27;)) as (pos, val)-- è¿”å›çš„poså­—æ®µå³ä¸º[0,99]åŒºé—´çš„100ä¸ªæ•´æ•°-- æˆ–è€…ä¸‹é¢è¿™ç§å†™æ³•select posexplode(split(repeat(&#x27;,&#x27;,99), &#x27;,&#x27;)) as (pos, val) å®ä¾‹åœºæ™¯æ•°æ®é‡å¤æ‰©å®¹10å€12345678910-- é€ æ•°æ®with myTable as ( select &#x27;å¼ ä¸‰&#x27; as name union all select &#x27;æå››&#x27; as name)-- å°†myTableçš„æ¯è¡Œæ•°æ®é‡å¤å¤åˆ¶ä¸º5è¡ŒSELECT name ,posexplode(split(space(4), &#x27; &#x27;)) AS (pos, val) FROM myTable å¾—åˆ°ç»“æœä¸ºï¼š name pos val å¼ ä¸‰ 0 å¼ ä¸‰ 1 å¼ ä¸‰ 2 å¼ ä¸‰ 3 å¼ ä¸‰ 4 æå›› 0 æå›› 1 æå›› 2 æå›› 3 æå›› 4 ç”ŸæˆæŒ‡å®šèŒƒå›´å†…çš„è¿ç»­æ—¥æœŸ123456789with subquery as ( select split(space(datediff(&#x27;2023-1-31&#x27;,&#x27;2022-11-30&#x27;)), &#x27; &#x27;) as x) select date_add(&#x27;2022-11-30&#x27;, pos) as new_datefrom subquery t lateral view posexplode(x) pe as pos, val","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"SQLé«˜çº§è¯­æ³•","slug":"SQLé«˜çº§è¯­æ³•","permalink":"https://llye-hub.github.io/tags/SQL%E9%AB%98%E7%BA%A7%E8%AF%AD%E6%B3%95/"}]},{"title":"SparkSQLä¹‹confå‚æ•°","slug":"SQL/SparkSQLä¹‹confå‚æ•°","date":"2023-02-03T08:15:46.000Z","updated":"2023-02-20T05:44:02.740Z","comments":true,"path":"posts/5e220c44.html","link":"","permalink":"https://llye-hub.github.io/posts/5e220c44.html","excerpt":"","text":"èµ„æºå‚æ•°num-executors å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®Sparkä½œä¸šæ€»å…±è¦ç”¨å¤šå°‘ä¸ªExecutorè¿›ç¨‹æ¥æ‰§è¡Œã€‚Driveråœ¨å‘YARNé›†ç¾¤ç®¡ç†å™¨ç”³è¯·èµ„æºæ—¶ï¼ŒYARNé›†ç¾¤ç®¡ç†å™¨ä¼šå°½å¯èƒ½æŒ‰ç…§ä½ çš„è®¾ç½®æ¥åœ¨é›†ç¾¤çš„å„ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šï¼Œå¯åŠ¨ç›¸åº”æ•°é‡çš„Executorè¿›ç¨‹ã€‚è¿™ä¸ªå‚æ•°éå¸¸ä¹‹é‡è¦ï¼Œå¦‚æœä¸è®¾ç½®çš„è¯ï¼Œé»˜è®¤åªä¼šç»™ä½ å¯åŠ¨å°‘é‡çš„Executorè¿›ç¨‹ï¼Œæ­¤æ—¶ä½ çš„Sparkä½œä¸šçš„è¿è¡Œé€Ÿåº¦æ˜¯éå¸¸æ…¢çš„ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šæ¯ä¸ªSparkä½œä¸šçš„è¿è¡Œä¸€èˆ¬è®¾ç½®50~100ä¸ªå·¦å³çš„Executorè¿›ç¨‹æ¯”è¾ƒåˆé€‚ï¼Œè®¾ç½®å¤ªå°‘æˆ–å¤ªå¤šçš„Executorè¿›ç¨‹éƒ½ä¸å¥½ã€‚è®¾ç½®çš„å¤ªå°‘ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨é›†ç¾¤èµ„æºï¼›è®¾ç½®çš„å¤ªå¤šçš„è¯ï¼Œå¤§éƒ¨åˆ†é˜Ÿåˆ—å¯èƒ½æ— æ³•ç»™äºˆå……åˆ†çš„èµ„æºã€‚ executor-memory å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªExecutorè¿›ç¨‹çš„å†…å­˜ã€‚Executorå†…å­˜çš„å¤§å°ï¼Œå¾ˆå¤šæ—¶å€™ç›´æ¥å†³å®šäº†Sparkä½œä¸šçš„æ€§èƒ½ï¼Œè€Œä¸”è·Ÿå¸¸è§çš„JVM OOMå¼‚å¸¸ï¼Œä¹Ÿæœ‰ç›´æ¥çš„å…³è”ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šæ¯ä¸ªExecutorè¿›ç¨‹çš„å†…å­˜è®¾ç½®4G~8Gè¾ƒä¸ºåˆé€‚ã€‚ä½†æ˜¯è¿™åªæ˜¯ä¸€ä¸ªå‚è€ƒå€¼ï¼Œå…·ä½“çš„è®¾ç½®è¿˜æ˜¯å¾—æ ¹æ®ä¸åŒéƒ¨é—¨çš„èµ„æºé˜Ÿåˆ—æ¥å®šã€‚å¯ä»¥çœ‹çœ‹è‡ªå·±å›¢é˜Ÿçš„èµ„æºé˜Ÿåˆ—çš„æœ€å¤§å†…å­˜é™åˆ¶æ˜¯å¤šå°‘ï¼Œnum-executorsä¹˜ä»¥executor-memoryï¼Œæ˜¯ä¸èƒ½è¶…è¿‡é˜Ÿåˆ—çš„æœ€å¤§å†…å­˜é‡çš„ã€‚æ­¤å¤–ï¼Œå¦‚æœä½ æ˜¯è·Ÿå›¢é˜Ÿé‡Œå…¶ä»–äººå…±äº«è¿™ä¸ªèµ„æºé˜Ÿåˆ—ï¼Œé‚£ä¹ˆç”³è¯·çš„å†…å­˜é‡æœ€å¥½ä¸è¦è¶…è¿‡èµ„æºé˜Ÿåˆ—æœ€å¤§æ€»å†…å­˜çš„1&#x2F;3~1&#x2F;2ï¼Œé¿å…ä½ è‡ªå·±çš„Sparkä½œä¸šå ç”¨äº†é˜Ÿåˆ—æ‰€æœ‰çš„èµ„æºï¼Œå¯¼è‡´åˆ«çš„åŒå­¦çš„ä½œä¸šæ— æ³•è¿è¡Œã€‚ ##executor-cores å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡ã€‚è¿™ä¸ªå‚æ•°å†³å®šäº†æ¯ä¸ªExecutorè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œtaskçº¿ç¨‹çš„èƒ½åŠ›ã€‚å› ä¸ºæ¯ä¸ªCPU coreåŒä¸€æ—¶é—´åªèƒ½æ‰§è¡Œä¸€ä¸ªtaskçº¿ç¨‹ï¼Œå› æ­¤æ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡è¶Šå¤šï¼Œè¶Šèƒ½å¤Ÿå¿«é€Ÿåœ°æ‰§è¡Œå®Œåˆ†é…ç»™è‡ªå·±çš„æ‰€æœ‰taskçº¿ç¨‹ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šExecutorçš„CPU coreæ•°é‡è®¾ç½®ä¸º2~4ä¸ªè¾ƒä¸ºåˆé€‚ã€‚åŒæ ·å¾—æ ¹æ®ä¸åŒéƒ¨é—¨çš„èµ„æºé˜Ÿåˆ—æ¥å®šï¼Œå¯ä»¥çœ‹çœ‹è‡ªå·±çš„èµ„æºé˜Ÿåˆ—çš„æœ€å¤§CPU coreé™åˆ¶æ˜¯å¤šå°‘ï¼Œå†ä¾æ®è®¾ç½®çš„Executoræ•°é‡ï¼Œæ¥å†³å®šæ¯ä¸ªExecutorè¿›ç¨‹å¯ä»¥åˆ†é…åˆ°å‡ ä¸ªCPU coreã€‚åŒæ ·å»ºè®®ï¼Œå¦‚æœæ˜¯è·Ÿä»–äººå…±äº«è¿™ä¸ªé˜Ÿåˆ—ï¼Œé‚£ä¹ˆnum-executors * executor-coresä¸è¦è¶…è¿‡é˜Ÿåˆ—æ€»CPU coreçš„1&#x2F;3~1&#x2F;2å·¦å³æ¯”è¾ƒåˆé€‚ï¼Œä¹Ÿæ˜¯é¿å…å½±å“å…¶ä»–åŒå­¦çš„ä½œä¸šè¿è¡Œã€‚ driver-memory å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®Driverè¿›ç¨‹çš„å†…å­˜ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šDriverçš„å†…å­˜é€šå¸¸æ¥è¯´ä¸è®¾ç½®ï¼Œæˆ–è€…è®¾ç½®1Gå·¦å³åº”è¯¥å°±å¤Ÿäº†ã€‚å”¯ä¸€éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œå¦‚æœéœ€è¦ä½¿ç”¨collectç®—å­å°†RDDçš„æ•°æ®å…¨éƒ¨æ‹‰å–åˆ°Driverä¸Šè¿›è¡Œå¤„ç†ï¼Œé‚£ä¹ˆå¿…é¡»ç¡®ä¿Driverçš„å†…å­˜è¶³å¤Ÿå¤§ï¼Œå¦åˆ™ä¼šå‡ºç°OOMå†…å­˜æº¢å‡ºçš„é—®é¢˜ã€‚ spark.default.parallelism å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªstageçš„é»˜è®¤taskæ•°é‡ã€‚è¿™ä¸ªå‚æ•°æä¸ºé‡è¦ï¼Œå¦‚æœä¸è®¾ç½®å¯èƒ½ä¼šç›´æ¥å½±å“ä½ çš„Sparkä½œä¸šæ€§èƒ½ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šSparkä½œä¸šçš„é»˜è®¤taskæ•°é‡ä¸º500~1000ä¸ªè¾ƒä¸ºåˆé€‚ã€‚å¾ˆå¤šåŒå­¦å¸¸çŠ¯çš„ä¸€ä¸ªé”™è¯¯å°±æ˜¯ä¸å»è®¾ç½®è¿™ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆæ­¤æ—¶å°±ä¼šå¯¼è‡´Sparkè‡ªå·±æ ¹æ®åº•å±‚HDFSçš„blockæ•°é‡æ¥è®¾ç½®taskçš„æ•°é‡ï¼Œé»˜è®¤æ˜¯ä¸€ä¸ªHDFS blockå¯¹åº”ä¸€ä¸ªtaskã€‚é€šå¸¸æ¥è¯´ï¼ŒSparké»˜è®¤è®¾ç½®çš„æ•°é‡æ˜¯åå°‘çš„ï¼ˆæ¯”å¦‚å°±å‡ åä¸ªtaskï¼‰ï¼Œå¦‚æœtaskæ•°é‡åå°‘çš„è¯ï¼Œå°±ä¼šå¯¼è‡´ä½ å‰é¢è®¾ç½®å¥½çš„Executorçš„å‚æ•°éƒ½å‰åŠŸå°½å¼ƒã€‚è¯•æƒ³ä¸€ä¸‹ï¼Œæ— è®ºä½ çš„Executorè¿›ç¨‹æœ‰å¤šå°‘ä¸ªï¼Œå†…å­˜å’ŒCPUæœ‰å¤šå¤§ï¼Œä½†æ˜¯taskåªæœ‰1ä¸ªæˆ–è€…10ä¸ªï¼Œé‚£ä¹ˆ90%çš„Executorè¿›ç¨‹å¯èƒ½æ ¹æœ¬å°±æ²¡æœ‰taskæ‰§è¡Œï¼Œä¹Ÿå°±æ˜¯ç™½ç™½æµªè´¹äº†èµ„æºï¼å› æ­¤Sparkå®˜ç½‘å»ºè®®çš„è®¾ç½®åŸåˆ™æ˜¯ï¼Œè®¾ç½®è¯¥å‚æ•°ä¸ºnum-executors * executor-coresçš„2~3å€è¾ƒä¸ºåˆé€‚ï¼Œæ¯”å¦‚Executorçš„æ€»CPU coreæ•°é‡ä¸º300ä¸ªï¼Œé‚£ä¹ˆè®¾ç½®1000ä¸ªtaskæ˜¯å¯ä»¥çš„ï¼Œæ­¤æ—¶å¯ä»¥å……åˆ†åœ°åˆ©ç”¨Sparké›†ç¾¤çš„èµ„æºã€‚ spark.storage.memoryFraction å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®RDDæŒä¹…åŒ–æ•°æ®åœ¨Executorå†…å­˜ä¸­èƒ½å çš„æ¯”ä¾‹ï¼Œé»˜è®¤æ˜¯0.6ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œé»˜è®¤Executor 60%çš„å†…å­˜ï¼Œå¯ä»¥ç”¨æ¥ä¿å­˜æŒä¹…åŒ–çš„RDDæ•°æ®ã€‚æ ¹æ®ä½ é€‰æ‹©çš„ä¸åŒçš„æŒä¹…åŒ–ç­–ç•¥ï¼Œå¦‚æœå†…å­˜ä¸å¤Ÿæ—¶ï¼Œå¯èƒ½æ•°æ®å°±ä¸ä¼šæŒä¹…åŒ–ï¼Œæˆ–è€…æ•°æ®ä¼šå†™å…¥ç£ç›˜ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šå¦‚æœSparkä½œä¸šä¸­ï¼Œæœ‰è¾ƒå¤šçš„RDDæŒä¹…åŒ–æ“ä½œï¼Œè¯¥å‚æ•°çš„å€¼å¯ä»¥é€‚å½“æé«˜ä¸€äº›ï¼Œä¿è¯æŒä¹…åŒ–çš„æ•°æ®èƒ½å¤Ÿå®¹çº³åœ¨å†…å­˜ä¸­ã€‚é¿å…å†…å­˜ä¸å¤Ÿç¼“å­˜æ‰€æœ‰çš„æ•°æ®ï¼Œå¯¼è‡´æ•°æ®åªèƒ½å†™å…¥ç£ç›˜ä¸­ï¼Œé™ä½äº†æ€§èƒ½ã€‚ä½†æ˜¯å¦‚æœSparkä½œä¸šä¸­çš„shuffleç±»æ“ä½œæ¯”è¾ƒå¤šï¼Œè€ŒæŒä¹…åŒ–æ“ä½œæ¯”è¾ƒå°‘ï¼Œé‚£ä¹ˆè¿™ä¸ªå‚æ•°çš„å€¼é€‚å½“é™ä½ä¸€äº›æ¯”è¾ƒåˆé€‚ã€‚æ­¤å¤–ï¼Œå¦‚æœå‘ç°ä½œä¸šç”±äºé¢‘ç¹çš„gcå¯¼è‡´è¿è¡Œç¼“æ…¢ï¼ˆé€šè¿‡spark web uiå¯ä»¥è§‚å¯Ÿåˆ°ä½œä¸šçš„gcè€—æ—¶ï¼‰ï¼Œæ„å‘³ç€taskæ‰§è¡Œç”¨æˆ·ä»£ç çš„å†…å­˜ä¸å¤Ÿç”¨ï¼Œé‚£ä¹ˆåŒæ ·å»ºè®®è°ƒä½è¿™ä¸ªå‚æ•°çš„å€¼ã€‚ spark.shuffle.memoryFraction å‚æ•°è¯´æ˜ï¼šè¯¥å‚æ•°ç”¨äºè®¾ç½®shuffleè¿‡ç¨‹ä¸­ä¸€ä¸ªtaskæ‹‰å–åˆ°ä¸Šä¸ªstageçš„taskçš„è¾“å‡ºåï¼Œè¿›è¡Œèšåˆæ“ä½œæ—¶èƒ½å¤Ÿä½¿ç”¨çš„Executorå†…å­˜çš„æ¯”ä¾‹ï¼Œé»˜è®¤æ˜¯0.2ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒExecutoré»˜è®¤åªæœ‰20%çš„å†…å­˜ç”¨æ¥è¿›è¡Œè¯¥æ“ä½œã€‚shuffleæ“ä½œåœ¨è¿›è¡Œèšåˆæ—¶ï¼Œå¦‚æœå‘ç°ä½¿ç”¨çš„å†…å­˜è¶…å‡ºäº†è¿™ä¸ª20%çš„é™åˆ¶ï¼Œé‚£ä¹ˆå¤šä½™çš„æ•°æ®å°±ä¼šæº¢å†™åˆ°ç£ç›˜æ–‡ä»¶ä¸­å»ï¼Œæ­¤æ—¶å°±ä¼šæå¤§åœ°é™ä½æ€§èƒ½ã€‚ å‚æ•°è°ƒä¼˜å»ºè®®ï¼šå¦‚æœSparkä½œä¸šä¸­çš„RDDæŒä¹…åŒ–æ“ä½œè¾ƒå°‘ï¼Œshuffleæ“ä½œè¾ƒå¤šæ—¶ï¼Œå»ºè®®é™ä½æŒä¹…åŒ–æ“ä½œçš„å†…å­˜å æ¯”ï¼Œæé«˜shuffleæ“ä½œçš„å†…å­˜å æ¯”æ¯”ä¾‹ï¼Œé¿å…shuffleè¿‡ç¨‹ä¸­æ•°æ®è¿‡å¤šæ—¶å†…å­˜ä¸å¤Ÿç”¨ï¼Œå¿…é¡»æº¢å†™åˆ°ç£ç›˜ä¸Šï¼Œé™ä½äº†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¦‚æœå‘ç°ä½œä¸šç”±äºé¢‘ç¹çš„gcå¯¼è‡´è¿è¡Œç¼“æ…¢ï¼Œæ„å‘³ç€taskæ‰§è¡Œç”¨æˆ·ä»£ç çš„å†…å­˜ä¸å¤Ÿç”¨ï¼Œé‚£ä¹ˆåŒæ ·å»ºè®®è°ƒä½è¿™ä¸ªå‚æ•°çš„å€¼ã€‚ å¹¿æ’­ç›¸å…³spark.sql.broadcastTimeoutspark.kryoserializer.buffer.max&#x3D;128Mspark.sql.shuffle.partitions&#x3D;1000spark.sql.orc.compression.codec&#x3D;zlibspark.sql.files.maxPartitionBytes&#x3D;65536","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[]},{"title":"hiveSQLä¹‹setå‚æ•°","slug":"SQL/hiveSQLä¹‹setå‚æ•°","date":"2023-02-03T08:14:57.000Z","updated":"2023-02-20T07:52:21.554Z","comments":true,"path":"posts/4547a6e2.html","link":"","permalink":"https://llye-hub.github.io/posts/4547a6e2.html","excerpt":"","text":"hive.merge.mapfilesDefault Value: truemap-onlyä»»åŠ¡ç»“æŸæ—¶åˆå¹¶å°æ–‡ä»¶ hive.merge.mapredfilesDefault Value: truemap-reduceä»»åŠ¡ç»“æŸæ—¶åˆå¹¶å°æ–‡ä»¶ hive.optimize.cte.materialize.thresholdé»˜è®¤æƒ…å†µä¸‹æ˜¯-1ï¼ˆå…³é—­ï¼‰ï¼›å½“å¼€å¯ï¼ˆå¤§äº0ï¼‰ï¼Œæ¯”å¦‚è®¾ç½®ä¸º2ï¼Œåˆ™å¦‚æœwith..asè¯­å¥è¢«å¼•ç”¨2æ¬¡åŠä»¥ä¸Šæ—¶ï¼Œä¼šæŠŠwith..asè¯­å¥ç”Ÿæˆçš„tableç‰©åŒ–ï¼Œä»è€Œåšåˆ°with..asè¯­å¥åªæ‰§è¡Œä¸€æ¬¡ï¼Œæ¥æé«˜æ•ˆç‡","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[]},{"title":"hiveSQLå‘½ä»¤ä¹‹alter partition","slug":"SQL/hiveSQLå‘½ä»¤ä¹‹alter-partition","date":"2023-02-02T06:02:26.000Z","updated":"2023-02-21T06:18:34.677Z","comments":true,"path":"posts/8a94c1da.html","link":"","permalink":"https://llye-hub.github.io/posts/8a94c1da.html","excerpt":"","text":"msck repair table https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ExchangePartition","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"æ”¹åˆ†åŒº","slug":"æ”¹åˆ†åŒº","permalink":"https://llye-hub.github.io/tags/%E6%94%B9%E5%88%86%E5%8C%BA/"}]},{"title":"hadoopå‘½ä»¤ä¹‹distcpåˆ†å¸ƒå¼æ‹·è´","slug":"hadoop/hadoopå‘½ä»¤ä¹‹distcpåˆ†å¸ƒå¼æ‹·è´","date":"2023-02-01T02:06:03.000Z","updated":"2023-02-20T08:58:42.949Z","comments":true,"path":"posts/bcc5bdf2.html","link":"","permalink":"https://llye-hub.github.io/posts/bcc5bdf2.html","excerpt":"","text":"distcpç”¨é€”DistCpï¼ˆåˆ†å¸ƒå¼æ‹·è´ï¼‰æ˜¯ç”¨äºå¤§è§„æ¨¡é›†ç¾¤å†…éƒ¨å’Œé›†ç¾¤ä¹‹é—´æ‹·è´çš„å·¥å…·ã€‚ä½¿ç”¨Map&#x2F;Reduceå®ç°æ–‡ä»¶åˆ†å‘ï¼Œé”™è¯¯å¤„ç†å’Œæ¢å¤ï¼Œä»¥åŠæŠ¥å‘Šç”Ÿæˆã€‚DistCpå°†æ–‡ä»¶å’Œç›®å½•çš„åˆ—è¡¨ä½œä¸ºmapä»»åŠ¡çš„è¾“å…¥ï¼Œæ¯ä¸ªä»»åŠ¡ä¼šå®Œæˆæºåˆ—è¡¨ä¸­éƒ¨åˆ†æ–‡ä»¶çš„æ‹·è´ã€‚ distcpç”¨æ³•å‘½ä»¤è¡Œä¸­å¯ä»¥æŒ‡å®šå¤šä¸ªæºç›®å½• 12# hadoop distcp source_dir1 [source_dir2 source_dir3â€¦â€¦] target_dir é›†ç¾¤å†…æ‹·è´ 12# hadoop distcp [hdfs://nn:8020]/db/table_a/partition=1 [hdfs://nn:8020]/db/table_b/partition=1 ä¸åŒé›†ç¾¤é—´æ‹·è´ï¼ŒDistCpå¿…é¡»è¿è¡Œåœ¨ç›®æ ‡ç«¯é›†ç¾¤ä¸Š 12# hadoop distcp hdfs://nn1:8020/db/table_a/partition=1 hdfs://nn2:8020/db/table_b/partition=1 å¸¸ç”¨å‚æ•°é€‰é¡¹-overwriteæºæ–‡ä»¶è¦†ç›–åŒåç›®æ ‡æ–‡ä»¶ -updateæ‹·è´ç›®æ ‡ç›®å½•ä¸‹ä¸å­˜åœ¨è€Œæºç›®å½•ä¸‹å­˜åœ¨çš„æ–‡ä»¶ï¼Œå½“æ–‡ä»¶å¤§å°ä¸ä¸€è‡´æ—¶ï¼Œæºæ–‡ä»¶è¦†ç›–åŒåç›®æ ‡æ–‡ä»¶ -deleteåˆ é™¤ç›®æ ‡ç›®å½•ä¸‹å­˜åœ¨ï¼Œä½†æºç›®å½•ä¸‹ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼Œéœ€è¦é…åˆ-updateæˆ–-overwriteä½¿ç”¨ -p[rbugpcaxt]æ§åˆ¶æ˜¯å¦ä¿ç•™æºæ–‡ä»¶çš„å±æ€§ï¼Œ-pé»˜è®¤å…¨éƒ¨ä¿ç•™ï¼Œå¸¸ç”¨çš„ä¸º-pbugpã€‚ä¿®æ”¹æ¬¡æ•°ä¸ä¼šè¢«ä¿ç•™ã€‚å¹¶ä¸”å½“æŒ‡å®š -update æ—¶ï¼Œæ›´æ–°çš„çŠ¶æ€ä¸ä¼š è¢«åŒæ­¥ï¼Œé™¤éæ–‡ä»¶å¤§å°ä¸åŒï¼ˆæ¯”å¦‚æ–‡ä»¶è¢«é‡æ–°åˆ›å»ºï¼‰ã€‚ æ ‡è¯† å«ä¹‰ å¤‡æ³¨ r replication number æ–‡ä»¶å‰¯æœ¬æ•° b block size æ–‡ä»¶å—å¤§å° u user ç”¨æˆ· g group ç»„ p permission æ–‡ä»¶æƒé™ c checksum-type æ ¡éªŒå’Œç±»å‹ a acl x xattr t timestamp æ—¶é—´æˆ³ -mæ§åˆ¶æ‹·è´æ—¶çš„mapä»»åŠ¡æœ€å¤§ä¸ªæ•°å¦‚æœæ²¡ä½¿ç”¨-mé€‰é¡¹ï¼ŒDistCpä¼šå°è¯•åœ¨è°ƒåº¦å·¥ä½œæ—¶æŒ‡å®šmapæ•°ç›®&#x3D;min(total_bytes&#x2F;bytes.per.map,20*num_task_trackers)ï¼Œ å…¶ä¸­bytes.per.mapé»˜è®¤æ˜¯256MBã€‚ åº”ç”¨å®ä¾‹è¡¨ç»“æ„ä¸€è‡´çš„ä¸¤è¡¨äº’ç›¸æ‹·è´æ•°æ®1234567891011121314151617181920212223242526272829303132333435#********************************************************************************# ** åŠŸèƒ½æè¿°ï¼šé€šè¿‡hdfsæ–‡ä»¶è·¯å¾„æ‹·è´çš„æ–¹å¼ï¼Œå®ç°è¡¨ç»“æ„å®Œå…¨ç›¸åŒçš„è¡¨äº’ç›¸æ‹·è´æ•°æ®#********************************************************************************# æŒ‡å®šæºè·¯å¾„ã€ç›®æ ‡è·¯å¾„source_dir=/db/table_a/partition=1target_dir=/db/table_b/partition=1db_name=db_atarget_tbl_name=db_a.table_b# åˆ¤æ–­æºè·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è¿”å›hadoop fs -test -e $source_dirif [ $? -ne 0 ];then echo &quot;æºè·¯å¾„$source_dirä¸å­˜åœ¨&quot; exit 1fi# åˆ¤æ–­ç›®æ ‡è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºhadoop fs -test -e $target_dirif [ $? -ne 0 ];then hadoop fs -mkdir $target_dir echo &quot;ç›®æ ‡è·¯å¾„$target_dirä¸å­˜åœ¨ï¼Œåˆ›å»ºæˆåŠŸ&quot;fi# å¼€å§‹æ‹·è´echo &quot;å¼€å§‹hdfsæ–‡ä»¶æ‹·è´ï¼Œsource_dir=$source_dirï¼Œtarget_dir=$target_dir&quot;hadoop distcp -overwrite -delete -pbugp $source_dir $target_dirif [ $? -eq 0 ];then echo &quot;hdfsæ–‡ä»¶æ‹·è´æˆåŠŸ&quot;else echo &quot;hdfsæ–‡ä»¶æ‹·è´å¤±è´¥&quot; exit -1fi# åˆ·æ–°ç›®æ ‡è¡¨çš„metastoreä¿¡æ¯hive -database $db_name -v -e &quot;msck repair table $target_tbl_name;&quot;if [ $? -eq 0 ];then echo &quot;$target_tbl_nameè¡¨çš„metastoreä¿¡æ¯åˆ·æ–°æˆåŠŸ&quot; exit 0fi å‚è€ƒèµ„æ–™DistCpä½¿ç”¨æŒ‡å—Hadoopä¸­æ–‡ç½‘ï¼šDistCp","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://llye-hub.github.io/categories/hadoop/"}],"tags":[{"name":"hadoopå‘½ä»¤","slug":"hadoopå‘½ä»¤","permalink":"https://llye-hub.github.io/tags/hadoop%E5%91%BD%E4%BB%A4/"},{"name":"hdfsæ–‡ä»¶æ‹·è´","slug":"hdfsæ–‡ä»¶æ‹·è´","permalink":"https://llye-hub.github.io/tags/hdfs%E6%96%87%E4%BB%B6%E6%8B%B7%E8%B4%9D/"}]},{"title":"Shellå‘½ä»¤ä¹‹set-e","slug":"shell/Shellå‘½ä»¤ä¹‹set-e","date":"2023-01-31T09:26:54.000Z","updated":"2023-02-20T08:35:55.810Z","comments":true,"path":"posts/ba81765c.html","link":"","permalink":"https://llye-hub.github.io/posts/ba81765c.html","excerpt":"","text":"","categories":[{"name":"shell","slug":"shell","permalink":"https://llye-hub.github.io/categories/shell/"}],"tags":[{"name":"shellå‘½ä»¤","slug":"shellå‘½ä»¤","permalink":"https://llye-hub.github.io/tags/shell%E5%91%BD%E4%BB%A4/"}]},{"title":"hadoopåŸºæœ¬å‘½ä»¤","slug":"hadoop/hadoopåŸºæœ¬å‘½ä»¤","date":"2023-01-31T09:10:11.000Z","updated":"2023-02-20T08:35:55.810Z","comments":true,"path":"posts/b24f0feb.html","link":"","permalink":"https://llye-hub.github.io/posts/b24f0feb.html","excerpt":"","text":"hadoop fs -cphadoop fs -rm -rhadoop distcp -overwrite -delete -phadoop fs -mkdir -p","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://llye-hub.github.io/categories/hadoop/"}],"tags":[{"name":"hadoopå‘½ä»¤","slug":"hadoopå‘½ä»¤","permalink":"https://llye-hub.github.io/tags/hadoop%E5%91%BD%E4%BB%A4/"}]},{"title":"hiveåŠ¨æ€åˆ†åŒº","slug":"hive/hiveåŠ¨æ€åˆ†åŒº","date":"2023-01-30T09:01:49.000Z","updated":"2023-02-20T08:35:55.811Z","comments":true,"path":"posts/44d3528f.html","link":"","permalink":"https://llye-hub.github.io/posts/44d3528f.html","excerpt":"","text":"","categories":[{"name":"hive","slug":"hive","permalink":"https://llye-hub.github.io/categories/hive/"}],"tags":[{"name":"åŠ¨æ€åˆ†åŒº","slug":"åŠ¨æ€åˆ†åŒº","permalink":"https://llye-hub.github.io/tags/%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA/"}]},{"title":"SparkSQLæ— æ³•å¤„ç†hiveè¡¨ä¸­çš„ç©ºORCæ–‡ä»¶","slug":"spark/Spark SQLæ— æ³•å¤„ç†hiveè¡¨ä¸­çš„ç©ºORCæ–‡ä»¶","date":"2022-12-16T09:56:46.000Z","updated":"2023-02-20T03:40:11.835Z","comments":true,"path":"posts/1f69e18b.html","link":"","permalink":"https://llye-hub.github.io/posts/1f69e18b.html","excerpt":"","text":"ç¢°åˆ°äº†ä»€ä¹ˆé—®é¢˜èµ·å› æ˜¯åœ¨ä½¿ç”¨SparkSQLæŸ¥è¯¢è¡¨æ—¶ï¼Œé‡åˆ°æŠ¥é”™ï¼šjava.lang.RuntimeException: serious problem at OrcInputFormat.generateSplitsInfoä¹‹åï¼Œæ¢äº†hiveSQLæ‰§è¡ŒæˆåŠŸï¼Œä½†è¿™å¹¶ä¸ç®—æ’æŸ¥æˆåŠŸï¼Œæ’æŸ¥åº”å°½å¯èƒ½è¿½æ ¹ç©¶åº•ï¼Œä»¥åæ‰èƒ½åšåˆ°ä¸¾ä¸€åä¸‰ï¼Œæ‰€ä»¥åŸºäºç½‘ä¸Šèµ„æ–™å’Œä¸ªäººç†è§£å†™äº†è¿™ç¯‡åšå®¢ é—®é¢˜åˆ†æå®šä½é—®é¢˜æ ¹æ®æŠ¥é”™çš„javaç±»å+æ–¹æ³•åï¼ˆOrcInputFormat.generateSplitsInfoï¼‰ï¼Œå¯ä»¥åˆ¤æ–­é—®é¢˜å‡ºç°åœ¨è¯»å–orcæ–‡ä»¶é˜¶æ®µã€‚ æŸ¥çœ‹HDFSæ–‡ä»¶æŸ¥çœ‹è¡¨å­˜å‚¨è·¯å¾„ä¸‹çš„æ–‡ä»¶ï¼Œå‘ç°æœ‰1ä¸ªç©ºæ–‡ä»¶ ä¸ºä»€ä¹ˆä¼šæœ‰ç©ºæ–‡ä»¶1ã€sparkSQLå»ºè¡¨2ã€è¡¨å†™å…¥æ•°æ®æ—¶ï¼Œsqlæœ€ååšäº†distribute byæ“ä½œï¼Œäº§ç”Ÿäº†ç©ºæ–‡ä»¶ sparksqlè¯»å–ç©ºæ–‡ä»¶çš„æ—¶å€™ï¼Œå› ä¸ºè¡¨æ˜¯orcæ ¼å¼çš„ï¼Œå¯¼è‡´sparkSQLè§£æorcæ–‡ä»¶å‡ºé”™ã€‚ä½†æ˜¯ç”¨hiveå´å¯ä»¥æ­£å¸¸è¯»å–ã€‚ ç½‘ä¸Šæœç½—çš„è§£å†³åŠæ³•é—®é¢˜åŸå› åŸºæœ¬æ¸…æ™°äº†ï¼Œå°±æ˜¯è¯»å–ç©ºæ–‡ä»¶å¯¼è‡´çš„æŠ¥é”™ï¼Œå¦‚æœéå¾—ç”¨SparkSQLæ‰§è¡ŒæŸ¥è¯¢è¯­å¥ï¼Œè¿™é‡Œæä¾›å‡ ç§è§£å†³æ–¹æ¡ˆï¼š 1ã€ä¿®æ”¹è¡¨å­˜å‚¨æ ¼å¼ä¸ºparquetè¿™ç§æ–¹æ³•æ˜¯ç½‘ä¸ŠæŸ¥è¯¢åˆ°çš„ï¼Œä½†åœ¨å®é™…æ•°ä»“å·¥ä½œä¸­ï¼Œå¯¹äºå·²åœ¨ä½¿ç”¨ä¸­çš„è¡¨æ¥è¯´ï¼Œåˆ è¡¨é‡å»ºæ“ä½œæ˜¯ä¸å…è®¸çš„ï¼Œæ‰€ä»¥ä¸æ¨è 2ã€å‚æ•°è®¾ç½®ï¼šset hive.exec.orc.split.strategy=ETLæ—¢ç„¶å·²ç»å®šä½åˆ°æ˜¯ç©ºæ–‡ä»¶è¯»å–çš„é—®é¢˜ï¼Œé‚£å°±ä»æ–‡ä»¶è¯»å–å±‚é¢è§£å†³ã€‚ è‡ªå»ºé›†ç¾¤Sparkæºç ï¼š 12345678910111213141516171819202122232425262728// org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.javaswitch(context.splitStrategyKind) &#123; case BI: // BI strategy requested through config splitStrategy = new BISplitStrategy(context, fs, dir, children, isOriginal, deltas, covered); break; case ETL: // ETL strategy requested through config splitStrategy = new ETLSplitStrategy(context, fs, dir, children, isOriginal, deltas, covered); break; default: // HYBRID strategy if (avgFileSize &gt; context.maxSize) &#123; splitStrategy = new ETLSplitStrategy(context, fs, dir, children, isOriginal, deltas, covered); &#125; else &#123; splitStrategy = new BISplitStrategy(context, fs, dir, children, isOriginal, deltas, covered); &#125; break;&#125;// ./repository/org/spark-project/hive/hive-exec/1.2.1.spark2/hive-exec-1.2.1.spark2.jar!/org/apache/hadoop/hive/conf/HiveConf.classHIVE_ORC_SPLIT_STRATEGY(&quot;hive.exec.orc.split.strategy&quot;, &quot;HYBRID&quot;, new StringSet(new String[]&#123;&quot;HYBRID&quot;, &quot;BI&quot;, &quot;ETL&quot;&#125;), &quot;This is not a user level config. BI strategy is used when the requirement is to spend less time in split generation as opposed to query execution (split generation does not read or cache file footers). ETL strategy is used when spending little more time in split generation is acceptable (split generation reads and caches file footers). HYBRID chooses between the above strategies based on heuristics.&quot;) ä¹Ÿå°±æ˜¯è¯´ï¼Œé»˜è®¤æ˜¯HYBRIDï¼ˆæ··åˆæ¨¡å¼è¯»å–ï¼Œæ ¹æ®å¹³å‡æ–‡ä»¶å¤§å°å’Œæ–‡ä»¶ä¸ªæ•°é€‰æ‹©ETLè¿˜æ˜¯BIæ¨¡å¼ï¼‰ã€‚ BIç­–ç•¥ä»¥æ–‡ä»¶ä¸ºç²’åº¦è¿›è¡Œsplitåˆ’åˆ† ETLç­–ç•¥ä¼šå°†æ–‡ä»¶è¿›è¡Œåˆ‡åˆ†ï¼Œå¤šä¸ªstripeç»„æˆä¸€ä¸ªsplit HYBRIDç­–ç•¥ä¸ºï¼šå½“æ–‡ä»¶çš„å¹³å‡å¤§å°å¤§äºhadoopæœ€å¤§splitå€¼ï¼ˆé»˜è®¤256 * 1024 * 1024ï¼‰æ—¶ä½¿ç”¨ETLç­–ç•¥ï¼Œå¦åˆ™ä½¿ç”¨BIç­–ç•¥ã€‚ ETLSplitStrategyå’ŒBISplitStrategyä¸¤ç§ç­–ç•¥åœ¨å¯¹getSplitsæ–¹æ³•é‡‡ç”¨äº†ä¸åŒçš„å®ç°æ–¹å¼ï¼ŒBISplitStrategyåœ¨é¢å¯¹ç©ºæ–‡ä»¶æ—¶ä¼šå‡ºç°ç©ºæŒ‡é’ˆå¼‚å¸¸ï¼ŒETLSplitStrategyåˆ™å¸®æˆ‘ä»¬è¿‡æ»¤äº†ç©ºæ–‡ä»¶ã€‚ 123456789101112131415161718192021222324252627282930313233// org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.BISplitStrategy#getSplitspublic List&lt;OrcSplit&gt; getSplits() throws IOException &#123; List&lt;OrcSplit&gt; splits = Lists.newArrayList(); for (FileStatus fileStatus : fileStatuses) &#123; String[] hosts = SHIMS .getLocationsWithOffset(fs, fileStatus) // å¯¹ç©ºæ–‡ä»¶ä¼šè¿”å›ä¸€ä¸ªç©ºçš„TreeMap .firstEntry() // null .getValue() // NPE .getHosts(); OrcSplit orcSplit = new OrcSplit(fileStatus.getPath(), 0, fileStatus.getLen(), hosts, null, isOriginal, true, deltas, -1); splits.add(orcSplit); &#125; // add uncovered ACID delta splits splits.addAll(super.getSplits()); return splits;&#125;// org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.ETLSplitStrategy#getSplitspublic List&lt;SplitInfo&gt; getSplits() throws IOException &#123; List&lt;SplitInfo&gt; result = Lists.newArrayList(); for (FileStatus file : files) &#123; FileInfo info = null; if (context.cacheStripeDetails) &#123; info = verifyCachedFileInfo(file); &#125; // ignore files of 0 lengthï¼ˆæ­¤å¤„å¯¹ç©ºæ–‡ä»¶åšäº†è¿‡æ»¤ï¼‰ if (file.getLen() &gt; 0) &#123; result.add(new SplitInfo(context, fs, file, info, isOriginal, deltas, true, dir, covered)); &#125; &#125; return result;&#125; æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªBUGï¼ŒSpark2.4ç‰ˆæœ¬ä¸­è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚ 123456789101112131415// org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.BISplitStrategy#getSplitspublic List&lt;OrcSplit&gt; getSplits() throws IOException &#123; List&lt;OrcSplit&gt; splits = Lists.newArrayList(); for (FileStatus fileStatus : fileStatuses) &#123; String[] hosts = SHIMS.getLocationsWithOffset(fs, fileStatus).firstEntry().getValue() .getHosts(); OrcSplit orcSplit = new OrcSplit(fileStatus.getPath(), 0, fileStatus.getLen(), hosts, null, isOriginal, true, deltas, -1); splits.add(orcSplit); &#125; // add uncovered ACID delta splits splits.addAll(super.getSplits()); return splits;&#125; äº†è§£äº†sparkè¯»å–orcæ–‡ä»¶ç­–ç•¥ï¼Œé‚£ä¹ˆå°±è®¾ç½®é¿å…æ··åˆæ¨¡å¼ä½¿ç”¨æ ¹æ®æ–‡ä»¶å¤§å°åˆ†å‰²è¯»å–ï¼Œä¸æ ¹æ®æ–‡ä»¶æ¥è¯»å– 1set hive.exec.orc.split.strategy=ETL ç»æµ‹è¯•æ— æ•ˆã€‚åŸå› åˆ†æï¼š1ã€å‚æ•°æœªç”Ÿæ•ˆ2ã€hdfsæ–‡ä»¶æœ‰ä¸¤ä¸ªï¼Œå¤§å°ä¸º49Bå’Œ7.45Gï¼Œæ–‡ä»¶çš„å¹³å‡å¤§å°è‚¯å®šæ˜¯å¤§äº256Mçš„ï¼Œæ‰€ä»¥æŒ‰é»˜è®¤HYBRIDç­–ç•¥è§„åˆ™åº”æœ¬å°±æ˜¯é‡‡å–çš„ETLç­–ç•¥split ORCæ–‡ä»¶ 3ã€å‚æ•°è®¾ç½®ï¼šspark.sql.hive.convertMetastoreOrc=trueå…³äºå‚æ•°çš„å®˜æ–¹ä»‹ç» Since Spark 2.3, Spark supports a vectorized ORC reader with a new ORC file format for ORC files. To do that, the following configurations are newly added. The vectorized reader is used for the native ORC tables (e.g., the ones created using the clause USING ORC) when spark.sql.orc.impl is set to native and spark.sql.orc.enableVectorizedReader is set to true. For the Hive ORC serde tables (e.g., the ones created using the clause USING HIVE OPTIONS (fileFormat â€˜ORCâ€™)), the vectorized reader is used when spark.sql.hive.convertMetastoreOrc is also set to true. ç»æµ‹è¯•æœ‰æ•ˆã€‚è‹¥ä»æŠ¥é”™ï¼Œå¯å°è¯•æ­é…spark.sql.orc.impl&#x3D;nativeä½¿ç”¨ã€‚ è¡¥å……çŸ¥è¯†hive.exec.orc.split.strategyå‚æ•°æ§åˆ¶åœ¨è¯»å–ORCè¡¨æ—¶ç”Ÿæˆsplitçš„ç­–ç•¥ã€‚å¯¹äºä¸€äº›è¾ƒå¤§çš„ORCè¡¨ï¼Œå¯èƒ½å…¶footerè¾ƒå¤§ï¼ŒETLç­–ç•¥å¯èƒ½ä¼šå¯¼è‡´å…¶ä»hdfsæ‹‰å–å¤§é‡çš„æ•°æ®æ¥åˆ‡åˆ†splitï¼Œç”šè‡³ä¼šå¯¼è‡´driverç«¯OOMï¼Œå› æ­¤è¿™ç±»è¡¨çš„è¯»å–å»ºè®®ä½¿ç”¨BIç­–ç•¥ã€‚å¯¹äºä¸€äº›è¾ƒå°çš„å°¤å…¶æœ‰æ•°æ®å€¾æ–œçš„è¡¨ï¼ˆè¿™é‡Œçš„æ•°æ®å€¾æ–œæŒ‡å¤§é‡stripeå­˜å‚¨äºå°‘æ•°æ–‡ä»¶ä¸­ï¼‰ï¼Œå»ºè®®ä½¿ç”¨ETLç­–ç•¥ã€‚å¦å¤–ï¼Œspark.hadoop.mapreduce.input.fileinputformat.split.minsizeå‚æ•°å¯ä»¥æ§åˆ¶åœ¨ORCåˆ‡åˆ†æ—¶stripeçš„åˆå¹¶å¤„ç†ã€‚å…·ä½“é€»è¾‘æ˜¯ï¼Œå½“å‡ ä¸ªstripeçš„å¤§å°å°äºspark.hadoop.mapreduce.input.fileinputformat.split.minsizeæ—¶ï¼Œä¼šåˆå¹¶åˆ°ä¸€ä¸ªtaskä¸­å¤„ç†ã€‚å¯ä»¥é€‚å½“è°ƒå°è¯¥å€¼ï¼Œä»¥æ­¤å¢å¤§è¯»ORCè¡¨çš„å¹¶å‘ã€‚ å‚è€ƒèµ„æ–™SPARKæŸ¥ORCæ ¼å¼HIVEæ•°æ®æŠ¥é”™NULLPOINTEREXCEPTIONSparkSQLè¯»å–ORCè¡¨æ—¶é‡åˆ°ç©ºæ–‡ä»¶","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"ORC","slug":"ORC","permalink":"https://llye-hub.github.io/tags/ORC/"}]},{"title":"get_json_objectåœ¨sqlä¸­çš„é«˜çº§ç”¨æ³•","slug":"SQL/get_json_objectåœ¨sqlä¸­çš„é«˜çº§ç”¨æ³•","date":"2022-12-16T03:46:24.000Z","updated":"2023-02-20T03:39:56.457Z","comments":true,"path":"posts/5f45fcd7.html","link":"","permalink":"https://llye-hub.github.io/posts/5f45fcd7.html","excerpt":"","text":"è¯­æ³•ä»‹ç»12get_json_object(String json_string, String path)-- return string get_json_objectå‡½æ•°æ˜¯ç”¨æ¥æ ¹æ®æŒ‡å®šè·¯å¾„æå–jsonå­—ç¬¦ä¸²ä¸­çš„jsonå¯¹è±¡ï¼Œå¹¶è¿”å›jsonå¯¹è±¡çš„jsonå­—ç¬¦ä¸² ç°æœ‰å›°æƒ‘å…³äºè¿™ä¸ªå‡½æ•°æœ€å¸¸è§çš„ç”¨æ³•å°±æ˜¯get_json_object(&#39;&#123;&quot;a&quot;:&quot;b&quot;&#125;&#39;, &#39;$.a&#39;)ï¼Œè¿”å›ç»“æœbä½†$.aè¿™ç§pathå†™æ³•ä»…é€‚ç”¨äºç®€å•çš„å¤šå±‚åµŒå¥—jsonå­—ç¬¦ä¸²è§£æï¼Œç¢°åˆ°åµŒå¥—å±‚æœ‰jsonæ•°ç»„æ—¶å°±éš¾ä»¥è§£æäº†æ¯”å¦‚ï¼Œè¦æå–ä¸‹é¢è¿™æ®µjsonä¸­çš„æ‰€æœ‰weightå¯¹è±¡çš„å€¼ 123456789&#123; &quot;store&quot;: &#123; &quot;fruit&quot;:[&#123;&quot;weight&quot;:8,&quot;type&quot;:&quot;apple&quot;&#125;, &#123;&quot;weight&quot;:9,&quot;type&quot;:&quot;pear&quot;&#125;], //jsonæ•°ç»„ &quot;bicycle&quot;:&#123;&quot;price&quot;:19.95,&quot;color&quot;:&quot;red&quot;&#125; &#125;, &quot;email&quot;:&quot;amy@only_for_json_udf_test.net&quot;, &quot;owner&quot;:&quot;amy&quot; &#125; é€šè¿‡$.store.fruit.weightè·¯å¾„æ˜¯æ— æ³•æå–çš„ï¼Œ$.store.fruit[0].weightè¿™ç§å†™æ³•ä»…èƒ½è·å–jsonæ•°ç»„ä¸­ç¬¬ä¸€ä¸ªjsonå­—ç¬¦ä¸²ä¸­weightå¯¹è±¡çš„å€¼ï¼Œä¹Ÿæ€»ä¸èƒ½ç”¨[0]ã€[1]ã€[2]â€¦â€¦çš„æ–¹å¼æ— ç©·å°½å–å€¼å§ åˆ°è¿™é‡Œæ€ç»´å°±é™åˆ¶ä½äº†ï¼Œé‡åˆ°è¿™ç§æƒ…å†µæ—¶ï¼Œä»¥å‰çš„æ–¹å¼æ˜¯é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼å¤„ç†å…·ä½“å®ç°å¦‚ä¸‹ï¼šé¦–å…ˆå°†item_propertiesæŒ‰æŒ‡å®šåˆ†éš”ç¬¦splitä¸ºarrayæ•°ç»„ï¼Œå†åˆ©ç”¨explodeå‡½æ•°å°†arrayæ•°ç»„çš„å…ƒç´ é€è¡Œè¾“å‡ºï¼Œæœ€ç»ˆå¾—åˆ°çš„item_propertieå³ä¸ºå•ä¸ªjsonå­—ç¬¦ä¸²ï¼Œå¯æ ¹æ®$.æå–æŒ‡å®šjsonå¯¹è±¡çš„å€¼ï¼Œ 12345678910-- item_properties = [&#123;&quot;id&quot;:42,&quot;name&quot;:&quot;åŒ…è£…&quot;,&quot;sort&quot;:0,&quot;type&quot;:1&#125;-- ,&#123;&quot;id&quot;:43,&quot;name&quot;:&quot;ç§ç±»&quot;,&quot;sort&quot;:0,&quot;type&quot;:1&#125;-- ,&#123;&quot;id&quot;:44,&quot;name&quot;:&quot;è§„æ ¼&quot;,&quot;sort&quot;:0,&quot;type&quot;:2&#125;-- ,&#123;&quot;id&quot;:63,&quot;name&quot;:&quot;ä¿è´¨æœŸ(å¤©)&quot;,&quot;sort&quot;:0,&quot;type&quot;:2&#125;-- ,&#123;&quot;id&quot;:100,&quot;name&quot;:&quot;é€‚ç”¨å¹´é¾„&quot;,&quot;sort&quot;:0,&quot;type&quot;:2&#125;-- ,&#123;&quot;id&quot;:101,&quot;name&quot;:&quot;å‚¨å­˜æ¡ä»¶&quot;,&quot;sort&quot;:0,&quot;type&quot;:2&#125;]select get_json_object(item_propertie,&#x27;$.id&#x27;)from table_alateral view explode(split(regexp_replace(substr(item_properties,2,length(item_properties)-2),&#x27;\\\\&#125;\\\\,\\\\&#123;&#x27;,&#x27;\\\\&#125;\\\\|\\\\|\\\\&#123;&#x27;),&#x27;\\\\|\\\\|&#x27;)) tmp as item_propertie ä½†ä¸Šé¢è¿™ç§å¤„ç†æ–¹å¼å­˜åœ¨bugï¼Œå°†jsonæ•°æ®splitä¸ºarrayæ•°ç»„æ—¶ï¼Œå¿…é¡»ä¿è¯æŒ‡å®šåˆ†éš”ç¬¦ä¸å‡ºç°åœ¨å•ä¸ªjsonå­—ç¬¦ä¸²ä¸­ï¼Œæ¯”å¦‚ä¸Šè¿°caseä¸­æ˜¯ç”¨&#125;,&#123;æ›¿æ¢ä¸º&#125;||&#123;ï¼Œå†ä»¥||ä½œä¸ºåˆ†éš”ç¬¦splitï¼Œå¦‚è‹¥åœ¨å•ä¸ªjsonå­—ç¬¦ä¸²ä¸­ä¹Ÿå‡ºç°äº†&#125;,&#123;æˆ–æ˜¯||å°±ä¼šå¯¼è‡´è§£æå¤±è´¥ æ€ä¹ˆé«˜çº§äº†çªç„¶æœ‰ä¸€å¤©åœ¨ç¿»çœ‹hiveå®˜æ–¹æ–‡æ¡£æ—¶å‘ç°pathæ”¯æŒçš„é€šé…ç¬¦* 1234$ : è¡¨ç¤ºæ ¹èŠ‚ç‚¹. : è¡¨ç¤ºå­èŠ‚ç‚¹[] : [number]è¡¨ç¤ºæ•°ç»„ä¸‹æ ‡ï¼Œä»0å¼€å§‹* : []çš„é€šé…ç¬¦ï¼Œè¿”å›æ•´ä¸ªæ•°ç»„ æ‰€ä»¥ï¼Œä¸€å¼€å§‹çš„é—®é¢˜åº”è¯¥æŒ‰å¦‚ä¸‹è§£æ³•ï¼š 123456789-- jsonArray = &#123;&quot;store&quot;:-- &#123;-- &quot;fruit&quot;:[&#123;&quot;weight&quot;:8,&quot;type&quot;:&quot;apple&quot;&#125;, &#123;&quot;weight&quot;:9,&quot;type&quot;:&quot;pear&quot;&#125;],-- &quot;bicycle&quot;:&#123;&quot;price&quot;:19.95,&quot;color&quot;:&quot;red&quot;&#125;-- &#125;, -- &quot;email&quot;:&quot;amy@only_for_json_udf_test.net&quot;, -- &quot;owner&quot;:&quot;amy&quot;&#125;select get_json_object(jsonArray, &#x27;$.store.fruit[*].weight&#x27;);-- return [8,9] ç¬”è€…ä¸ªäººè®¤ä¸ºï¼Œé«˜çº§ä¹‹å¤„åœ¨äºå†™æ³•æå…¶æ¸…çˆ½ï¼ŒæŒ‰ç…§ä»¥å‰ç”¨æ­£åˆ™è¡¨è¾¾å¼çš„å¤„ç†æ–¹æ³•ï¼Œéœ€è¦å¤šé“å¤„ç†æ‰èƒ½å¾—åˆ°ç»“æœ[8,9]ï¼Œè€Œä¸”å…¶ä¸­è¿˜æœ‰éšæ€§é£é™©ï¼Œä½†æ˜¯ç°åœ¨$.store.fruit[*].weightè¿™ç§æç®€è¯­æ³•æ—¢é¿å…äº†é£é™©ï¼Œåˆæ¸…æ™°æ˜“ç†è§£","categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"}],"tags":[{"name":"SQLé«˜çº§è¯­æ³•","slug":"SQLé«˜çº§è¯­æ³•","permalink":"https://llye-hub.github.io/tags/SQL%E9%AB%98%E7%BA%A7%E8%AF%AD%E6%B3%95/"}]},{"title":"èµ„æ–™æ±‡æ€»","slug":"èµ„æ–™æ±‡æ€»","date":"2022-12-16T03:46:24.000Z","updated":"2023-02-22T02:49:03.975Z","comments":true,"path":"posts/76d5a95a.html","link":"","permalink":"https://llye-hub.github.io/posts/76d5a95a.html","excerpt":"","text":"SparkSQLSpark SQL Limit ä»‹ç»åŠä¼˜åŒ– Sparkæ€§èƒ½ä¼˜åŒ–æŒ‡å—â€”â€”åŸºç¡€ç¯‡ Sparkæ€§èƒ½ä¼˜åŒ–æŒ‡å—â€”â€”é«˜çº§ç¯‡ å¤§æ•°æ®ç¬”è®°å¤§æ•°æ®å…¥é—¨æŒ‡å— æ•°æ®ç»“æ„ä¸ç®—æ³•ä»£ç éšæƒ³å½• æ•°æ®æ²»ç†å­˜å‚¨å’Œè®¡ç®—èµ„æºéƒ½èŠ‚çœ 30%ï¼Œç½‘æ˜“äº‘éŸ³ä¹æ•°æ®æ²»ç†å®è·µ æ•°æ®åº“æ•°æ®åº“å†…æ ¸æ‚è°ˆç³»åˆ— ä¹±ä¸ƒå…«ç³Ÿçš„2ä¸‡å­—æ­ç§˜é˜¿é‡Œå·´å·´æ•°æ®æ²»ç†å¹³å°å»ºè®¾ç»éªŒ","categories":[{"name":"èµ„æ–™","slug":"èµ„æ–™","permalink":"https://llye-hub.github.io/categories/%E8%B5%84%E6%96%99/"}],"tags":[]}],"categories":[{"name":"SQL","slug":"SQL","permalink":"https://llye-hub.github.io/categories/SQL/"},{"name":"é˜…è¯»ç¬”è®°","slug":"é˜…è¯»ç¬”è®°","permalink":"https://llye-hub.github.io/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"spark","slug":"spark","permalink":"https://llye-hub.github.io/categories/spark/"},{"name":"hive","slug":"hive","permalink":"https://llye-hub.github.io/categories/hive/"},{"name":"hadoop","slug":"hadoop","permalink":"https://llye-hub.github.io/categories/hadoop/"},{"name":"shell","slug":"shell","permalink":"https://llye-hub.github.io/categories/shell/"},{"name":"é¢˜é›†","slug":"é¢˜é›†","permalink":"https://llye-hub.github.io/categories/%E9%A2%98%E9%9B%86/"},{"name":"èµ„æ–™","slug":"èµ„æ–™","permalink":"https://llye-hub.github.io/categories/%E8%B5%84%E6%96%99/"}],"tags":[{"name":"hiveSQL","slug":"hiveSQL","permalink":"https://llye-hub.github.io/tags/hiveSQL/"},{"name":"è¯»ä¹¦ç¬”è®°","slug":"è¯»ä¹¦ç¬”è®°","permalink":"https://llye-hub.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"å†…ç½®å‡½æ•°","slug":"å†…ç½®å‡½æ•°","permalink":"https://llye-hub.github.io/tags/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"},{"name":"spark on yarn","slug":"spark-on-yarn","permalink":"https://llye-hub.github.io/tags/spark-on-yarn/"},{"name":"hiveå®‰è£…","slug":"hiveå®‰è£…","permalink":"https://llye-hub.github.io/tags/hive%E5%AE%89%E8%A3%85/"},{"name":"hadoopå®‰è£…","slug":"hadoopå®‰è£…","permalink":"https://llye-hub.github.io/tags/hadoop%E5%AE%89%E8%A3%85/"},{"name":"shellå‘½ä»¤","slug":"shellå‘½ä»¤","permalink":"https://llye-hub.github.io/tags/shell%E5%91%BD%E4%BB%A4/"},{"name":"å…å¯†ç™»å½•","slug":"å…å¯†ç™»å½•","permalink":"https://llye-hub.github.io/tags/%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"},{"name":"sqlç»ƒä¹ ","slug":"sqlç»ƒä¹ ","permalink":"https://llye-hub.github.io/tags/sql%E7%BB%83%E4%B9%A0/"},{"name":"çª—å£å‡½æ•°","slug":"çª—å£å‡½æ•°","permalink":"https://llye-hub.github.io/tags/%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/"},{"name":"java","slug":"java","permalink":"https://llye-hub.github.io/tags/java/"},{"name":"æ•°æ®ç»“æ„","slug":"æ•°æ®ç»“æ„","permalink":"https://llye-hub.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Maxcompute","slug":"Maxcompute","permalink":"https://llye-hub.github.io/tags/Maxcompute/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://llye-hub.github.io/tags/LeetCode/"},{"name":"æ•°æ®å€¾æ–œ","slug":"æ•°æ®å€¾æ–œ","permalink":"https://llye-hub.github.io/tags/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"},{"name":"SQLé«˜çº§è¯­æ³•","slug":"SQLé«˜çº§è¯­æ³•","permalink":"https://llye-hub.github.io/tags/SQL%E9%AB%98%E7%BA%A7%E8%AF%AD%E6%B3%95/"},{"name":"æ”¹åˆ†åŒº","slug":"æ”¹åˆ†åŒº","permalink":"https://llye-hub.github.io/tags/%E6%94%B9%E5%88%86%E5%8C%BA/"},{"name":"hadoopå‘½ä»¤","slug":"hadoopå‘½ä»¤","permalink":"https://llye-hub.github.io/tags/hadoop%E5%91%BD%E4%BB%A4/"},{"name":"hdfsæ–‡ä»¶æ‹·è´","slug":"hdfsæ–‡ä»¶æ‹·è´","permalink":"https://llye-hub.github.io/tags/hdfs%E6%96%87%E4%BB%B6%E6%8B%B7%E8%B4%9D/"},{"name":"åŠ¨æ€åˆ†åŒº","slug":"åŠ¨æ€åˆ†åŒº","permalink":"https://llye-hub.github.io/tags/%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA/"},{"name":"ORC","slug":"ORC","permalink":"https://llye-hub.github.io/tags/ORC/"}]}